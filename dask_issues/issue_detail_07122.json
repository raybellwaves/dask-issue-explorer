{
    "url": "https://api.github.com/repos/dask/dask/issues/7122",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/7122/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/7122/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/7122/events",
    "html_url": "https://github.com/dask/dask/pull/7122",
    "id": 796022023,
    "node_id": "MDExOlB1bGxSZXF1ZXN0NTYzMjcxNzUw",
    "number": 7122,
    "title": "BUG: len / column subset failing on filtered parquet dataset using pyarrow.dataset engine",
    "user": {
        "login": "jorisvandenbossche",
        "id": 1020496,
        "node_id": "MDQ6VXNlcjEwMjA0OTY=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1020496?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/jorisvandenbossche",
        "html_url": "https://github.com/jorisvandenbossche",
        "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
        "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
        "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
        "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
        "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
        "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
        "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2021-01-28T13:50:38Z",
    "updated_at": "2021-03-08T20:19:54Z",
    "closed_at": null,
    "author_association": "MEMBER",
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
        "url": "https://api.github.com/repos/dask/dask/pulls/7122",
        "html_url": "https://github.com/dask/dask/pull/7122",
        "diff_url": "https://github.com/dask/dask/pull/7122.diff",
        "patch_url": "https://github.com/dask/dask/pull/7122.patch",
        "merged_at": null
    },
    "body": "This is actually a bug report, but in form of a PR with test. I noticed that my demo notebook with the pyarrow dataset engine was not actually fully working anymore (it seems this was already the case at the end of https://github.com/dask/dask/pull/6534, though, so the bug was probably introduced somewhere along that long PR). \r\n\r\nThe rather simple case of checking the length or getting a subset of columns of a filtered partitioned dataset is failing:\r\n\r\n```python\r\ndf = pd.DataFrame({\"part\": [\"A\", \"B\"] * 10, \"col\": range(20)})\r\nddf = dd.from_pandas(df, npartitions=2)\r\nddf.to_parquet(\"test_dask_pyarrow_filter\", partition_on=[\"part\"])\r\nddf_subset = dd.read_parquet(\"test_dask_pyarrow_filter\", filters=[[('part', '=', \"A\")]], engine=\"pyarrow-dataset\")\r\n\r\n# both fail\r\nlen(ddf_subset)\r\nddf_subset[\"col\"].sum().compute()\r\n```\r\n\r\ncc @rjzamora \r\n\r\nThe reason that it is failing is because in `read_partition` in the lines below, we don't calculate a `keys_dict` if we have a pyarrow.dataset ParquetFileFragment, but we *still* have `partitions`:\r\n\r\nhttps://github.com/dask/dask/blob/9bb586a6b8fac1983b7cea3ab399719f93dbbb29/dask/dataframe/io/parquet/arrow.py#L616-L625\r\n\r\nThe \"easy\" fix might be to just always calculate `keys_dict`, but on the other hand, in the case that we have a ParquetFileFragment, we shouldn't remove the partition columns from `columns` and let pyarrow read the `arrow_table` with partition columns included (I suppose was the rationale about the above if/else, but in practice that doesn't happen anymore, and `arrow_table` does not actually include the partition columns, and thus the code here is trying to add them, getting it from `keys_dict`, but which is empty. ",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/7122/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/7122/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}