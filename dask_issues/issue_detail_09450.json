{
    "url": "https://api.github.com/repos/dask/dask/issues/9450",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/9450/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/9450/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/9450/events",
    "html_url": "https://github.com/dask/dask/issues/9450",
    "id": 1358184175,
    "node_id": "I_kwDOAbcwm85Q9D7v",
    "number": 9450,
    "title": "Change `split_every=False` default for DataFrame reductions like `mean`?",
    "user": {
        "login": "gjoseph92",
        "id": 3309802,
        "node_id": "MDQ6VXNlcjMzMDk4MDI=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3309802?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/gjoseph92",
        "html_url": "https://github.com/gjoseph92",
        "followers_url": "https://api.github.com/users/gjoseph92/followers",
        "following_url": "https://api.github.com/users/gjoseph92/following{/other_user}",
        "gists_url": "https://api.github.com/users/gjoseph92/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/gjoseph92/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/gjoseph92/subscriptions",
        "organizations_url": "https://api.github.com/users/gjoseph92/orgs",
        "repos_url": "https://api.github.com/users/gjoseph92/repos",
        "events_url": "https://api.github.com/users/gjoseph92/events{/privacy}",
        "received_events_url": "https://api.github.com/users/gjoseph92/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        },
        {
            "id": 3468123446,
            "node_id": "LA_kwDOAbcwm87Ot102",
            "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention",
            "name": "needs attention",
            "color": "6d626c",
            "default": false,
            "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."
        },
        {
            "id": 3798602129,
            "node_id": "LA_kwDOAbcwm87iahGR",
            "url": "https://api.github.com/repos/dask/dask/labels/enhancement",
            "name": "enhancement",
            "color": "C2E0C6",
            "default": true,
            "description": "Improve existing functionality or make things work better"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 4,
    "created_at": "2022-09-01T03:10:35Z",
    "updated_at": "2022-10-03T02:13:33Z",
    "closed_at": null,
    "author_association": "MEMBER",
    "active_lock_reason": null,
    "body": "Most DataFrame reductions like `mean`, `count`, etc. use a hardcoded `split_every=False` default. This means that we'll apply the reduction to every partiton, then in a single task, combine all those results into one.\r\n\r\nThis makes sense because it keeps the graph smaller. And the intermediate results should be tiny (a single row), so transferring them is relatively cheap. It's ideal for a local scheduler.\r\n\r\n### `split_every=False` (current)\r\n![mydask](https://user-images.githubusercontent.com/3309802/187822585-d540d515-d849-40ea-b437-503c708f55d6.png)\r\n### `split_every=None`\r\n![mydask](https://user-images.githubusercontent.com/3309802/187822522-df288e83-65d1-4a2c-a858-099588aa93a0.png)\r\n\r\nThe problem is that this doesn't overlap communication and computation well when you have large numbers of partitions in a distributed cluster.\r\n1. The final task can't be scheduled until every input is done. **This means none of the transfers can start until every input is already done.**\r\n2. The final task has to transfer lots of individual keys from many different workers. Workers have limits on how many other workers they're allowed to talk to at once (and how much data they're allowed to gather at once). Trying to fetch 1k or 10k dependencies as input to a single task could be quite slow, even if each input is very small, especially when there are many workers.\r\n\r\nWhereas with a tree reduction, you can start reducing before all the inputs are done (overlapping communication and computation), and avoid the massive all-to-one transfers.\r\n\r\nSo I'm wondering if we should change the `split_every=False` default for reductions like `sum`, `mean`, etc. Perhaps `None` (to use the default), or perhaps something higher (16? 32?) to recognize that the pieces of data being transferred are small, so we can combine more of them at once and have a smaller graph.\r\n\r\ncc @jrbourbeau @ian-r-rose @jsignell @rjzamora",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/9450/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/9450/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}