{
    "url": "https://api.github.com/repos/dask/dask/issues/5373",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/5373/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/5373/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/5373/events",
    "html_url": "https://github.com/dask/dask/issues/5373",
    "id": 490767191,
    "node_id": "MDU6SXNzdWU0OTA3NjcxOTE=",
    "number": 5373,
    "title": "Cholesky fails for sparse matrices",
    "user": {
        "login": "TomMaullin",
        "id": 22241320,
        "node_id": "MDQ6VXNlcjIyMjQxMzIw",
        "avatar_url": "https://avatars.githubusercontent.com/u/22241320?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/TomMaullin",
        "html_url": "https://github.com/TomMaullin",
        "followers_url": "https://api.github.com/users/TomMaullin/followers",
        "following_url": "https://api.github.com/users/TomMaullin/following{/other_user}",
        "gists_url": "https://api.github.com/users/TomMaullin/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/TomMaullin/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/TomMaullin/subscriptions",
        "organizations_url": "https://api.github.com/users/TomMaullin/orgs",
        "repos_url": "https://api.github.com/users/TomMaullin/repos",
        "events_url": "https://api.github.com/users/TomMaullin/events{/privacy}",
        "received_events_url": "https://api.github.com/users/TomMaullin/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862305,
            "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=",
            "url": "https://api.github.com/repos/dask/dask/labels/array",
            "name": "array",
            "color": "006b75",
            "default": false,
            "description": null
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 9,
    "created_at": "2019-09-08T15:22:49Z",
    "updated_at": "2022-01-12T16:15:35Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "Hi I am trying to run a cholesky decomposition on a Sparse matrix like so:\r\n\r\n```\r\n# Make a random positive definite sparse matrix in numpy\r\nX = np.random.randn(100,100)\r\nX[X<1.7]=0\r\nX = X + np.eye(100)\r\nXtX = np.matmul(X.transpose(), X)\r\n\r\n# Map it to a dask sparse matrix\r\nXtX_da = da.from_array(XtX, chunks=(10, 10)).map_blocks(sparse.COO).rechunk('auto')\r\n\r\n# Perform cholesky decomposition\r\nL_da_chol = da.linalg.cholesky(XtX_da).compute()\r\n```\r\n\r\nBut I get the following error:\r\n\r\n```\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-23-8ac43cb2d1f0> in <module>()\r\n     66 \r\n     67     t1 = time.time()\r\n---> 68     L_da_chol = da.linalg.cholesky(XtX_da).compute()\r\n     69     t2 = time.time()\r\n     70     daptime=t2-t1\r\n\r\n14 frames\r\n/usr/local/lib/python3.6/dist-packages/dask/base.py in compute(self, **kwargs)\r\n    154         dask.base.compute\r\n    155         \"\"\"\r\n--> 156         (result,) = compute(self, traverse=False, **kwargs)\r\n    157         return result\r\n    158 \r\n\r\n/usr/local/lib/python3.6/dist-packages/dask/base.py in compute(*args, **kwargs)\r\n    396     keys = [x.__dask_keys__() for x in collections]\r\n    397     postcomputes = [x.__dask_postcompute__() for x in collections]\r\n--> 398     results = schedule(dsk, keys, **kwargs)\r\n    399     return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\r\n    400 \r\n\r\n/usr/local/lib/python3.6/dist-packages/dask/threaded.py in get(dsk, result, cache, num_workers, pool, **kwargs)\r\n     74     results = get_async(pool.apply_async, len(pool._pool), dsk, result,\r\n     75                         cache=cache, get_id=_thread_get_id,\r\n---> 76                         pack_exception=pack_exception, **kwargs)\r\n     77 \r\n     78     # Cleanup pools associated to dead threads\r\n\r\n/usr/local/lib/python3.6/dist-packages/dask/local.py in get_async(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\r\n    460                         _execute_task(task, data)  # Re-execute locally\r\n    461                     else:\r\n--> 462                         raise_exception(exc, tb)\r\n    463                 res, worker_id = loads(res_info)\r\n    464                 state['cache'][key] = res\r\n\r\n/usr/local/lib/python3.6/dist-packages/dask/compatibility.py in reraise(exc, tb)\r\n    110         if exc.__traceback__ is not tb:\r\n    111             raise exc.with_traceback(tb)\r\n--> 112         raise exc\r\n    113 \r\n    114     import pickle as cPickle\r\n\r\n/usr/local/lib/python3.6/dist-packages/dask/local.py in execute_task(key, task_info, dumps, loads, get_id, pack_exception)\r\n    228     try:\r\n    229         task, data = loads(task_info)\r\n--> 230         result = _execute_task(task, data)\r\n    231         id = get_id()\r\n    232         result = dumps((result, id))\r\n\r\n/usr/local/lib/python3.6/dist-packages/dask/core.py in _execute_task(arg, cache, dsk)\r\n    116     elif istask(arg):\r\n    117         func, args = arg[0], arg[1:]\r\n--> 118         args2 = [_execute_task(a, cache) for a in args]\r\n    119         return func(*args2)\r\n    120     elif not ishashable(arg):\r\n\r\n/usr/local/lib/python3.6/dist-packages/dask/core.py in <listcomp>(.0)\r\n    116     elif istask(arg):\r\n    117         func, args = arg[0], arg[1:]\r\n--> 118         args2 = [_execute_task(a, cache) for a in args]\r\n    119         return func(*args2)\r\n    120     elif not ishashable(arg):\r\n\r\n/usr/local/lib/python3.6/dist-packages/dask/core.py in _execute_task(arg, cache, dsk)\r\n    117         func, args = arg[0], arg[1:]\r\n    118         args2 = [_execute_task(a, cache) for a in args]\r\n--> 119         return func(*args2)\r\n    120     elif not ishashable(arg):\r\n    121         return arg\r\n\r\n/usr/local/lib/python3.6/dist-packages/dask/array/linalg.py in _cholesky_lower(a)\r\n    940 def _cholesky_lower(a):\r\n    941     import scipy.linalg\r\n--> 942     return scipy.linalg.cholesky(a, lower=True)\r\n    943 \r\n    944 \r\n\r\n/usr/local/lib/python3.6/dist-packages/scipy/linalg/decomp_cholesky.py in cholesky(a, lower, overwrite_a, check_finite)\r\n     89     \"\"\"\r\n     90     c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\r\n---> 91                          check_finite=check_finite)\r\n     92     return c\r\n     93 \r\n\r\n/usr/local/lib/python3.6/dist-packages/scipy/linalg/decomp_cholesky.py in _cholesky(a, lower, overwrite_a, clean, check_finite)\r\n     17     \"\"\"Common code for cholesky() and cho_factor().\"\"\"\r\n     18 \r\n---> 19     a1 = asarray_chkfinite(a) if check_finite else asarray(a)\r\n     20     a1 = atleast_2d(a1)\r\n     21 \r\n\r\n/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py in asarray_chkfinite(a, dtype, order)\r\n    493 \r\n    494     \"\"\"\r\n--> 495     a = asarray(a, dtype=dtype, order=order)\r\n    496     if a.dtype.char in typecodes['AllFloat'] and not np.isfinite(a).all():\r\n    497         raise ValueError(\r\n\r\n/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py in asarray(a, dtype, order)\r\n    536 \r\n    537     \"\"\"\r\n--> 538     return array(a, dtype, copy=False, order=order)\r\n    539 \r\n    540 \r\n\r\n/usr/local/lib/python3.6/dist-packages/sparse/_sparse_array.py in __array__(self, **kwargs)\r\n    210         from ._settings import AUTO_DENSIFY\r\n    211         if not AUTO_DENSIFY:\r\n--> 212             raise RuntimeError('Cannot convert a sparse array to dense automatically. '\r\n    213                                'To manually densify, use the todense method.')\r\n    214 \r\n\r\nRuntimeError: Cannot convert a sparse array to dense automatically. To manually densify, use the todense method.\r\n```\r\n\r\nThis was run on a CPU in a google colab notebook; any help on resolving this would be greatly appreciated... ideally I'm hoping to find a solution that at least allows some of the computation to be done using sparse operations as time efficiency is a big factor in what I am working on (the above is a toy example... my actual work uses much larger matrices).",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/5373/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/5373/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}