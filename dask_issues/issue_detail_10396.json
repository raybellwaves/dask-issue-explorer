{
    "url": "https://api.github.com/repos/dask/dask/issues/10396",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/10396/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/10396/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/10396/events",
    "html_url": "https://github.com/dask/dask/issues/10396",
    "id": 1786562134,
    "node_id": "I_kwDOAbcwm85qfMZW",
    "number": 10396,
    "title": "Cache is not thread safe",
    "user": {
        "login": "andy-sweet",
        "id": 2608297,
        "node_id": "MDQ6VXNlcjI2MDgyOTc=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2608297?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/andy-sweet",
        "html_url": "https://github.com/andy-sweet",
        "followers_url": "https://api.github.com/users/andy-sweet/followers",
        "following_url": "https://api.github.com/users/andy-sweet/following{/other_user}",
        "gists_url": "https://api.github.com/users/andy-sweet/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/andy-sweet/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/andy-sweet/subscriptions",
        "organizations_url": "https://api.github.com/users/andy-sweet/orgs",
        "repos_url": "https://api.github.com/users/andy-sweet/repos",
        "events_url": "https://api.github.com/users/andy-sweet/events{/privacy}",
        "received_events_url": "https://api.github.com/users/andy-sweet/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 3468123446,
            "node_id": "LA_kwDOAbcwm87Ot102",
            "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention",
            "name": "needs attention",
            "color": "6d626c",
            "default": false,
            "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."
        },
        {
            "id": 3880424463,
            "node_id": "LA_kwDOAbcwm87nSpQP",
            "url": "https://api.github.com/repos/dask/dask/labels/needs%20triage",
            "name": "needs triage",
            "color": "eeeeee",
            "default": false,
            "description": "Needs a response from a contributor"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-07-03T17:22:25Z",
    "updated_at": "2023-08-14T01:44:48Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "**Describe the issue**:\r\n\r\nComputing any dask graphs while using the same cache on multiple threads can cause errors.\r\n\r\nThis has been previously reported in a variety of issues (e.g. https://github.com/dask/dask/issues/896, https://github.com/dask/distributed/issues/2372, https://github.com/napari/napari/issues/5591, https://github.com/haesleinhuepf/napari-time-slicer/pull/6), but I wrote a new issue with a reproducer to clarify one underlying cause.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\nThe following Python code should always raise an exception on the non-main thread.\r\n\r\n```python\r\nimport numpy as np\r\nimport dask.array as da\r\nfrom dask.cache import Cache\r\nfrom threading import Condition, RLock, Thread\r\n\r\n# Extend the regular cache so that we block execution in the _posttask callback\r\nclass BlockingCache(Cache):\r\n    def __init__(self, cache):\r\n        super().__init__(cache)\r\n        self.task_finished = Condition()\r\n        self.posttask_lock = RLock()\r\n\r\n    def _posttask(self, key, value, dsk, state, id):\r\n        with self.task_finished:\r\n            self.task_finished.notify()\r\n        with self.posttask_lock:\r\n            super()._posttask(key, value, dsk, state, id)\r\n\r\n\r\ndef cached_array_index(cache, array, index):\r\n    with cache:\r\n        return array[index].compute()\r\n\r\n\r\ndef test_multithreaded_access():\r\n    array = da.from_array([0, 1])\r\n    # Cache size is irrelevant because we don't need it here.\r\n    cache = BlockingCache(1)\r\n    thread = Thread(target=cached_array_index, args=(cache, array, 0))\r\n    # Hold the posttask_lock to prevent the other thread from\r\n    # executing the actual cache's _posttask callback.\r\n    with cache.posttask_lock:\r\n        with cache.task_finished:\r\n            thread.start()\r\n            # Wait for the other thread to reach _posttask.\r\n            cache.task_finished.wait()\r\n        # Execute the whole graph on the main thread.\r\n        cached_array_index(cache, array, 1)\r\n    # Wait for the other thread to finish executing.\r\n    thread.join()\r\n\r\nif __name__ == '__main__':\r\n    test_multithreaded_access()\r\n```\r\n\r\nHere is the error I get on my local machine.\r\n\r\n```\r\nException in thread Thread-1:\r\nTraceback (most recent call last):\r\n  File \"/Users/asweet/software/miniconda3/envs/napari-cryoet-data-portal-dev/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\r\n    self.run()\r\n  File \"/Users/asweet/software/miniconda3/envs/napari-cryoet-data-portal-dev/lib/python3.9/threading.py\", line 917, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/Users/asweet/data/bugs/5591/simplified_dask.py\", line 23, in cached_array_index\r\n    return array[index].compute()\r\n  File \"/Users/asweet/software/miniconda3/envs/napari-cryoet-data-portal-dev/lib/python3.9/site-packages/dask/base.py\", line 310, in compute\r\n    (result,) = compute(self, traverse=False, **kwargs)\r\n  File \"/Users/asweet/software/miniconda3/envs/napari-cryoet-data-portal-dev/lib/python3.9/site-packages/dask/base.py\", line 595, in compute\r\n    results = schedule(dsk, keys, **kwargs)\r\n  File \"/Users/asweet/software/miniconda3/envs/napari-cryoet-data-portal-dev/lib/python3.9/site-packages/dask/threaded.py\", line 89, in get\r\n    results = get_async(\r\n  File \"/Users/asweet/software/miniconda3/envs/napari-cryoet-data-portal-dev/lib/python3.9/site-packages/dask/local.py\", line 516, in get_async\r\n    f(key, res, dsk, state, worker_id)\r\n  File \"/Users/asweet/data/bugs/5591/simplified_dask.py\", line 18, in _posttask\r\n    super()._posttask(key, value, dsk, state, id)\r\n  File \"/Users/asweet/software/miniconda3/envs/napari-cryoet-data-portal-dev/lib/python3.9/site-packages/dask/cache.py\", line 58, in _posttask\r\n    duration = default_timer() - self.starttimes[key]\r\nKeyError: ('getitem-8d24cd8febbf60810a2497062186234f',)\r\n```\r\n\r\nI also [created a diagram to show what's happening here](https://github.com/andy-sweet/napari-diagrams/blob/main/dask-cache-multithread-error.drawio.svg).\r\n\r\nNote that in this case, the tasks are different, but that doesn't matter since `Cache._finish` clears `Cache.starttimes`. There is another more interesting variant of this bug where the cache actually gets used.\r\n\r\n```python\r\ndef test_multithreaded_access_same_key():\r\n    array = da.from_array([0, 1])\r\n    # Cache is not big enough to store even one result, so each\r\n    # array access will cause a task to be executed.\r\n    cache = BlockingCache(1)\r\n    thread = Thread(target=cached_array_index, args=(cache, array, 0))\r\n    with cache.posttask_lock:\r\n        with cache.task_finished:\r\n            thread.start()\r\n            cache.task_finished.wait()\r\n        cached_array_index(cache, array, 0)\r\n    thread.join()\r\n```\r\n\r\nAny fix here should probably fix both of these tests as a minimum.\r\n\r\n**Anything else we need to know?**:\r\n\r\nI'm mostly coming here from napari (https://github.com/napari/napari/pull/5610). Based on comments from the related issues, it sounds like there was no intent to make `Cache` thread safe and there may not be much motivation to make it thread safe in the future. I think that's fine, but hope this issue is still hopeful for others running into the same issue.\r\n\r\nOne potential fix is to change the implementation of `Cache._posttask` and `Cache._finish` to be the following.\r\n\r\n```python\r\n    def _posttask(self, key, value, dsk, state, id):\r\n        if starttime := self.starttimes.pop(key, None):\r\n            duration = default_timer() - starttime\r\n            if deps := state[\"dependencies\"][key]:\r\n                duration += max(self.durations.get(k, 0) for k in deps)\r\n            self.durations[key] = duration\r\n            nb = self._nbytes(value) + overhead + sys.getsizeof(key) * 4\r\n            self.cache.put(key, value, cost=duration / nb / 1e9, nbytes=nb)\r\n\r\n    def _finish(self, dsk, state, errored):\r\n        self.durations.clear()\r\n```\r\n\r\nThis fixes the tests above and seems to make some vague sense to me (i.e. don't update the cache when a stale task finishes), but I don't know enough about dask to state that with much certainty.\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2023.6.1\r\n- Python version: Python 3.9.6\r\n- Operating System: macOS 13.4 (Intel)\r\n- Install method (conda, pip, source): pip",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/10396/reactions",
        "total_count": 2,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 1,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/10396/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}