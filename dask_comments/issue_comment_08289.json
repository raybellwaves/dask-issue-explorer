[
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/960072876",
        "html_url": "https://github.com/dask/dask/issues/8289#issuecomment-960072876",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/8289",
        "id": 960072876,
        "node_id": "IC_kwDOAbcwm845OYys",
        "user": {
            "login": "jsignell",
            "id": 4806877,
            "node_id": "MDQ6VXNlcjQ4MDY4Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4806877?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jsignell",
            "html_url": "https://github.com/jsignell",
            "followers_url": "https://api.github.com/users/jsignell/followers",
            "following_url": "https://api.github.com/users/jsignell/following{/other_user}",
            "gists_url": "https://api.github.com/users/jsignell/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jsignell/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jsignell/subscriptions",
            "organizations_url": "https://api.github.com/users/jsignell/orgs",
            "repos_url": "https://api.github.com/users/jsignell/repos",
            "events_url": "https://api.github.com/users/jsignell/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jsignell/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-11-03T21:09:19Z",
        "updated_at": "2021-11-03T21:09:19Z",
        "author_association": "MEMBER",
        "body": "Sorry for the slow response. That seems like a reasonable proposal to me. I think it would be slightly better if `blocksize` could be expanded in scope to read in several files at a time if the first file that it reads is very small. But I can get how that might be hard to achieve.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/960072876/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/960139782",
        "html_url": "https://github.com/dask/dask/issues/8289#issuecomment-960139782",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/8289",
        "id": 960139782,
        "node_id": "IC_kwDOAbcwm845OpIG",
        "user": {
            "login": "jrbourbeau",
            "id": 11656932,
            "node_id": "MDQ6VXNlcjExNjU2OTMy",
            "avatar_url": "https://avatars.githubusercontent.com/u/11656932?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jrbourbeau",
            "html_url": "https://github.com/jrbourbeau",
            "followers_url": "https://api.github.com/users/jrbourbeau/followers",
            "following_url": "https://api.github.com/users/jrbourbeau/following{/other_user}",
            "gists_url": "https://api.github.com/users/jrbourbeau/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jrbourbeau/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jrbourbeau/subscriptions",
            "organizations_url": "https://api.github.com/users/jrbourbeau/orgs",
            "repos_url": "https://api.github.com/users/jrbourbeau/repos",
            "events_url": "https://api.github.com/users/jrbourbeau/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jrbourbeau/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-11-03T21:41:51Z",
        "updated_at": "2021-11-03T21:41:51Z",
        "author_association": "MEMBER",
        "body": "@y-he2 what version of `dask` are you using? Are you using the `distributed` scheduler? I would expect more recent versions of `dask` (which include https://github.com/dask/dask/pull/7415) to be more efficient when constructing / serializing the underlying task graph (cc @rjzamora for visibility) ",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/960139782/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/960611941",
        "html_url": "https://github.com/dask/dask/issues/8289#issuecomment-960611941",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/8289",
        "id": 960611941,
        "node_id": "IC_kwDOAbcwm845QcZl",
        "user": {
            "login": "y-he2",
            "id": 62895281,
            "node_id": "MDQ6VXNlcjYyODk1Mjgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/62895281?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/y-he2",
            "html_url": "https://github.com/y-he2",
            "followers_url": "https://api.github.com/users/y-he2/followers",
            "following_url": "https://api.github.com/users/y-he2/following{/other_user}",
            "gists_url": "https://api.github.com/users/y-he2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/y-he2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/y-he2/subscriptions",
            "organizations_url": "https://api.github.com/users/y-he2/orgs",
            "repos_url": "https://api.github.com/users/y-he2/repos",
            "events_url": "https://api.github.com/users/y-he2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/y-he2/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-11-04T10:03:50Z",
        "updated_at": "2021-11-04T10:03:50Z",
        "author_association": "NONE",
        "body": "Thanks for the reply and no worries with the delay. I think I might have entangled a few problems in my OPs and caused some confusion. Although regardless I still think being able to efficiently merge files during read could ease up the graph construction, if its possible and, not end up just like some implicit repartitions calls. \r\n\r\nRegarding the graph construction performance and size, firstly its Dask Distributed btw, maybe I should have opened the issue in Distributed instead? Not sure what are the thumb rules for issues here sry.\r\nAnyway I think I was using the newest version during the time: \r\n```\r\n'packages': {'python': '3.8.5.final.0',\r\n    'dask': '2021.09.1',\r\n    'distributed': '2021.09.1',\r\n    'msgpack': '1.0.2',\r\n    'cloudpickle': '2.0.0',\r\n    'tornado': '6.1',\r\n    'toolz': '0.11.1',\r\n    'numpy': '1.21.2',\r\n    'pandas': '1.3.3',\r\n    'lz4': None,\r\n    'blosc': None}},\r\n```\r\nbut as said, I could have mixed in a few more problems like #8290 when talked about the graph problems, I will try to produce a MRE and maybe breakdown the problem further in the linked issue. \r\n\r\nSo I would like us to just focus on the merge files when read_csv part of my OP, as Im not sure how Dask Distributed handle 20k small files, if it still make sense lets keep the discussion going, otherwise we could prob close it. ",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/960611941/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1010181706",
        "html_url": "https://github.com/dask/dask/issues/8289#issuecomment-1010181706",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/8289",
        "id": 1010181706,
        "node_id": "IC_kwDOAbcwm848NiZK",
        "user": {
            "login": "y-he2",
            "id": 62895281,
            "node_id": "MDQ6VXNlcjYyODk1Mjgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/62895281?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/y-he2",
            "html_url": "https://github.com/y-he2",
            "followers_url": "https://api.github.com/users/y-he2/followers",
            "following_url": "https://api.github.com/users/y-he2/following{/other_user}",
            "gists_url": "https://api.github.com/users/y-he2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/y-he2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/y-he2/subscriptions",
            "organizations_url": "https://api.github.com/users/y-he2/orgs",
            "repos_url": "https://api.github.com/users/y-he2/repos",
            "events_url": "https://api.github.com/users/y-he2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/y-he2/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-01-11T17:13:54Z",
        "updated_at": "2022-01-11T17:13:54Z",
        "author_association": "NONE",
        "body": "At the moment Im a bit more confident that this function is worthy to implement. As I happened to refactored my solution and did a preprocessing on those 20k files, baked in some massively parallel operations, indexing, and most importantly, bundled together the files into roughly 100M partitions, and cached. \r\n\r\nIf my observation was correct, this refactoring, gave at least 20x speedup for whatever task I was computing, which was from almost 24hrs to 1hr. \r\n\r\nAlthough I did added some other data structure memory optimization (flatten out arrays to DataFrame columns instead), which is possible happen to be where the speedup resides. However I do believe that it was the pre-repartitioning and cache that allowed Dask scheduler to do a much better job. \r\n\r\nSo I could abandon my suspicion that #8290 was causing the slow down of the scheduler, and instead of pinpoint the core to this issue. ",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1010181706/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1057798944",
        "html_url": "https://github.com/dask/dask/issues/8289#issuecomment-1057798944",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/8289",
        "id": 1057798944,
        "node_id": "IC_kwDOAbcwm84_DLsg",
        "user": {
            "login": "y-he2",
            "id": 62895281,
            "node_id": "MDQ6VXNlcjYyODk1Mjgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/62895281?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/y-he2",
            "html_url": "https://github.com/y-he2",
            "followers_url": "https://api.github.com/users/y-he2/followers",
            "following_url": "https://api.github.com/users/y-he2/following{/other_user}",
            "gists_url": "https://api.github.com/users/y-he2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/y-he2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/y-he2/subscriptions",
            "organizations_url": "https://api.github.com/users/y-he2/orgs",
            "repos_url": "https://api.github.com/users/y-he2/repos",
            "events_url": "https://api.github.com/users/y-he2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/y-he2/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-03T08:30:48Z",
        "updated_at": "2022-03-03T08:30:48Z",
        "author_association": "NONE",
        "body": "Closed #8290 which makes this feature request even more crucial. ",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1057798944/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]