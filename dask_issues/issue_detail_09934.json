{
    "url": "https://api.github.com/repos/dask/dask/issues/9934",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/9934/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/9934/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/9934/events",
    "html_url": "https://github.com/dask/dask/issues/9934",
    "id": 1578298060,
    "node_id": "I_kwDOAbcwm85eEurM",
    "number": 9934,
    "title": "`dask.array.linalg.svd` leaks memory for large dataset",
    "user": {
        "login": "cgahr",
        "id": 26804763,
        "node_id": "MDQ6VXNlcjI2ODA0NzYz",
        "avatar_url": "https://avatars.githubusercontent.com/u/26804763?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/cgahr",
        "html_url": "https://github.com/cgahr",
        "followers_url": "https://api.github.com/users/cgahr/followers",
        "following_url": "https://api.github.com/users/cgahr/following{/other_user}",
        "gists_url": "https://api.github.com/users/cgahr/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/cgahr/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/cgahr/subscriptions",
        "organizations_url": "https://api.github.com/users/cgahr/orgs",
        "repos_url": "https://api.github.com/users/cgahr/repos",
        "events_url": "https://api.github.com/users/cgahr/events{/privacy}",
        "received_events_url": "https://api.github.com/users/cgahr/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862305,
            "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=",
            "url": "https://api.github.com/repos/dask/dask/labels/array",
            "name": "array",
            "color": "006b75",
            "default": false,
            "description": null
        },
        {
            "id": 3468123446,
            "node_id": "LA_kwDOAbcwm87Ot102",
            "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention",
            "name": "needs attention",
            "color": "6d626c",
            "default": false,
            "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2023-02-09T17:24:40Z",
    "updated_at": "2023-02-14T20:40:44Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "**Describe the issue**:\r\nI have a test dataset (~6GB) with 4 dimensions `{'time': 2000, 'field': 3, 'x': 512, 'y': 512}`. I load the dataset with `(42, 3, 512, 512)` [~126MB] chunks (i.e. I only chunk in the time direction). \r\n\r\nAs a first step, I flatten the data along the `('field', 'x', 'y')` axes into an array with `{'time': 2000, 'dims': 786432}` with chunks `(42, 786432)` [~126MB]. \r\n\r\nOn this array, I run `_, s, basis = dask.linalg.svd(data)` to get the singular values and right singular vectors, ie. `s.shape = (2000,)`, `basis.shape = (2000, 786432)`. Of the basis, I want the 100 first elements, ie. `basis[:100].shape = (100, 786432)`.\r\n\r\nWhen I call `dask.compute()` I get the following warning:\r\n```\r\ndistributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory\r\nmay not be released to the OS; see \r\nhttps://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. \r\n-- Unmanaged memory: 27.61 GiB \r\n-- Worker memory limit: 37.66 GiB\r\n```\r\n\r\nIt seems like this should not happen if my dataset is only 6GBs and my chunk only ~126MB.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\nUnfortunately, I cannot share my dataset, it is too large. However, you can reproduce the problem as follows:\r\n\r\n1. imports:\r\n```python\r\nimport numpy as np\r\n\r\nimport dask\r\nfrom dask.distributed import Client\r\nimport xarray as xr\r\n```\r\n2. start client:\r\n```python\r\nclient = Client()\r\n```\r\n4. create dataset (using `xarray`):\r\n```python\r\nrng = np.random.default_rng()\r\ndata = rng.normal(0, 1, (2000, 500000))\r\narr = xr.DataArray(\r\n    data, \r\n    dims=('time', 'dims'), \r\n    coords={'time': np.arange(data.shape[0]), 'dims': np.arange(data.shape[1])}\r\n)\r\narr.name = 'data'\r\n\r\narr.to_netcdf('dask_9934.h5')\r\n```\r\n5. load data using `xarray`. This is done lazily:\r\n```python\r\nfh = xr.open_dataset('dask_9934.h5', chunks={'time': 'auto', 'dims': -1})\r\nX = fh['data']\r\n```\r\n\r\n6. compute svd using dask:\r\n```python\r\n_, s, v = dask.array.linalg.svd(X.data)\r\nbasis, singular_values = dask.compute(v[:100], s)\r\n```\r\n7. compute svd using xarray using dask:\r\n```python\r\n_, s, v = xr.apply_ufunc(\r\n    dask.array.linalg.svd,\r\n    X,\r\n    input_core_dims=[('time', \"dims\")],\r\n    output_core_dims=[('time', \"r\"), (\"r\",), (\"r\", \"dims\")],\r\n    dask=\"allowed\",\r\n)\r\nbasis, singular_values = dask.compute(v[:100], s)\r\n```\r\n\r\nBoth steps 4 and 5 throw a memory warning and leak memory to disk.\r\n\r\n**Environment**:\r\n\r\n- Dask version: '2023.1.0'\r\n- Python version: Python 3.10.8\r\n- Operating System: some linux (code is run on a compute node)\r\n- Install method (conda, pip, source): conda\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/9934/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/9934/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}