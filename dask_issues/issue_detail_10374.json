{
    "url": "https://api.github.com/repos/dask/dask/issues/10374",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/10374/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/10374/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/10374/events",
    "html_url": "https://github.com/dask/dask/issues/10374",
    "id": 1775461005,
    "node_id": "I_kwDOAbcwm85p02KN",
    "number": 10374,
    "title": "Support drop_duplicates(subset=...)",
    "user": {
        "login": "mrocklin",
        "id": 306380,
        "node_id": "MDQ6VXNlcjMwNjM4MA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mrocklin",
        "html_url": "https://github.com/mrocklin",
        "followers_url": "https://api.github.com/users/mrocklin/followers",
        "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
        "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
        "organizations_url": "https://api.github.com/users/mrocklin/orgs",
        "repos_url": "https://api.github.com/users/mrocklin/repos",
        "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
        "received_events_url": "https://api.github.com/users/mrocklin/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        },
        {
            "id": 3468123446,
            "node_id": "LA_kwDOAbcwm87Ot102",
            "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention",
            "name": "needs attention",
            "color": "6d626c",
            "default": false,
            "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."
        },
        {
            "id": 3798450420,
            "node_id": "LA_kwDOAbcwm87iZ8D0",
            "url": "https://api.github.com/repos/dask/dask/labels/feature",
            "name": "feature",
            "color": "b0f0fa",
            "default": false,
            "description": "Something is missing"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-06-26T19:36:21Z",
    "updated_at": "2024-01-29T01:45:03Z",
    "closed_at": null,
    "author_association": "MEMBER",
    "active_lock_reason": null,
    "body": "(This is a little ramble-y.  Sorry.)\r\n\r\nProbably we could make drop_duplicates more scalable in the case where folks subset on columns.  We would still probably have to fit information about every row for the relevant columns in memory, but this is quite different from reducing the entire dataset (all columns) to a single partition. \r\n\r\nMy thinking is that for each value of the subsetted columns we want to know that only a single partition will hold onto that value.  One way to do this would be to build up a mapping of value to partition number like the following:\r\n\r\n```python\r\ndf.drop_duplicates(subset=[\"id\"])\r\n```\r\n```python\r\n{ \r\n    (100,): 3,\r\n    (101,): 0,\r\n    (102,): 5,\r\n    ...\r\n}\r\n```\r\n\r\nWhere the keys are values and the values are the partition index in which they should be allowed.  Building this mapping requires a full reduction of this column to a single dataframe (or we could split things up if we wanted to I guess, similar to split_out).  Actually that could probably be a pandas DataFrame with a multi-index?.\r\n\r\nThen we would need to broadcast that data out to all of the partitions again.  ",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/10374/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/10374/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}