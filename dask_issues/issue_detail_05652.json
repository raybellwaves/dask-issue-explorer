{
    "url": "https://api.github.com/repos/dask/dask/issues/5652",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/5652/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/5652/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/5652/events",
    "html_url": "https://github.com/dask/dask/issues/5652",
    "id": 530481024,
    "node_id": "MDU6SXNzdWU1MzA0ODEwMjQ=",
    "number": 5652,
    "title": "KeyErrors in scheduler with large dataset and sklearn",
    "user": {
        "login": "kaptravis",
        "id": 35045516,
        "node_id": "MDQ6VXNlcjM1MDQ1NTE2",
        "avatar_url": "https://avatars.githubusercontent.com/u/35045516?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/kaptravis",
        "html_url": "https://github.com/kaptravis",
        "followers_url": "https://api.github.com/users/kaptravis/followers",
        "following_url": "https://api.github.com/users/kaptravis/following{/other_user}",
        "gists_url": "https://api.github.com/users/kaptravis/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/kaptravis/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/kaptravis/subscriptions",
        "organizations_url": "https://api.github.com/users/kaptravis/orgs",
        "repos_url": "https://api.github.com/users/kaptravis/repos",
        "events_url": "https://api.github.com/users/kaptravis/events{/privacy}",
        "received_events_url": "https://api.github.com/users/kaptravis/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 4,
    "created_at": "2019-11-29T20:29:38Z",
    "updated_at": "2019-12-17T15:21:26Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "I am running ElasticNetCV.fit() in parallel using Dask client.submit, and continue to see KeyErrors in the scheduler. I'm not sure if this is a problem, but it seems to be for large datasets. The fits finish despite the errors on smaller datasets, but with with higher NxP and default tolerance, I have yet to see the fit complete. On a single box using pandas/sklearn, it always completes. \r\n\r\nNote that my call to client.submit includes an int parameter that isn't used in the process method. Without it, I would only see one instance of process() running, even though the results would include 2 models\r\n\r\nThe errors:\r\n\r\n```\r\ndistributed.scheduler - ERROR - 'ndarray-e2403ddc588fc5516afcb36223c43bf3'\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/distributed/scheduler.py\", line 1753, in update_graph\r\n    resources=resources,\r\n  File \"/opt/conda/lib/python3.7/site-packages/distributed/diagnostics/graph_layout.py\", line 48, in update_graph\r\n    deps = dependencies[key]\r\nKeyError: 'ndarray-e2403ddc588fc5516afcb36223c43bf3'\r\n\r\ndistributed.scheduler - INFO - Plugin failed with exception\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/distributed/scheduler.py\", line 4359, in transition\r\n    plugin.transition(key, start, finish2, *args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/distributed/diagnostics/graph_layout.py\", line 91, in transition\r\n    self.state_updates.append((self.index[key], finish))\r\nKeyError: '_path_residuals-batch-923e2deb56564bd2923f7337cdffc9fb'\r\n```\r\n\r\n...errors repeat\r\n\r\nExample code. On my test cluster of 2x96 cores, it completes, but logs the above errors.\r\n```\r\nimport numpy as np\r\nimport dask.array as da\r\nfrom dask.distributed import Client\r\nfrom sklearn import linear_model\r\nfrom joblib import parallel_backend\r\nfrom dask_glm.utils import make_y\r\n\r\nclient = Client(<scheduler>)\r\n    \r\nN = 200000\r\nP = 10000\r\nchunks = 3e3\r\n    \r\nbeta = (np.random.random(P) - 0.5) * 3 \r\nX = da.random.random((N,len(beta)), chunks=(chunks,P))\r\ny = make_y(X, beta=np.array(beta), chunks=chunks)\r\n   \r\ndef process(x, y, i):\r\n    enet = linear_model.ElasticNetCV(fit_intercept=True, tol=0.5, normalize=True, n_jobs=-1, max_iter=50000, selection='random')\r\n\r\n    with parallel_backend('dask'):\r\n        enet.fit(x, y)\r\n    return enet\r\n\r\nresults = [client.submit(process, X, y, i) for i in range(2)]\r\nclient.gather(results)\r\n```\r\n\r\n\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/5652/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/5652/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}