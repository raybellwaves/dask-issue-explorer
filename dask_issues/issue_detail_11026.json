{
    "url": "https://api.github.com/repos/dask/dask/issues/11026",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/11026/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/11026/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/11026/events",
    "html_url": "https://github.com/dask/dask/issues/11026",
    "id": 2209247883,
    "node_id": "I_kwDOAbcwm86DrnKL",
    "number": 11026,
    "title": "Poor scheduling with `flox`, leading to high memory usage and eventual failure",
    "user": {
        "login": "ivirshup",
        "id": 8238804,
        "node_id": "MDQ6VXNlcjgyMzg4MDQ=",
        "avatar_url": "https://avatars.githubusercontent.com/u/8238804?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ivirshup",
        "html_url": "https://github.com/ivirshup",
        "followers_url": "https://api.github.com/users/ivirshup/followers",
        "following_url": "https://api.github.com/users/ivirshup/following{/other_user}",
        "gists_url": "https://api.github.com/users/ivirshup/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/ivirshup/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/ivirshup/subscriptions",
        "organizations_url": "https://api.github.com/users/ivirshup/orgs",
        "repos_url": "https://api.github.com/users/ivirshup/repos",
        "events_url": "https://api.github.com/users/ivirshup/events{/privacy}",
        "received_events_url": "https://api.github.com/users/ivirshup/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 3880424463,
            "node_id": "LA_kwDOAbcwm87nSpQP",
            "url": "https://api.github.com/repos/dask/dask/labels/needs%20triage",
            "name": "needs triage",
            "color": "eeeeee",
            "default": false,
            "description": "Needs a response from a contributor"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 13,
    "created_at": "2024-03-26T20:26:49Z",
    "updated_at": "2024-06-06T15:36:19Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**Describe the issue**:\r\n\r\nWhen performing aggregation with flox, I quickly run out of memory, regardless of the size of a chunk.\r\n\r\nIt appears that lower nodes (loading data) keep getting run while higher nodes (reduction) sit un-computed.\r\n\r\nOpening here as requested in:\r\n\r\n* https://github.com/xarray-contrib/flox/issues/346\r\n\r\ncc: @dcherian \r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport dask.distributed as dd\r\nimport dask.array as da\r\nimport numpy as np\r\nimport flox\r\n\r\ncluster = dd.LocalCluster(n_workers=3)\r\nclient = dd.Client(cluster)\r\n\r\nM, N = 1_000_000, 20_000\r\n\r\n# Note that it doesn't seem to matter where X comes from.\r\n# In my real-world use case, it is either generated from `map_blocks` or \r\n# read directly from a zarr store\r\nX = da.random.normal(size=(M, N), chunks=(5_000, N))\r\nby = np.random.choice(2_000, size=M)\r\n\r\nres, codes = flox.groupby_reduce(\r\n    X.T,\r\n    by,\r\n    func=\"sum\",\r\n    fill_value=0,\r\n    method=\"map-reduce\",\r\n    reindex=True,\r\n)\r\n\r\nres_comp = res.compute()\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\n\r\n<details>\r\n<summary> As an example, here's how my task graph completes if I run `X.sum(axis=0).compute()` </summary>\r\n\r\n<img width=\"500\" alt=\"image\" src=\"https://github.com/dask/dask/assets/8238804/e79e698e-ee21-4732-a856-19c3918492b6\">\r\n\r\n</details>\r\n\r\n\r\n\r\n<details>\r\n<summary> Whereas `res.compute()` ends up with something more like: </summary>\r\n\r\n\r\n<img width=\"500\" alt=\"image\" src=\"https://github.com/dask/dask/assets/8238804/2ba8f855-52db-42d5-81a0-df294161ae1d\">\r\n\r\n<img width=\"500\" alt=\"image\" src=\"https://github.com/dask/dask/assets/8238804/cc2d6aec-f134-4c75-a752-e93f5480d576\">\r\n\r\n\r\n\r\n</details>\r\n\r\n\r\n**Environment**:\r\n\r\n- Dask version: '2024.3.1'\r\n- Python version: Python 3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:43:09) [GCC 12.3.0]\r\n- Operating System: ubuntu (but can replicate on mac)\r\n- Install method (conda, pip, source): pip (in conda env)\r\n\r\n\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/11026/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/11026/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}