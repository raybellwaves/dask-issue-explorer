{
    "url": "https://api.github.com/repos/dask/dask/issues/8876",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/8876/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/8876/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/8876/events",
    "html_url": "https://github.com/dask/dask/issues/8876",
    "id": 1190259814,
    "node_id": "I_kwDOAbcwm85G8exm",
    "number": 8876,
    "title": "`dd.concat(..., interleave_partitions=True)` graph adds unnecessary communication and complexity",
    "user": {
        "login": "gjoseph92",
        "id": 3309802,
        "node_id": "MDQ6VXNlcjMzMDk4MDI=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3309802?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/gjoseph92",
        "html_url": "https://github.com/gjoseph92",
        "followers_url": "https://api.github.com/users/gjoseph92/followers",
        "following_url": "https://api.github.com/users/gjoseph92/following{/other_user}",
        "gists_url": "https://api.github.com/users/gjoseph92/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/gjoseph92/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/gjoseph92/subscriptions",
        "organizations_url": "https://api.github.com/users/gjoseph92/orgs",
        "repos_url": "https://api.github.com/users/gjoseph92/repos",
        "events_url": "https://api.github.com/users/gjoseph92/events{/privacy}",
        "received_events_url": "https://api.github.com/users/gjoseph92/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2022-04-01T20:52:55Z",
    "updated_at": "2022-04-07T17:46:17Z",
    "closed_at": null,
    "author_association": "MEMBER",
    "active_lock_reason": null,
    "body": "(Real-world use case) Say you have 10,000 single-partition dask DataFrames, each with known divisions. You want to combine them into one. Some don't overlap at all, but say 40% of them do overlap with a handful of the others. The obvious way to do this is `dd.concat(sorted(inputs, key=lambda df: df.divisions), interleave_partitions=True)`. You would expect that 60% of the resulting partitions would simply be a pass-through from the original input, and the others would just be a few tasks each combining those overlapping inputs.\r\n\r\nHowever, `dd.concat` seems to add significant complexity to the graph when _any_ inputs overlap\u2014_even to partitions that don't need to be combined with any others_. Here's a smaller reproducer.\r\n\r\n```python\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\nimport dask\r\n\r\n# Our three inputs don't overlap at all\r\na = pd.DataFrame({'n': 'a'}, index=range(1, 5))\r\nb = pd.DataFrame({'n': 'b'}, index=range(10, 15))\r\nc = pd.DataFrame({'n': 'c'}, index=range(20, 25))\r\n\r\na = dd.from_pandas(a, npartitions=1)\r\nb = dd.from_pandas(b, npartitions=1)\r\nc = dd.from_pandas(c, npartitions=1)\r\n```\r\nIf you combine these, the graph is good: just a pass-through of the originals.\r\n```python\r\nx = dd.concat([a, b, c], interleave_partitions=True)\r\nx.divisions\r\n# (1, 10, 20, 24)\r\nx.visualize(optimize_graph=True)\r\n```\r\n![mydask](https://user-images.githubusercontent.com/3309802/161332623-cad8a9c7-0a55-41d3-9ee5-035184016faa.png)\r\n\r\nHowever, if even one of the inputs overlap, then all of them go sideways:\r\n\r\n```python\r\n# Last element in `b` is 14; make `c` overlap with it\r\nc = pd.DataFrame({'n': 'c'}, index=range(14, 20))\r\nc = dd.from_pandas(c, npartitions=1)\r\n\r\nx = dd.concat([a, b, c], interleave_partitions=True)\r\nx.visualize(optimize_graph=True)\r\n```\r\n![mydask](https://user-images.githubusercontent.com/3309802/161336088-a191802d-8ac2-432b-a941-da15e184dcf6.png)\r\nThat graph seems unnecessarily convoluted! What's going on here?\r\n\r\n```python\r\nx.divisions\r\n# (1, 4, 10, 14, 19)\r\n```\r\nFirst, an extra partition was added! Why is there now a split at `4` between 1 and 10? Our first input partition still overlaps with nothing, so it should still be a pass-through.\r\n\r\nHere's what each output partition looks like:\r\n```python\r\ndask.compute([x.partitions[i] for i in range(x.npartitions)])\r\n# ([   n\r\n#   1  a\r\n#   2  a\r\n#   3  a,\r\n#      n\r\n#   4  a,\r\n#       n\r\n#   10  b\r\n#   11  b\r\n#   12  b\r\n#   13  b,\r\n#       n\r\n#   14  b\r\n#   14  c\r\n#   15  c\r\n#   16  c\r\n#   17  c\r\n#   18  c\r\n#   19  c],)\r\n```\r\nFor some reason, 4 was split into its own single-row partition. There's probably an off-by-one error in the `concat_indexed_dataframes` logic somewhere; there's no good reason to do this. But this means partition 0 must no longer a pass-through operation.\r\n\r\nBut that's actually not the main problem. Let's look at the graph for just partition 0 (which again, overlaps with nothing, and should have been a pass-through operation):\r\n```python\r\nx.partitions[0].visualize(optimize_graph=True)\r\n```\r\n![mydask](https://user-images.githubusercontent.com/3309802/161336712-037d6036-1e59-4fcb-ae3e-d75c5b5a5ff4.png)\r\n\r\nNotice how there are three separate `[ 0 ]` boxes as our root tasks. The fact that `visualize` displays them the same is misleading\u2014these are actually our three input partitions.\r\n\r\n**Our task that should have been a pass-through operation instead depends on every single other input dataframe!**\r\n\r\n<details><summary>If we dig into the graph, we can see what's happening</summary>\r\n\r\n```python\r\no, = dask.optimize(x.partitions[0])\r\ndict(o.dask)\r\n```\r\n```python\r\n{('blocks-fb54414703cd9f8c0b37fb039bc4f1b7',\r\n  0): ('concat-indexed-c623aeea3b4baf4272f1b15381c926b5', 0),\r\n ('concat-indexed-c623aeea3b4baf4272f1b15381c926b5',\r\n  0): (<function dask.dataframe.dispatch.concat(dfs, axis=0, join='outer', uniform=False, filter_warning=True, ignore_index=False, **kwargs)>,\r\n  [('repartition-merge-cb44e3c757ac1087e6bb6801dfc7afac', 0),\r\n   ('repartition-merge-8596e038e334d6729b9486e4b0ecec92', 0),\r\n   ('repartition-merge-1f6d669e193038e9e5ab917a2295c588', 0)],\r\n  0,\r\n  'outer',\r\n  False,\r\n  True,\r\n  {'ignore_order': False}),\r\n ('repartition-merge-cb44e3c757ac1087e6bb6801dfc7afac',\r\n  0): ('repartition-split-cb44e3c757ac1087e6bb6801dfc7afac', 0),\r\n ('repartition-merge-1f6d669e193038e9e5ab917a2295c588',\r\n  0): (<function dask.dataframe.methods.boundary_slice(df, start, stop, right_boundary=True, left_boundary=True, kind=None)>,\r\n  ('from_pandas-cde2bda2bd6ad57faa7bd54164e47d74', 0),\r\n  14,\r\n  14,\r\n  False),\r\n ('from_pandas-cde2bda2bd6ad57faa7bd54164e47d74',\r\n  0):     n\r\n 14  c\r\n 15  c\r\n 16  c\r\n 17  c\r\n 18  c\r\n 19  c,\r\n ('repartition-split-cb44e3c757ac1087e6bb6801dfc7afac',\r\n  0): (<function dask.dataframe.methods.boundary_slice(df, start, stop, right_boundary=True, left_boundary=True, kind=None)>, ('from_pandas-b6aa54b407dedd16e7128d4b817cbaef',\r\n   0), 1, 4, False),\r\n ('repartition-merge-8596e038e334d6729b9486e4b0ecec92',\r\n  0): (<function dask.dataframe.methods.boundary_slice(df, start, stop, right_boundary=True, left_boundary=True, kind=None)>, ('from_pandas-915f88967ee362178affd913ada85f7b',\r\n   0), 10, 10, False),\r\n ('from_pandas-915f88967ee362178affd913ada85f7b',\r\n  0):     n\r\n 10  b\r\n 11  b\r\n 12  b\r\n 13  b\r\n 14  b,\r\n ('from_pandas-b6aa54b407dedd16e7128d4b817cbaef',\r\n  0):    n\r\n 1  a\r\n 2  a\r\n 3  a\r\n 4  a}\r\n```\r\nFirst, notice that all three of our pandas DataFrames show up in the optimized graph for the first pass-through output partition. That's a dead giveaway that there's unnecessary communication going on.\r\n\r\nYou see the final `concat-indexed-c623aeea3b4baf4272f1b15381c926b5` depends on the three `repartition-merge`s. 2/3 of those are tasks that look like:\r\n\r\n```\r\n(<function dask.dataframe.methods.boundary_slice(df, start, stop, right_boundary=True, left_boundary=True, kind=None)>,\r\n  ('from_pandas-cde2bda2bd6ad57faa7bd54164e47d74', 0),\r\n  14,\r\n  14,\r\n  False)\r\n```\r\nThat's basically `boundary_slice(x, 14, 14)`\u2014aka make an empty DataFrame, aka a no-op. So even though the dependency exists in the graph, its entire contents will be thrown away as soon as it arrives.\r\n\r\nThis should definitely be avoided.\r\n</details>\r\n\r\n------\r\n\r\nSo it seems like the [`concat_indexed_dataframes`](https://github.com/dask/dask/blob/63d608e6a21fa1b56b01e560c9b87b4019eaf12c/dask/dataframe/multi.py#L1001-L1033) logic could definitely be improved. I'm not sure whether the overall approach of `align_partitions` and then concat will make sense if we want to avoid these problems\u2014is the problem in `align_partitions` itself, or in how `concat_indexed_dataframes` is using it?\r\n\r\nIf there's an underlying issue with `align_partitions`, that would be especially important to look into since it's used in a few paces (such as `merge_indexed_dataframes`). These sorts of \"merge-by-known-divisions\" operations are supposed to be the idiomatic, performant way to use dask, so the fact that this actually results in all-to-all communication is problematic.\r\n\r\ncc @jsignell @jrbourbeau @jcrist ",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/8876/reactions",
        "total_count": 3,
        "+1": 3,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/8876/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}