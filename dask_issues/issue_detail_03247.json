{
    "url": "https://api.github.com/repos/dask/dask/issues/3247",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/3247/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/3247/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/3247/events",
    "html_url": "https://github.com/dask/dask/issues/3247",
    "id": 302478147,
    "node_id": "MDU6SXNzdWUzMDI0NzgxNDc=",
    "number": 3247,
    "title": "Dask holding on to memory after garbage collection",
    "user": {
        "login": "djhoese",
        "id": 1828519,
        "node_id": "MDQ6VXNlcjE4Mjg1MTk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1828519?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/djhoese",
        "html_url": "https://github.com/djhoese",
        "followers_url": "https://api.github.com/users/djhoese/followers",
        "following_url": "https://api.github.com/users/djhoese/following{/other_user}",
        "gists_url": "https://api.github.com/users/djhoese/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/djhoese/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/djhoese/subscriptions",
        "organizations_url": "https://api.github.com/users/djhoese/orgs",
        "repos_url": "https://api.github.com/users/djhoese/repos",
        "events_url": "https://api.github.com/users/djhoese/events{/privacy}",
        "received_events_url": "https://api.github.com/users/djhoese/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 35,
    "created_at": "2018-03-05T21:52:56Z",
    "updated_at": "2020-09-30T09:33:56Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "active_lock_reason": null,
    "body": "While debugging/profiling our software using dask we noticed that dask seems to hold on to something and it seems to be dependent on number of arrays or chunks maybe. I'm using python 3.6 on OSX and using the `memory_profiler` package for profiling. This doesn't seem to be dependent on platform or python version. I created the below test script after trying a few different things including running the function multiple times or doing things at random, but I think the below gives a good example of what I'm curious about. You can run it by doing `python script.py`.\r\n\r\n```python\r\nimport sys\r\nfrom time import time\r\nimport gc\r\nimport dask\r\ndask.set_options(get=dask.local.get_sync)\r\nfrom memory_profiler import profile\r\n\r\nNUM_VALUES = 10000\r\nCHUNK_SIZE = 4096\r\n\r\n@profile\r\ndef main():\r\n    import dask.array as da\r\n    #num_values = round(((time() * 100) % 5) * (NUM_VALUES / 2))\r\n    num_values = 10000\r\n    print(\"Number of values: {}\".format(num_values))\r\n\r\n    v1 = da.arange(num_values, chunks=CHUNK_SIZE)\r\n    v2 = da.arange(num_values, chunks=CHUNK_SIZE)\r\n    arr_x, arr_y = da.meshgrid(v1, v2)\r\n    res = da.compute(arr_x + arr_y)\r\n    del v1, v2, res, arr_x, arr_y\r\n    print(gc.collect())\r\n\r\n    v1 = da.arange(num_values + 1, chunks=CHUNK_SIZE)\r\n    v2 = da.arange(num_values + 1, chunks=CHUNK_SIZE)\r\n    v3 = da.arange(num_values + 1, chunks=CHUNK_SIZE)\r\n    arr_x, arr_y = da.meshgrid(v1, v2)\r\n    arr_x2, arr_y2 = da.meshgrid(v2, v3)\r\n    res = da.compute(arr_x + arr_y + arr_x2)\r\n    del v1, v2, res, arr_x, arr_y, v3, arr_x2, arr_y2\r\n    print(gc.collect())\r\n\r\n    v1 = da.arange(num_values + 2, chunks=CHUNK_SIZE)\r\n    v2 = da.arange(num_values + 2, chunks=CHUNK_SIZE)\r\n    v3 = da.arange(num_values + 2, chunks=CHUNK_SIZE)\r\n    v4 = da.arange(num_values + 2, chunks=CHUNK_SIZE)\r\n    arr_x, arr_y = da.meshgrid(v1, v2)\r\n    arr_x2, arr_y2 = da.meshgrid(v3, v4)\r\n    res = da.compute(arr_x + arr_y + arr_x2)\r\n    del v1, v2, res, arr_x, arr_y, v3, v4, arr_x2, arr_y2\r\n    print(gc.collect())\r\n\r\n    v1 = da.arange(num_values + 3, chunks=CHUNK_SIZE)\r\n    v2 = da.arange(num_values + 3, chunks=CHUNK_SIZE)\r\n    arr_x, arr_y = da.meshgrid(v1, v2)\r\n    arr_x2, arr_y2 = da.meshgrid(v2, v1)\r\n    res = da.compute(arr_x + arr_y + arr_x2)\r\n    del v1, v2, res, arr_x, arr_y, arr_x2, arr_y2\r\n    print(gc.collect())\r\n\r\n    v1 = da.arange(num_values, chunks=CHUNK_SIZE)\r\n    v2 = da.arange(num_values, chunks=CHUNK_SIZE)\r\n    arr_x, arr_y = da.meshgrid(v1, v2)\r\n    res = da.compute(arr_x + arr_y)\r\n    del v1, v2, res, arr_x, arr_y\r\n    print(gc.collect())\r\n\r\nmain()\r\n```\r\n\r\nAfter running you will get something like the following output:\r\n\r\n```\r\nNumber of values: 10000\r\n126\r\n0\r\n7\r\n0\r\n10\r\nFilename: test_memory_leak.py\r\n\r\nLine #    Mem usage    Increment   Line Contents\r\n================================================\r\n    11     40.6 MiB     40.6 MiB   @profile\r\n    12                             def main():\r\n    13     49.7 MiB      9.0 MiB       import dask.array as da\r\n    14                                 #num_values = round(((time() * 100) % 5) * (NUM_VALUES / 2))\r\n    15     49.7 MiB      0.0 MiB       num_values = 10000\r\n    16     49.7 MiB      0.0 MiB       print(\"Number of values: {}\".format(num_values))\r\n    17                             \r\n    18     49.7 MiB      0.0 MiB       v1 = da.arange(num_values, chunks=CHUNK_SIZE)\r\n    19     49.7 MiB      0.0 MiB       v2 = da.arange(num_values, chunks=CHUNK_SIZE)\r\n    20     49.7 MiB      0.0 MiB       arr_x, arr_y = da.meshgrid(v1, v2)\r\n    21   1064.4 MiB   1014.6 MiB       res = da.compute(arr_x + arr_y)\r\n    22    301.4 MiB   -762.9 MiB       del v1, v2, res, arr_x, arr_y\r\n    23    301.4 MiB      0.0 MiB       print(gc.collect())\r\n    24                             \r\n    25    301.4 MiB      0.0 MiB       v1 = da.arange(num_values + 1, chunks=CHUNK_SIZE)\r\n    26    301.4 MiB      0.0 MiB       v2 = da.arange(num_values + 1, chunks=CHUNK_SIZE)\r\n    27    301.4 MiB      0.0 MiB       v3 = da.arange(num_values + 1, chunks=CHUNK_SIZE)\r\n    28    301.4 MiB      0.0 MiB       arr_x, arr_y = da.meshgrid(v1, v2)\r\n    29    301.4 MiB      0.0 MiB       arr_x2, arr_y2 = da.meshgrid(v2, v3)\r\n    30   1396.5 MiB   1095.1 MiB       res = da.compute(arr_x + arr_y + arr_x2)\r\n    31    633.4 MiB   -763.1 MiB       del v1, v2, res, arr_x, arr_y, v3, arr_x2, arr_y2\r\n    32    633.4 MiB      0.0 MiB       print(gc.collect())\r\n    33                             \r\n    34    633.4 MiB      0.0 MiB       v1 = da.arange(num_values + 2, chunks=CHUNK_SIZE)\r\n    35    633.4 MiB      0.0 MiB       v2 = da.arange(num_values + 2, chunks=CHUNK_SIZE)\r\n    36    633.4 MiB      0.0 MiB       v3 = da.arange(num_values + 2, chunks=CHUNK_SIZE)\r\n    37    633.4 MiB      0.0 MiB       v4 = da.arange(num_values + 2, chunks=CHUNK_SIZE)\r\n    38    633.4 MiB      0.0 MiB       arr_x, arr_y = da.meshgrid(v1, v2)\r\n    39    633.4 MiB      0.0 MiB       arr_x2, arr_y2 = da.meshgrid(v3, v4)\r\n    40   1590.8 MiB    957.4 MiB       res = da.compute(arr_x + arr_y + arr_x2)\r\n    41    827.5 MiB   -763.2 MiB       del v1, v2, res, arr_x, arr_y, v3, v4, arr_x2, arr_y2\r\n    42    827.5 MiB      0.0 MiB       print(gc.collect())\r\n    43                             \r\n    44    827.5 MiB      0.0 MiB       v1 = da.arange(num_values + 3, chunks=CHUNK_SIZE)\r\n    45    827.5 MiB      0.0 MiB       v2 = da.arange(num_values + 3, chunks=CHUNK_SIZE)\r\n    46    827.5 MiB      0.0 MiB       arr_x, arr_y = da.meshgrid(v1, v2)\r\n    47    827.5 MiB      0.0 MiB       arr_x2, arr_y2 = da.meshgrid(v2, v1)\r\n    48   1591.6 MiB    764.0 MiB       res = da.compute(arr_x + arr_y + arr_x2)\r\n    49    828.2 MiB   -763.4 MiB       del v1, v2, res, arr_x, arr_y, arr_x2, arr_y2\r\n    50    828.2 MiB      0.0 MiB       print(gc.collect())\r\n    51                             \r\n    52    828.2 MiB      0.0 MiB       v1 = da.arange(num_values, chunks=CHUNK_SIZE)\r\n    53    828.2 MiB      0.0 MiB       v2 = da.arange(num_values, chunks=CHUNK_SIZE)\r\n    54    828.2 MiB      0.0 MiB       arr_x, arr_y = da.meshgrid(v1, v2)\r\n    55   1591.2 MiB    763.0 MiB       res = da.compute(arr_x + arr_y)\r\n    56    828.2 MiB   -762.9 MiB       del v1, v2, res, arr_x, arr_y\r\n    57    828.2 MiB      0.0 MiB       print(gc.collect())\r\n\r\n```\r\n\r\nSo I'm not sure if this is intended but seeing as the memory usage is based on the number/size of inputs it seems like something that should have an option for clearing it out. Just looking for some information on what's going on here.",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/3247/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/3247/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}