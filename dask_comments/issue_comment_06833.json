[
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/726478514",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-726478514",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 726478514,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyNjQ3ODUxNA==",
        "user": {
            "login": "pseudotensor",
            "id": 2249614,
            "node_id": "MDQ6VXNlcjIyNDk2MTQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2249614?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pseudotensor",
            "html_url": "https://github.com/pseudotensor",
            "followers_url": "https://api.github.com/users/pseudotensor/followers",
            "following_url": "https://api.github.com/users/pseudotensor/following{/other_user}",
            "gists_url": "https://api.github.com/users/pseudotensor/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pseudotensor/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pseudotensor/subscriptions",
            "organizations_url": "https://api.github.com/users/pseudotensor/orgs",
            "repos_url": "https://api.github.com/users/pseudotensor/repos",
            "events_url": "https://api.github.com/users/pseudotensor/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pseudotensor/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-13T03:07:11Z",
        "updated_at": "2020-11-13T03:14:35Z",
        "author_association": "NONE",
        "body": "[maps.txt](https://github.com/dask/dask/files/5534505/maps.txt)\r\n\r\nHere is output of `sudo cat /proc/32193/maps > maps.txt`\r\n\r\n`0x7f3b29ace000     0x7f52ac000000 0x1782532000        0x0 ` is about 94GB",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/726478514/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/726482715",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-726482715",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 726482715,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyNjQ4MjcxNQ==",
        "user": {
            "login": "pseudotensor",
            "id": 2249614,
            "node_id": "MDQ6VXNlcjIyNDk2MTQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2249614?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pseudotensor",
            "html_url": "https://github.com/pseudotensor",
            "followers_url": "https://api.github.com/users/pseudotensor/followers",
            "following_url": "https://api.github.com/users/pseudotensor/following{/other_user}",
            "gists_url": "https://api.github.com/users/pseudotensor/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pseudotensor/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pseudotensor/subscriptions",
            "organizations_url": "https://api.github.com/users/pseudotensor/orgs",
            "repos_url": "https://api.github.com/users/pseudotensor/repos",
            "events_url": "https://api.github.com/users/pseudotensor/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pseudotensor/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-13T03:19:51Z",
        "updated_at": "2020-11-13T03:31:17Z",
        "author_association": "NONE",
        "body": "Apart from being all odd and a serious issue (can't use dask like this), is there a way to ask scheduler for its memory usage?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/726482715/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/726490357",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-726490357",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 726490357,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyNjQ5MDM1Nw==",
        "user": {
            "login": "pseudotensor",
            "id": 2249614,
            "node_id": "MDQ6VXNlcjIyNDk2MTQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2249614?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pseudotensor",
            "html_url": "https://github.com/pseudotensor",
            "followers_url": "https://api.github.com/users/pseudotensor/followers",
            "following_url": "https://api.github.com/users/pseudotensor/following{/other_user}",
            "gists_url": "https://api.github.com/users/pseudotensor/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pseudotensor/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pseudotensor/subscriptions",
            "organizations_url": "https://api.github.com/users/pseudotensor/orgs",
            "repos_url": "https://api.github.com/users/pseudotensor/repos",
            "events_url": "https://api.github.com/users/pseudotensor/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pseudotensor/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-13T03:47:53Z",
        "updated_at": "2020-11-13T03:47:53Z",
        "author_association": "NONE",
        "body": "I'm guessing I'm misunderstanding a user's responsibility when using dask.\r\n\r\n1) I assume that if I did not persist the data, then when a process closes that data is gone\r\n\r\n2) I assume data is distributed, not sitting on a single node's scheduler.  That would defeat the purpose of distribution.\r\n\r\n3) I assume from_array() is taking the numpy array and distributing that on the cluster, not just storing it within the scheduler.    That would defeat the purpose of distribution as well.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/726490357/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/726492018",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-726492018",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 726492018,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyNjQ5MjAxOA==",
        "user": {
            "login": "pseudotensor",
            "id": 2249614,
            "node_id": "MDQ6VXNlcjIyNDk2MTQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2249614?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pseudotensor",
            "html_url": "https://github.com/pseudotensor",
            "followers_url": "https://api.github.com/users/pseudotensor/followers",
            "following_url": "https://api.github.com/users/pseudotensor/following{/other_user}",
            "gists_url": "https://api.github.com/users/pseudotensor/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pseudotensor/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pseudotensor/subscriptions",
            "organizations_url": "https://api.github.com/users/pseudotensor/orgs",
            "repos_url": "https://api.github.com/users/pseudotensor/repos",
            "events_url": "https://api.github.com/users/pseudotensor/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pseudotensor/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-13T03:55:24Z",
        "updated_at": "2020-11-13T03:59:38Z",
        "author_association": "NONE",
        "body": "Here's a code fragment, but it's obvious from my description:\r\n\r\nX is 2D numpy array, y 1D numpy array.\r\n```\r\nwith client:\r\n    import xgboost as xgb\r\n\r\n    import dask.dataframe as dd\r\n    chunksize=500000\r\n    X = dd.from_array(X, columns=columns, chunksize=chunksize)\r\n    y = dd.from_array(y, chunksize=chunksize)\r\n    model = xgb.dask.DaskXGBClassifier()\r\n    model.fit(X, y)\r\n```\r\nThis is done in a fork that dies every fit on about 5M rows x 10 columns.\r\n\r\nI expect the dask-scheduler memory should *never* be large or hold data.  And certainly memory should not keep growing.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/726492018/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/726494868",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-726494868",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 726494868,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyNjQ5NDg2OA==",
        "user": {
            "login": "pseudotensor",
            "id": 2249614,
            "node_id": "MDQ6VXNlcjIyNDk2MTQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2249614?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pseudotensor",
            "html_url": "https://github.com/pseudotensor",
            "followers_url": "https://api.github.com/users/pseudotensor/followers",
            "following_url": "https://api.github.com/users/pseudotensor/following{/other_user}",
            "gists_url": "https://api.github.com/users/pseudotensor/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pseudotensor/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pseudotensor/subscriptions",
            "organizations_url": "https://api.github.com/users/pseudotensor/orgs",
            "repos_url": "https://api.github.com/users/pseudotensor/repos",
            "events_url": "https://api.github.com/users/pseudotensor/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pseudotensor/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-13T04:06:46Z",
        "updated_at": "2020-11-13T04:06:46Z",
        "author_association": "NONE",
        "body": "FYI before posting I googled and search around and didn't find exactly the same scale of problem.  Mostly stack overflow stuff was misuses or misinterpretations AFAIK.\r\n\r\nI'm also not clear if I should post to dask or dask/distributed.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/726494868/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/726494870",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-726494870",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 726494870,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyNjQ5NDg3MA==",
        "user": {
            "login": "rjzamora",
            "id": 20461013,
            "node_id": "MDQ6VXNlcjIwNDYxMDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rjzamora",
            "html_url": "https://github.com/rjzamora",
            "followers_url": "https://api.github.com/users/rjzamora/followers",
            "following_url": "https://api.github.com/users/rjzamora/following{/other_user}",
            "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions",
            "organizations_url": "https://api.github.com/users/rjzamora/orgs",
            "repos_url": "https://api.github.com/users/rjzamora/repos",
            "events_url": "https://api.github.com/users/rjzamora/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rjzamora/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-13T04:06:47Z",
        "updated_at": "2020-11-13T04:06:47Z",
        "author_association": "MEMBER",
        "body": "This question may be a better fit for [dask/distributed](https://github.com/dask/distributed/issues), but I can try to offer some thoughts...\r\n\r\n>I assume that if I did not persist the data, then when a process closes that data is gone\r\n\r\nI assume that it is definitely better to explicitly close your client (and maybe even cancel futures).  Although your client process is dying, I don't think the relevent data will be immediately deleted from the cluster.\r\n\r\n>I assume data is distributed, not sitting on a single node's scheduler. That would defeat the purpose of distribution.\r\n\r\nThe data will be distributed for processing.  However, since your data is being generated with numpy, the initial data has to originate on a single process.\r\n\r\n> I assume from_array() is taking the numpy array and distributing that on the cluster, not just storing it within the scheduler. That would defeat the purpose of distribution as well.\r\n\r\n\r\nSame answer as above - To perform a truely \"data-distributed\" workflow, you will need a parallel read, or to use `from_delayed` to allow the data to be generated in parallel.  When you are using a single numpy array as the source data, it is indeed likely that the entirity of your data will be stored in the graph.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/726494870/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/726495435",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-726495435",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 726495435,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyNjQ5NTQzNQ==",
        "user": {
            "login": "pseudotensor",
            "id": 2249614,
            "node_id": "MDQ6VXNlcjIyNDk2MTQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2249614?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pseudotensor",
            "html_url": "https://github.com/pseudotensor",
            "followers_url": "https://api.github.com/users/pseudotensor/followers",
            "following_url": "https://api.github.com/users/pseudotensor/following{/other_user}",
            "gists_url": "https://api.github.com/users/pseudotensor/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pseudotensor/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pseudotensor/subscriptions",
            "organizations_url": "https://api.github.com/users/pseudotensor/orgs",
            "repos_url": "https://api.github.com/users/pseudotensor/repos",
            "events_url": "https://api.github.com/users/pseudotensor/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pseudotensor/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-13T04:09:18Z",
        "updated_at": "2020-11-13T04:23:06Z",
        "author_association": "NONE",
        "body": "> This question may be a better fit for [dask/distributed](https://github.com/dask/distributed/issues), but I can try to offer some thoughts...\r\n> \r\n> > I assume that if I did not persist the data, then when a process closes that data is gone\r\n> \r\n> I assume that it is definitely better to explicitly close your client (and maybe even cancel futures). Although your client process is dying, I don't think the relevent data will be immediately deleted from the cluster.\r\n> \r\n> > I assume data is distributed, not sitting on a single node's scheduler. That would defeat the purpose of distribution.\r\n> \r\n> The data will be distributed for processing. However, since your data is being generated with numpy, the initial data has to originate on a single process.\r\n> \r\n> > I assume from_array() is taking the numpy array and distributing that on the cluster, not just storing it within the scheduler. That would defeat the purpose of distribution as well.\r\n> \r\n> Same answer as above - To perform a truely \"data-distributed\" workflow, you will need a parallel read, or to use `from_delayed` to allow the data to be generated in parallel. When you are using a single numpy array as the source data, it is indeed likely that the entirity of your data will be stored in the graph.\r\n\r\nI understand that the initial numpy data is on the single server, but this is not on the dask-scheduler.  Also, it's relatively small amount of data, only 200MB of numpy data.\r\n\r\nI understand to get a fully distributed experience I need to start from get-go with dask, but I'm far from that if even simple uses are showing massive use by the scheduler.\r\n\r\nI'm confused why the data needs to be stored in the graph.  Do I need to force distribution before passing the data to xgboost? If I run .compute I just manifest the data locally, so I assume I need to run .scatter or some equivalent?  .persist()? Not sure what will force data to be distributed and the graph completed so scheduler is done with data.\r\n\r\nIs there a command that will take numpy or pandas data and bypass the single-node scheduler and immediately distribute the data?\r\n\r\nAlso, why does the data keep accumulating?  Every fit adds 200MB to scheduler.  Why are (I guess) the old graphs still there after xgboost is done and all forks related to the client are gone?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/726495435/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/726499357",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-726499357",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 726499357,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyNjQ5OTM1Nw==",
        "user": {
            "login": "rjzamora",
            "id": 20461013,
            "node_id": "MDQ6VXNlcjIwNDYxMDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rjzamora",
            "html_url": "https://github.com/rjzamora",
            "followers_url": "https://api.github.com/users/rjzamora/followers",
            "following_url": "https://api.github.com/users/rjzamora/following{/other_user}",
            "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions",
            "organizations_url": "https://api.github.com/users/rjzamora/orgs",
            "repos_url": "https://api.github.com/users/rjzamora/repos",
            "events_url": "https://api.github.com/users/rjzamora/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rjzamora/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-13T04:24:44Z",
        "updated_at": "2020-11-13T04:24:44Z",
        "author_association": "MEMBER",
        "body": "Right - I understand that your data is small, and I agree that it shouldn't be taking up a lot of space in the graph.   When I say \"the entirity of your data will be stored in the graph\", I am just saying that the very first task in the graph will include the entire array as input.  If you call `X.persist()` after the `from_array` call, your data will become distributed (you are correct that `compute` is **not** what you want).\r\n\r\n>Also, why does the data keep accumulating? Every fit adds 200MB to scheduler. Why are (I guess) the old graphs still there after xgboost is done and all forks related to the client are gone?\r\n\r\nThis is where someone with better `distributed` knowledge my have more intuition than me (cc @quasiben ).  Perhaps you can try to be explicit about cleaning up collections before you let the client die (e.g. `client.cancel(X)`)?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/726499357/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/726505079",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-726505079",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 726505079,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyNjUwNTA3OQ==",
        "user": {
            "login": "pseudotensor",
            "id": 2249614,
            "node_id": "MDQ6VXNlcjIyNDk2MTQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2249614?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pseudotensor",
            "html_url": "https://github.com/pseudotensor",
            "followers_url": "https://api.github.com/users/pseudotensor/followers",
            "following_url": "https://api.github.com/users/pseudotensor/following{/other_user}",
            "gists_url": "https://api.github.com/users/pseudotensor/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pseudotensor/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pseudotensor/subscriptions",
            "organizations_url": "https://api.github.com/users/pseudotensor/orgs",
            "repos_url": "https://api.github.com/users/pseudotensor/repos",
            "events_url": "https://api.github.com/users/pseudotensor/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pseudotensor/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-13T04:46:01Z",
        "updated_at": "2020-11-13T05:08:06Z",
        "author_association": "NONE",
        "body": "Will use of dd.from_array(X).persist() bypass the scheduler or must it go through it?\r\n\r\nIt seems a bit odd of a design if all in-memory dask distributed data operations have to go from the client process -> scheduler -> workers.  Then the scheduler always ends up holding all the data meant for the cluster of workers for from_pandas, from_array, etc.  How can one just get the data in memory on the cluster?\r\n\r\nI understand read_csv or other url/file operations can lazily slice data and use it to distribute, and there the lazy thing stored is just the file name or link.  Of course, read_csv does not work unless disk is shared.  And connectors that read data from cloud require special other infrastructure.\r\n\r\nThe simplest mode should be in-memory and be optimal by itself IMHO.  As-is, it's at least an excessive copy of the full data frame on the scheduler.  Factors of 2 are important! :)  In reality, the numpy frame is converted into a dask frame that I think has more overhead like pandas, but maybe not.  It seems scheduler should just remember the client has memory and use it when performing any task in the task graph, not the actual data.\r\n\r\nAt worst, for whatever reason, the frames never go away.  I'll try the .persist and client.cancel.  Thanks.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/726505079/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/726517622",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-726517622",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 726517622,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyNjUxNzYyMg==",
        "user": {
            "login": "rjzamora",
            "id": 20461013,
            "node_id": "MDQ6VXNlcjIwNDYxMDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rjzamora",
            "html_url": "https://github.com/rjzamora",
            "followers_url": "https://api.github.com/users/rjzamora/followers",
            "following_url": "https://api.github.com/users/rjzamora/following{/other_user}",
            "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions",
            "organizations_url": "https://api.github.com/users/rjzamora/orgs",
            "repos_url": "https://api.github.com/users/rjzamora/repos",
            "events_url": "https://api.github.com/users/rjzamora/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rjzamora/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-13T05:07:38Z",
        "updated_at": "2020-11-13T05:07:38Z",
        "author_association": "MEMBER",
        "body": ">It seems a bit odd of a design if all in-memory dask distributed data operations have to go from the client process -> scheduler -> workers. Then the scheduler always ends up holding all the data meant for the cluster of workers for from_pandas, from_array, etc. How can one just get the data in memory on the cluster?\r\n\r\nI see - If you are starting with a literal numpy array or pandas DataFrame, you are correct that the data will flow client process -> scheduler -> workers.  There is really no way around this, since the starting point is an in-memory data structure.  If you don't want to read from disk, you may be looking for something like [dask.delayed](https://docs.dask.org/en/latest/array-creation.html#using-dask-delayed) for the generation of your data (where you can supply a user-defined function to generate in in-memory numpy array for each initial chunk).  ",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/726517622/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/726518107",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-726518107",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 726518107,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyNjUxODEwNw==",
        "user": {
            "login": "pseudotensor",
            "id": 2249614,
            "node_id": "MDQ6VXNlcjIyNDk2MTQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2249614?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pseudotensor",
            "html_url": "https://github.com/pseudotensor",
            "followers_url": "https://api.github.com/users/pseudotensor/followers",
            "following_url": "https://api.github.com/users/pseudotensor/following{/other_user}",
            "gists_url": "https://api.github.com/users/pseudotensor/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pseudotensor/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pseudotensor/subscriptions",
            "organizations_url": "https://api.github.com/users/pseudotensor/orgs",
            "repos_url": "https://api.github.com/users/pseudotensor/repos",
            "events_url": "https://api.github.com/users/pseudotensor/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pseudotensor/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-13T05:09:24Z",
        "updated_at": "2020-11-13T05:22:12Z",
        "author_association": "NONE",
        "body": "But why can't the scheduler and task just keep track of the client having the memory?  Of course, one can't del the object provided as that would mess up things, but one can't rm the file for read_csv anyways.  So it's the same issue, no new issue.\r\n\r\nActually del isn't a problem.  As long as the client/dask stuff keeps track of memory and holds a reference, del won't matter.  So it's even easier to manage than file issues.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/726518107/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/726536525",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-726536525",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 726536525,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyNjUzNjUyNQ==",
        "user": {
            "login": "pseudotensor",
            "id": 2249614,
            "node_id": "MDQ6VXNlcjIyNDk2MTQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2249614?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pseudotensor",
            "html_url": "https://github.com/pseudotensor",
            "followers_url": "https://api.github.com/users/pseudotensor/followers",
            "following_url": "https://api.github.com/users/pseudotensor/following{/other_user}",
            "gists_url": "https://api.github.com/users/pseudotensor/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pseudotensor/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pseudotensor/subscriptions",
            "organizations_url": "https://api.github.com/users/pseudotensor/orgs",
            "repos_url": "https://api.github.com/users/pseudotensor/repos",
            "events_url": "https://api.github.com/users/pseudotensor/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pseudotensor/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-13T05:48:40Z",
        "updated_at": "2020-11-13T05:48:40Z",
        "author_association": "NONE",
        "body": "Looking at https://distributed.dask.org/en/latest/memory.html I see no reason why there is accumulation.  The fork goes away, the future held should be deleted.  I would think I don't have to cancel the future myself.\r\n\r\nHowever, perhaps I'm uncleanly shutting down the fork.  Maybe then the future isn't entirely removed?  That is, while in-memory stuff is clearly gone after a fork is gone, any distributed off-memory things are not.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/726536525/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/726636547",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-726636547",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 726636547,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyNjYzNjU0Nw==",
        "user": {
            "login": "pseudotensor",
            "id": 2249614,
            "node_id": "MDQ6VXNlcjIyNDk2MTQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2249614?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pseudotensor",
            "html_url": "https://github.com/pseudotensor",
            "followers_url": "https://api.github.com/users/pseudotensor/followers",
            "following_url": "https://api.github.com/users/pseudotensor/following{/other_user}",
            "gists_url": "https://api.github.com/users/pseudotensor/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pseudotensor/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pseudotensor/subscriptions",
            "organizations_url": "https://api.github.com/users/pseudotensor/orgs",
            "repos_url": "https://api.github.com/users/pseudotensor/repos",
            "events_url": "https://api.github.com/users/pseudotensor/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pseudotensor/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-13T08:56:58Z",
        "updated_at": "2020-11-13T09:01:08Z",
        "author_association": "NONE",
        "body": "I added more details and repros at: https://github.com/dmlc/xgboost/issues/6388#issuecomment-726589459\r\n\r\nThere are some things mentioned in the issue that seem to be xgboost's fault, like excessive memory usage on CPU before dask is even used.\r\n\r\nHowever, the fact that the scheduler and worker both keep growing in memory use every completed client python script, despite having client.cancel(X) and client.cancel(y) even (and a clean exit of the script) seems to be a problem with dask.\r\n\r\nIn the context I originally posted about, only the scheduler seems to grow in memory use, but excessively so.  cancels didn't help there either.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/726636547/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/726642487",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-726642487",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 726642487,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyNjY0MjQ4Nw==",
        "user": {
            "login": "pseudotensor",
            "id": 2249614,
            "node_id": "MDQ6VXNlcjIyNDk2MTQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2249614?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pseudotensor",
            "html_url": "https://github.com/pseudotensor",
            "followers_url": "https://api.github.com/users/pseudotensor/followers",
            "following_url": "https://api.github.com/users/pseudotensor/following{/other_user}",
            "gists_url": "https://api.github.com/users/pseudotensor/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pseudotensor/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pseudotensor/subscriptions",
            "organizations_url": "https://api.github.com/users/pseudotensor/orgs",
            "repos_url": "https://api.github.com/users/pseudotensor/repos",
            "events_url": "https://api.github.com/users/pseudotensor/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pseudotensor/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-13T09:08:17Z",
        "updated_at": "2020-11-13T09:08:26Z",
        "author_association": "NONE",
        "body": "Eventually the worker gets killed and restarts due to the OOM accumulated.\r\n\r\n```\r\ndistributed.nanny - INFO - Worker process 29371 was killed by signal 9\r\ndistributed.nanny - WARNING - Restarting worker\r\n```\r\nThis keeps happening over and over.\r\n\r\n\r\nEverytime this happens, the new worker starts again with less memory but again accumulating after each iteration in the loop.  Again it gets killed, etc.\r\n\r\nMeanwhile the scheduler continues itself to grow in memory use.\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/726642487/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/726644358",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-726644358",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 726644358,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyNjY0NDM1OA==",
        "user": {
            "login": "pseudotensor",
            "id": 2249614,
            "node_id": "MDQ6VXNlcjIyNDk2MTQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2249614?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pseudotensor",
            "html_url": "https://github.com/pseudotensor",
            "followers_url": "https://api.github.com/users/pseudotensor/followers",
            "following_url": "https://api.github.com/users/pseudotensor/following{/other_user}",
            "gists_url": "https://api.github.com/users/pseudotensor/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pseudotensor/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pseudotensor/subscriptions",
            "organizations_url": "https://api.github.com/users/pseudotensor/orgs",
            "repos_url": "https://api.github.com/users/pseudotensor/repos",
            "events_url": "https://api.github.com/users/pseudotensor/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pseudotensor/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-13T09:12:00Z",
        "updated_at": "2020-11-13T09:15:41Z",
        "author_association": "NONE",
        "body": "Maybe related:\r\nhttps://github.com/dask/distributed/issues/3898\r\nhttps://github.com/dask/dask/issues/3530\r\nhttps://github.com/dask/dask/issues/6762",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/726644358/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/726649142",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-726649142",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 726649142,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyNjY0OTE0Mg==",
        "user": {
            "login": "pseudotensor",
            "id": 2249614,
            "node_id": "MDQ6VXNlcjIyNDk2MTQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2249614?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pseudotensor",
            "html_url": "https://github.com/pseudotensor",
            "followers_url": "https://api.github.com/users/pseudotensor/followers",
            "following_url": "https://api.github.com/users/pseudotensor/following{/other_user}",
            "gists_url": "https://api.github.com/users/pseudotensor/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pseudotensor/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pseudotensor/subscriptions",
            "organizations_url": "https://api.github.com/users/pseudotensor/orgs",
            "repos_url": "https://api.github.com/users/pseudotensor/repos",
            "events_url": "https://api.github.com/users/pseudotensor/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pseudotensor/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-13T09:21:18Z",
        "updated_at": "2020-11-13T09:21:18Z",
        "author_association": "NONE",
        "body": "Moved discussion to: https://github.com/dask/distributed/issues/4243 since seems to be dask.distributed problem only perhaps.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/726649142/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/729554422",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-729554422",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 729554422,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyOTU1NDQyMg==",
        "user": {
            "login": "trivialfis",
            "id": 16746409,
            "node_id": "MDQ6VXNlcjE2NzQ2NDA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/16746409?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/trivialfis",
            "html_url": "https://github.com/trivialfis",
            "followers_url": "https://api.github.com/users/trivialfis/followers",
            "following_url": "https://api.github.com/users/trivialfis/following{/other_user}",
            "gists_url": "https://api.github.com/users/trivialfis/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/trivialfis/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/trivialfis/subscriptions",
            "organizations_url": "https://api.github.com/users/trivialfis/orgs",
            "repos_url": "https://api.github.com/users/trivialfis/repos",
            "events_url": "https://api.github.com/users/trivialfis/events{/privacy}",
            "received_events_url": "https://api.github.com/users/trivialfis/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-18T09:33:02Z",
        "updated_at": "2020-11-18T10:57:12Z",
        "author_association": "CONTRIBUTOR",
        "body": "Moving discussion from xgboost to here (or distributed if preferred).  Here is a minimum reproducible example modified from script provided by @pseudotensor with xgboost removed:\r\n\r\n``` python\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\nimport distributed\r\n\r\n\r\ndef main():\r\n    colnames = ['label'] + ['feature-%02d' % i for i in range(1, 29)]\r\n    df = pd.read_csv('HIGGS.csv',\r\n                     names=colnames)\r\n\r\n    y = df['label']\r\n    X = df[df.columns.difference(['label'])]\r\n    print('X.shape', X.shape)\r\n\r\n    for i in range(0, 100):\r\n        from dask.distributed import Client\r\n        with Client(scheduler_file='scheduler.json') as client:\r\n            chunksize = 50000\r\n            dX = dd.from_array(X.values, chunksize=chunksize)\r\n            dy = dd.from_array(y.values, chunksize=chunksize)\r\n\r\n            dX = client.persist(dX)\r\n            dy = client.persist(dy)\r\n            distributed.wait(dX)\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n\r\n```\r\n\r\nSpec:\r\n```\r\ndask.__version__: 2.30.0\r\ndistributed.__version__: 2.30.0\r\nWorkers: 2\r\nMemory budget for each worker: ~32 GB\r\nTotal memory on system: 64GB + 8GB swap\r\nX.shape: (11000000, 28)\r\nData file size: 7.5G\r\n```\r\n\r\nI can confirm that the scheduler by itself has significant memory (close to 44 GB).",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/729554422/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/729726388",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-729726388",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 729726388,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyOTcyNjM4OA==",
        "user": {
            "login": "quasiben",
            "id": 1403768,
            "node_id": "MDQ6VXNlcjE0MDM3Njg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1403768?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/quasiben",
            "html_url": "https://github.com/quasiben",
            "followers_url": "https://api.github.com/users/quasiben/followers",
            "following_url": "https://api.github.com/users/quasiben/following{/other_user}",
            "gists_url": "https://api.github.com/users/quasiben/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/quasiben/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/quasiben/subscriptions",
            "organizations_url": "https://api.github.com/users/quasiben/orgs",
            "repos_url": "https://api.github.com/users/quasiben/repos",
            "events_url": "https://api.github.com/users/quasiben/events{/privacy}",
            "received_events_url": "https://api.github.com/users/quasiben/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-18T14:45:51Z",
        "updated_at": "2020-11-18T15:04:15Z",
        "author_association": "MEMBER",
        "body": "Can you also provide how you started the cluster ?  In the above, you are connecting with `scheduler.json` which does not show how ~many workers~, memory limits, etc. \r\n\r\nEDIT:\r\n\r\nI now see the spec list some of the cluster setup but having it explicitly laid out would be helpful in reproducing",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/729726388/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/729743542",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-729743542",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 729743542,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyOTc0MzU0Mg==",
        "user": {
            "login": "quasiben",
            "id": 1403768,
            "node_id": "MDQ6VXNlcjE0MDM3Njg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1403768?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/quasiben",
            "html_url": "https://github.com/quasiben",
            "followers_url": "https://api.github.com/users/quasiben/followers",
            "following_url": "https://api.github.com/users/quasiben/following{/other_user}",
            "gists_url": "https://api.github.com/users/quasiben/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/quasiben/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/quasiben/subscriptions",
            "organizations_url": "https://api.github.com/users/quasiben/orgs",
            "repos_url": "https://api.github.com/users/quasiben/repos",
            "events_url": "https://api.github.com/users/quasiben/events{/privacy}",
            "received_events_url": "https://api.github.com/users/quasiben/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-18T15:11:28Z",
        "updated_at": "2020-11-18T15:11:28Z",
        "author_association": "MEMBER",
        "body": "I think it would be good to read through https://github.com/dask/distributed/issues/3032 as it outlines some problems when using `from_array` with data already loaded in memory.  As @rjzamora has noted, the data is included in task graph which is going to run through the scheduler.  Instead, I would suggest rewriting things with dask throughout the workflow:\r\n\r\n```python\r\nddf = dd.read_csv('/datasets/bzaitlen/GitRepos/HIGGS.csv', names=colnames)\r\ny = ddf['label']\r\ndy = y.to_dask_array()\r\ndy = dy.persist()\r\n\r\nX = ddf[ddf.columns.difference(['label'])]\r\ndX = X.to_dask_array()\r\ndX = dX.persist()\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/729743542/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/729755763",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-729755763",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 729755763,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyOTc1NTc2Mw==",
        "user": {
            "login": "trivialfis",
            "id": 16746409,
            "node_id": "MDQ6VXNlcjE2NzQ2NDA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/16746409?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/trivialfis",
            "html_url": "https://github.com/trivialfis",
            "followers_url": "https://api.github.com/users/trivialfis/followers",
            "following_url": "https://api.github.com/users/trivialfis/following{/other_user}",
            "gists_url": "https://api.github.com/users/trivialfis/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/trivialfis/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/trivialfis/subscriptions",
            "organizations_url": "https://api.github.com/users/trivialfis/orgs",
            "repos_url": "https://api.github.com/users/trivialfis/repos",
            "events_url": "https://api.github.com/users/trivialfis/events{/privacy}",
            "received_events_url": "https://api.github.com/users/trivialfis/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-18T15:29:14Z",
        "updated_at": "2020-11-18T15:29:14Z",
        "author_association": "CONTRIBUTOR",
        "body": "@quasiben  Thanks for the reply!  I believe the your example should be the right way of loading data.  But for a small dataset like HIGGS, the in memory size with double is about 2.5 GB (11000000 rows * 29 cols * 8 bytes / 1024^3).  To fill out 60 GB of memory there has to be at least 24 copies of data.  That seems to be something worth looking into?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/729755763/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/729813087",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-729813087",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 729813087,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyOTgxMzA4Nw==",
        "user": {
            "login": "quasiben",
            "id": 1403768,
            "node_id": "MDQ6VXNlcjE0MDM3Njg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1403768?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/quasiben",
            "html_url": "https://github.com/quasiben",
            "followers_url": "https://api.github.com/users/quasiben/followers",
            "following_url": "https://api.github.com/users/quasiben/following{/other_user}",
            "gists_url": "https://api.github.com/users/quasiben/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/quasiben/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/quasiben/subscriptions",
            "organizations_url": "https://api.github.com/users/quasiben/orgs",
            "repos_url": "https://api.github.com/users/quasiben/repos",
            "events_url": "https://api.github.com/users/quasiben/events{/privacy}",
            "received_events_url": "https://api.github.com/users/quasiben/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-18T16:58:22Z",
        "updated_at": "2020-11-18T16:58:22Z",
        "author_association": "MEMBER",
        "body": "I would expect this to actually have more memory consumption in the scheduler as you've laid it out.  With 11000000 rows and a chunksize of 50000, you end up with 220 nodes in the graph all of which will be 2.5 GBs so you should have 550GBs in the scheduler.  If instead you have have a chunksize of 5500000, there will be 2 nodes and ~5GBs on the scheduler.  \r\n\r\nIf you are curious, you can look at what the scheduler is holding onto with something like:\r\n```python\r\nIn [32]: keys = client.run_on_scheduler(lambda dask_scheduler: list(dask_scheduler.tasks.keys()))\r\n\r\nIn [33]: client.run_on_scheduler(lambda dask_scheduler: dask_scheduler.tasks[keys[0]].nbytes)\r\nOut[33]: 1232002128\r\n```\r\n\r\nSo, I don't think there is anything wrong here per-se.  As said in https://github.com/dask/distributed/issues/3032, there are policy decisions here and it's not obvious what dask _should_ do here to make the experience \"better\".  Instead, try to avoid loading data from memory and if they _have to_ quick process those tasks.  So instead of persisting the array, it would be better to move onto the next computation and persist that allowing the scheduler to release those tasks",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/729813087/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/729880661",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-729880661",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 729880661,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyOTg4MDY2MQ==",
        "user": {
            "login": "pseudotensor",
            "id": 2249614,
            "node_id": "MDQ6VXNlcjIyNDk2MTQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2249614?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pseudotensor",
            "html_url": "https://github.com/pseudotensor",
            "followers_url": "https://api.github.com/users/pseudotensor/followers",
            "following_url": "https://api.github.com/users/pseudotensor/following{/other_user}",
            "gists_url": "https://api.github.com/users/pseudotensor/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pseudotensor/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pseudotensor/subscriptions",
            "organizations_url": "https://api.github.com/users/pseudotensor/orgs",
            "repos_url": "https://api.github.com/users/pseudotensor/repos",
            "events_url": "https://api.github.com/users/pseudotensor/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pseudotensor/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-18T18:46:21Z",
        "updated_at": "2020-11-18T18:46:21Z",
        "author_association": "NONE",
        "body": "But why is there accumulation if one repeats the fit in a loop?  Once a task is done, why does the task graph continue to hold the arrays?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/729880661/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/729882496",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-729882496",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 729882496,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyOTg4MjQ5Ng==",
        "user": {
            "login": "pseudotensor",
            "id": 2249614,
            "node_id": "MDQ6VXNlcjIyNDk2MTQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2249614?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pseudotensor",
            "html_url": "https://github.com/pseudotensor",
            "followers_url": "https://api.github.com/users/pseudotensor/followers",
            "following_url": "https://api.github.com/users/pseudotensor/following{/other_user}",
            "gists_url": "https://api.github.com/users/pseudotensor/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pseudotensor/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pseudotensor/subscriptions",
            "organizations_url": "https://api.github.com/users/pseudotensor/orgs",
            "repos_url": "https://api.github.com/users/pseudotensor/repos",
            "events_url": "https://api.github.com/users/pseudotensor/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pseudotensor/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-18T18:49:40Z",
        "updated_at": "2020-11-18T18:49:40Z",
        "author_association": "NONE",
        "body": "The other point I made earlier. The task graph should never contain data, it can just contain a reference to the clients data.\r\n\r\nSame with files actually.   read_csv should be possible on the client alone, in the context of multinode with no shared disk, the client should be possible as a reference for where the file is, and any operations on the task graph should be able to keep that as a reference.  Currently the file has to be common to all nodes via shared disk.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/729882496/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/729893800",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-729893800",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 729893800,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyOTg5MzgwMA==",
        "user": {
            "login": "rjzamora",
            "id": 20461013,
            "node_id": "MDQ6VXNlcjIwNDYxMDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rjzamora",
            "html_url": "https://github.com/rjzamora",
            "followers_url": "https://api.github.com/users/rjzamora/followers",
            "following_url": "https://api.github.com/users/rjzamora/following{/other_user}",
            "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions",
            "organizations_url": "https://api.github.com/users/rjzamora/orgs",
            "repos_url": "https://api.github.com/users/rjzamora/repos",
            "events_url": "https://api.github.com/users/rjzamora/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rjzamora/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-18T19:10:35Z",
        "updated_at": "2020-11-18T19:10:54Z",
        "author_association": "MEMBER",
        "body": ">The other point I made earlier. The task graph should never contain data, it can just contain a reference to the clients data.\r\n\r\nThis seems straightforward on a local cluster, but a bit complicated when the cluster is distributed.  In the case of IO, all workers have access to a shared file system with an established API for accessing the data by its path.  Accessing remote data by memory reference seems less reliable.  Won't this require rmda support in both the software and hardware?   Note that I don't know much about this at all :)",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/729893800/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/729896726",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-729896726",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 729896726,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyOTg5NjcyNg==",
        "user": {
            "login": "pseudotensor",
            "id": 2249614,
            "node_id": "MDQ6VXNlcjIyNDk2MTQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2249614?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pseudotensor",
            "html_url": "https://github.com/pseudotensor",
            "followers_url": "https://api.github.com/users/pseudotensor/followers",
            "following_url": "https://api.github.com/users/pseudotensor/following{/other_user}",
            "gists_url": "https://api.github.com/users/pseudotensor/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pseudotensor/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pseudotensor/subscriptions",
            "organizations_url": "https://api.github.com/users/pseudotensor/orgs",
            "repos_url": "https://api.github.com/users/pseudotensor/repos",
            "events_url": "https://api.github.com/users/pseudotensor/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pseudotensor/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-18T19:16:07Z",
        "updated_at": "2020-11-18T19:16:07Z",
        "author_association": "NONE",
        "body": "Ya I'm thinking of distributed case too.  Both a file or in-memory object could be modified after read_csv or from_array() type operations are done.  So both have reliability issues but the API can be made robust to make it clear how things should function, e.g. shallow reference or deep copy.  But in any case, no need to store data on graph.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/729896726/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/729951218",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-729951218",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 729951218,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyOTk1MTIxOA==",
        "user": {
            "login": "quasiben",
            "id": 1403768,
            "node_id": "MDQ6VXNlcjE0MDM3Njg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1403768?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/quasiben",
            "html_url": "https://github.com/quasiben",
            "followers_url": "https://api.github.com/users/quasiben/followers",
            "following_url": "https://api.github.com/users/quasiben/following{/other_user}",
            "gists_url": "https://api.github.com/users/quasiben/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/quasiben/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/quasiben/subscriptions",
            "organizations_url": "https://api.github.com/users/quasiben/orgs",
            "repos_url": "https://api.github.com/users/quasiben/repos",
            "events_url": "https://api.github.com/users/quasiben/events{/privacy}",
            "received_events_url": "https://api.github.com/users/quasiben/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-18T21:01:58Z",
        "updated_at": "2020-11-18T21:01:58Z",
        "author_association": "MEMBER",
        "body": "> But why is there accumulation if one repeats the fit in a loop? Once a task is done, why does the task graph continue to hold the arrays?\r\n\r\nIn the case of a chunksize of `5500000` I don't see total memory exceeding 5.1GBs.  \r\n```python\r\nfor i in range(0, 20):\r\n    chunksize = 5500000\r\n    dX = dd.from_array(X.values, chunksize=chunksize)\r\n    dy = dd.from_array(y.values, chunksize=chunksize)\r\n\r\n    dX = dX.persist()\r\n    dy = dy.persist()\r\n    wait([dX, dy])\r\n```\r\n\r\nThe scheduler should (and does) clean up after futures which no longer are being held onto by worker or client.  This can be made more [aggressive](https://distributed.dask.org/en/latest/memory.html#aggressively-clearing-data) .\r\n\r\nBacking out for a minute, I think we've identified what is happening with the original issue.  It seems like now we are moving towards a discussion around whether Dask should support a new model for handling in memory data for `from_array`.  If that is the case, then I would suggest we close this issue and begin anew.  \r\n\r\nIf I am incorrect, apologies, what remaining issues are there ?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/729951218/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/730437694",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-730437694",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 730437694,
        "node_id": "MDEyOklzc3VlQ29tbWVudDczMDQzNzY5NA==",
        "user": {
            "login": "quasiben",
            "id": 1403768,
            "node_id": "MDQ6VXNlcjE0MDM3Njg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1403768?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/quasiben",
            "html_url": "https://github.com/quasiben",
            "followers_url": "https://api.github.com/users/quasiben/followers",
            "following_url": "https://api.github.com/users/quasiben/following{/other_user}",
            "gists_url": "https://api.github.com/users/quasiben/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/quasiben/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/quasiben/subscriptions",
            "organizations_url": "https://api.github.com/users/quasiben/orgs",
            "repos_url": "https://api.github.com/users/quasiben/repos",
            "events_url": "https://api.github.com/users/quasiben/events{/privacy}",
            "received_events_url": "https://api.github.com/users/quasiben/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-19T15:08:56Z",
        "updated_at": "2020-11-19T15:08:56Z",
        "author_association": "MEMBER",
        "body": "I was thinking again about this last night and I think you can avoid long term storage on scheduler all together with what I think you are doing. \r\n\r\nTypically, the first response to folks who have a large numpy array in memory and then want to move some dask collection is naively, don't do that.  Here, the assumption is that the data is loaded directly from disk and instead, the dask collection (array/dataframe) should be responsible for loading that data.  Perhaps in your case the data is loaded from disk, some processing happens locally then you end up with some NumPy array which you then want to combine with dask/xgboost \r\n\r\nIn this case, you could scatter the data the first then create a dask array:\r\n\r\n```python\r\nfuture = client.scatter(arr)\r\nx = da.from_delayed(future, shape=arr.shape, dtype=arr.dtype)\r\n```\r\n\r\nThe data will temporarily flow through the scheduler but end up on the workers.  All of this is nicely summarized in a stackoverflow post:\r\nhttps://stackoverflow.com/questions/45941528/how-to-efficiently-send-a-large-numpy-array-to-the-cluster-with-dask-array\r\n\r\nAgain, if you think there are better ways of managing in-memory data from the client then we could continue that discussion in a separate issue",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/730437694/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/730713218",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-730713218",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 730713218,
        "node_id": "MDEyOklzc3VlQ29tbWVudDczMDcxMzIxOA==",
        "user": {
            "login": "trivialfis",
            "id": 16746409,
            "node_id": "MDQ6VXNlcjE2NzQ2NDA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/16746409?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/trivialfis",
            "html_url": "https://github.com/trivialfis",
            "followers_url": "https://api.github.com/users/trivialfis/followers",
            "following_url": "https://api.github.com/users/trivialfis/following{/other_user}",
            "gists_url": "https://api.github.com/users/trivialfis/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/trivialfis/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/trivialfis/subscriptions",
            "organizations_url": "https://api.github.com/users/trivialfis/orgs",
            "repos_url": "https://api.github.com/users/trivialfis/repos",
            "events_url": "https://api.github.com/users/trivialfis/events{/privacy}",
            "received_events_url": "https://api.github.com/users/trivialfis/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-20T00:02:33Z",
        "updated_at": "2020-11-20T00:02:33Z",
        "author_association": "CONTRIBUTOR",
        "body": "Those are useful references.  I think it might be best for xgboost to list some of these discussions in its doc.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/730713218/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/731445019",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-731445019",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 731445019,
        "node_id": "MDEyOklzc3VlQ29tbWVudDczMTQ0NTAxOQ==",
        "user": {
            "login": "pseudotensor",
            "id": 2249614,
            "node_id": "MDQ6VXNlcjIyNDk2MTQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2249614?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pseudotensor",
            "html_url": "https://github.com/pseudotensor",
            "followers_url": "https://api.github.com/users/pseudotensor/followers",
            "following_url": "https://api.github.com/users/pseudotensor/following{/other_user}",
            "gists_url": "https://api.github.com/users/pseudotensor/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pseudotensor/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pseudotensor/subscriptions",
            "organizations_url": "https://api.github.com/users/pseudotensor/orgs",
            "repos_url": "https://api.github.com/users/pseudotensor/repos",
            "events_url": "https://api.github.com/users/pseudotensor/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pseudotensor/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-20T22:44:21Z",
        "updated_at": "2020-11-20T22:44:44Z",
        "author_association": "NONE",
        "body": "In the original xgboost script the accumulation was ongoing and futures were never cleaned up.  I would continuously hit OOM killer over periods of time.  Client process being done didn't matter, scheduler/worker still persist the data uncleaned.\r\n\r\nSo maybe you found way around the attempt at a repro by @trivialfis , but the original issue cannot be explained then.\r\n\r\nAlso, chunk size shouldn't matter for accumulation problem.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/731445019/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/731624326",
        "html_url": "https://github.com/dask/dask/issues/6833#issuecomment-731624326",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/6833",
        "id": 731624326,
        "node_id": "MDEyOklzc3VlQ29tbWVudDczMTYyNDMyNg==",
        "user": {
            "login": "quasiben",
            "id": 1403768,
            "node_id": "MDQ6VXNlcjE0MDM3Njg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1403768?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/quasiben",
            "html_url": "https://github.com/quasiben",
            "followers_url": "https://api.github.com/users/quasiben/followers",
            "following_url": "https://api.github.com/users/quasiben/following{/other_user}",
            "gists_url": "https://api.github.com/users/quasiben/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/quasiben/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/quasiben/subscriptions",
            "organizations_url": "https://api.github.com/users/quasiben/orgs",
            "repos_url": "https://api.github.com/users/quasiben/repos",
            "events_url": "https://api.github.com/users/quasiben/events{/privacy}",
            "received_events_url": "https://api.github.com/users/quasiben/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-21T19:21:00Z",
        "updated_at": "2020-11-21T19:21:00Z",
        "author_association": "MEMBER",
        "body": "@pseudotensor can you link to or rewrite the reproducer.  https://github.com/dask/dask/issues/6833#issuecomment-726492018 is a good start but I'd like to have X and y explicitly stated.  It's best if it can be can be reproduced without downloading a file (using random data or dask.datasets.timeseries()) but using HIGGS.csv or some other canonical dataset would be ok.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/731624326/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]