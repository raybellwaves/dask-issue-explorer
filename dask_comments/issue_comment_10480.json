[
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1698613793",
        "html_url": "https://github.com/dask/dask/issues/10480#issuecomment-1698613793",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/10480",
        "id": 1698613793,
        "node_id": "IC_kwDOAbcwm85lPsoh",
        "user": {
            "login": "RobbeSneyders",
            "id": 20990866,
            "node_id": "MDQ6VXNlcjIwOTkwODY2",
            "avatar_url": "https://avatars.githubusercontent.com/u/20990866?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RobbeSneyders",
            "html_url": "https://github.com/RobbeSneyders",
            "followers_url": "https://api.github.com/users/RobbeSneyders/followers",
            "following_url": "https://api.github.com/users/RobbeSneyders/following{/other_user}",
            "gists_url": "https://api.github.com/users/RobbeSneyders/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RobbeSneyders/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RobbeSneyders/subscriptions",
            "organizations_url": "https://api.github.com/users/RobbeSneyders/orgs",
            "repos_url": "https://api.github.com/users/RobbeSneyders/repos",
            "events_url": "https://api.github.com/users/RobbeSneyders/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RobbeSneyders/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-08-30T07:07:04Z",
        "updated_at": "2023-08-30T07:07:04Z",
        "author_association": "NONE",
        "body": "When scaling up to 10 partitions, the `processes` scheduler does seem to write partitions intermediately, but it still batches them.\r\n\r\n**processes**\r\n\r\n> `time python test.py`\r\n> real    0m30,122s\r\n> user    0m30,225s\r\n> sys     0m2,255s\r\n> \r\n> `ls --full-time /tmp/url`\r\n> total 40\r\n> 2023-08-30 08:58:01.143333792 +0200 part.0.parquet\r\n> 2023-08-30 08:58:01.139333868 +0200 part.1.parquet\r\n> 2023-08-30 08:58:01.139333868 +0200 part.2.parquet\r\n> 2023-08-30 08:58:01.131334019 +0200 part.3.parquet\r\n> 2023-08-30 08:58:01.131334019 +0200 part.4.parquet\r\n> 2023-08-30 08:58:01.127334095 +0200 part.5.parquet\r\n> 2023-08-30 08:58:10.655152933 +0200 part.6.parquet\r\n> 2023-08-30 08:58:10.651153010 +0200 part.7.parquet\r\n> 2023-08-30 08:58:10.651153010 +0200 part.8.parquet\r\n> 2023-08-30 08:58:10.647153086 +0200 part.9.parquet\r\n\r\n**threads**\r\n\r\n> `time python test.py`\r\n> real    0m28,275s\r\n> user    0m28,261s\r\n> sys     0m1,257s\r\n> \r\n> `ls --full-time /tmp/url`\r\n> total 40\r\n> 2023-08-30 08:58:29.002804041 +0200 part.0.parquet\r\n> 2023-08-30 08:58:31.466757184 +0200 part.1.parquet\r\n> 2023-08-30 08:58:33.938710174 +0200 part.2.parquet\r\n> 2023-08-30 08:58:36.446662479 +0200 part.3.parquet\r\n> 2023-08-30 08:58:38.906615696 +0200 part.4.parquet\r\n> 2023-08-30 08:58:41.418567924 +0200 part.5.parquet\r\n> 2023-08-30 08:58:43.926520227 +0200 part.6.parquet\r\n> 2023-08-30 08:58:46.462471996 +0200 part.7.parquet\r\n> 2023-08-30 08:58:48.974424221 +0200 part.8.parquet\r\n> 2023-08-30 08:58:51.506376066 +0200 part.9.parquet\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1698613793/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1769177922",
        "html_url": "https://github.com/dask/dask/issues/10480#issuecomment-1769177922",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/10480",
        "id": 1769177922,
        "node_id": "IC_kwDOAbcwm85pc4NC",
        "user": {
            "login": "rjzamora",
            "id": 20461013,
            "node_id": "MDQ6VXNlcjIwNDYxMDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rjzamora",
            "html_url": "https://github.com/rjzamora",
            "followers_url": "https://api.github.com/users/rjzamora/followers",
            "following_url": "https://api.github.com/users/rjzamora/following{/other_user}",
            "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions",
            "organizations_url": "https://api.github.com/users/rjzamora/orgs",
            "repos_url": "https://api.github.com/users/rjzamora/repos",
            "events_url": "https://api.github.com/users/rjzamora/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rjzamora/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-10-18T19:22:23Z",
        "updated_at": "2023-10-18T19:22:23Z",
        "author_association": "MEMBER",
        "body": "Sorry for the delayed response here.\r\n\r\nIn order to get a better idea of what the graph will actually look like on the scheduler, I recommend that you pass `optimize_graph=True` to `dask.visualize` (e.g. `dask.visualize(*write_tasks, optimize_graph=True, filename=\"graph.png\")`. Locally, I see something like:\r\n\r\n![graph](https://github.com/dask/dask/assets/20461013/cc813482-88e2-4ca6-bd04-33318ca32def)\r\n\r\nThe visualization now reflects that dask will be fusing most partition-wise tasks together, but cannot do so for the actual `to-parquet` tasks (because of the non-partition-wise store-to-parquet dependencies).\r\n\r\nThis is all to say that you are probably blocked by the use of the \"store-to-parquet\" task in `to_parquet`, because the algorithm used for that API call is not ideal when you plan to compute multiple `to_parquet` operations at once. This task has also cause pain in some other places (https://github.com/dask/dask/issues/10463).\r\n\r\nI will try to think if there is a good way to improve the API. However, it is always possible to use `map_partitions` for \"manual\" task fusion.  E.g.:\r\n\r\n```python\r\nimport dask.dataframe as dd\r\nimport os\r\n\r\n\r\ndef process_partition(df):\r\n    counter = 0\r\n    while counter < 100000000:\r\n        counter += 1\r\n    return df\r\n\r\ndef write_partition(df, index_path, url_path, partition_info=None):\r\n    os.makedirs(index_path, exist_ok=True)\r\n    os.makedirs(url_path, exist_ok=True)\r\n    if partition_info:\r\n        index = partition_info[\"number\"]\r\n        df[[\"id\"]].to_parquet(f\"{index_path}/part.{index}.parquet\")\r\n        df[[\"url\"]].to_parquet(f\"{url_path}/part.{index}.parquet\")\r\n    return True\r\n\r\ndataframe = dd.from_dict({\"id\": [0, 1], \"url\": [\"a\", \"b\"]}, npartitions=2)\r\ndataframe = dataframe.map_partitions(\r\n    process_partition,\r\n).map_partitions(\r\n    write_partition,\r\n    \"./id\",\r\n    \"./url\",\r\n)\r\n\r\ndataframe.visualize(filename=\"graph.png\", optimize_graph=True)\r\ndataframe.compute()\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1769177922/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1798025255",
        "html_url": "https://github.com/dask/dask/issues/10480#issuecomment-1798025255",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/10480",
        "id": 1798025255,
        "node_id": "IC_kwDOAbcwm85rK7An",
        "user": {
            "login": "RobbeSneyders",
            "id": 20990866,
            "node_id": "MDQ6VXNlcjIwOTkwODY2",
            "avatar_url": "https://avatars.githubusercontent.com/u/20990866?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RobbeSneyders",
            "html_url": "https://github.com/RobbeSneyders",
            "followers_url": "https://api.github.com/users/RobbeSneyders/followers",
            "following_url": "https://api.github.com/users/RobbeSneyders/following{/other_user}",
            "gists_url": "https://api.github.com/users/RobbeSneyders/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RobbeSneyders/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RobbeSneyders/subscriptions",
            "organizations_url": "https://api.github.com/users/RobbeSneyders/orgs",
            "repos_url": "https://api.github.com/users/RobbeSneyders/repos",
            "events_url": "https://api.github.com/users/RobbeSneyders/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RobbeSneyders/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-11-07T08:26:46Z",
        "updated_at": "2023-11-07T08:26:46Z",
        "author_association": "NONE",
        "body": "Hi @rjzamora, thanks for the response!\r\n\r\nWe tried using `map_partitions` and removing the `store-to-parquet` task in other ways. We were successful in creating a fully parallelized graph this way, but still ran into the same issue when using the `processes` scheduler. In the end, we switched to the `distributed.LocalCluster` which does release the processed partitions, even with the original graph.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1798025255/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1798148362",
        "html_url": "https://github.com/dask/dask/issues/10480#issuecomment-1798148362",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/10480",
        "id": 1798148362,
        "node_id": "IC_kwDOAbcwm85rLZEK",
        "user": {
            "login": "fjetter",
            "id": 8629629,
            "node_id": "MDQ6VXNlcjg2Mjk2Mjk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8629629?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fjetter",
            "html_url": "https://github.com/fjetter",
            "followers_url": "https://api.github.com/users/fjetter/followers",
            "following_url": "https://api.github.com/users/fjetter/following{/other_user}",
            "gists_url": "https://api.github.com/users/fjetter/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fjetter/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fjetter/subscriptions",
            "organizations_url": "https://api.github.com/users/fjetter/orgs",
            "repos_url": "https://api.github.com/users/fjetter/repos",
            "events_url": "https://api.github.com/users/fjetter/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fjetter/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-11-07T09:44:35Z",
        "updated_at": "2023-11-07T09:44:35Z",
        "author_association": "MEMBER",
        "body": "> In the end, we switched to the distributed.LocalCluster which does release the processed partitions, even with the original graph.\r\n\r\nI recommend using LocalCluster for everything. It comes with many optimizations we cannot do in the simple threaded/process executor and comes with diagnostics and a dashboard that are otherwise also not available, see https://docs.dask.org/en/stable/dashboard.html",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1798148362/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]