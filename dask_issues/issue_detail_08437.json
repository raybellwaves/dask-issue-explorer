{
    "url": "https://api.github.com/repos/dask/dask/issues/8437",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/8437/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/8437/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/8437/events",
    "html_url": "https://github.com/dask/dask/issues/8437",
    "id": 1067879313,
    "node_id": "I_kwDOAbcwm84_pouR",
    "number": 8437,
    "title": "When `divisions` has repeats, `set_index` puts all data in the last partition instead of balancing it",
    "user": {
        "login": "gjoseph92",
        "id": 3309802,
        "node_id": "MDQ6VXNlcjMzMDk4MDI=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3309802?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/gjoseph92",
        "html_url": "https://github.com/gjoseph92",
        "followers_url": "https://api.github.com/users/gjoseph92/followers",
        "following_url": "https://api.github.com/users/gjoseph92/following{/other_user}",
        "gists_url": "https://api.github.com/users/gjoseph92/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/gjoseph92/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/gjoseph92/subscriptions",
        "organizations_url": "https://api.github.com/users/gjoseph92/orgs",
        "repos_url": "https://api.github.com/users/gjoseph92/repos",
        "events_url": "https://api.github.com/users/gjoseph92/events{/privacy}",
        "received_events_url": "https://api.github.com/users/gjoseph92/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2021-12-01T02:25:16Z",
    "updated_at": "2021-12-01T09:14:44Z",
    "closed_at": null,
    "author_association": "MEMBER",
    "active_lock_reason": null,
    "body": "Reported in https://stackoverflow.com/a/70178087/17100540 by @DahnJ.\r\n\r\nGiven imbalanced data, you want the same value to be split across multiple output partitions:\r\n```python\r\nIn [1]: import dask.dataframe as dd\r\nIn [2]: import pandas as pd\r\nIn [3]: df = pd.DataFrame({\"A\": [0] * 10, \"B\": range(10)})\r\nIn [4]: ddf = dd.from_pandas(df, npartitions=5)\r\nIn [5]: s = ddf.set_index(\"A\")\r\nIn [6]: s.divisions\r\n(0, 0, 0, 0, 0, 0)\r\n```\r\n\r\nHowever, when the shuffle actually happens, all the data ends up in the last possible partition:\r\n```python\r\nIn [6]: dask.compute(*s.to_delayed())\r\nOut[6]: \r\n(Empty DataFrame\r\n Columns: [B]\r\n Index: [],\r\n Empty DataFrame\r\n Columns: [B]\r\n Index: [],\r\n Empty DataFrame\r\n Columns: [B]\r\n Index: [],\r\n Empty DataFrame\r\n Columns: [B]\r\n Index: [],\r\n    B\r\n A   \r\n 0  2\r\n 0  3\r\n 0  4\r\n 0  5\r\n 0  8\r\n 0  9\r\n 0  0\r\n 0  1\r\n 0  6\r\n 0  7)\r\n```\r\n\r\n_EDIT: I realized that although `set_index` will calculate `(0, 0, 0, 0, 0, 0)` as good divisions, if you pass in `divisions=(0, 0, 0, 0, 0, 0)`, you'll get `ValueError: New division must be unique, except for the last element`. So clearly there's some disagreement about whether repeated values are even valid divisions (xref https://github.com/dask/dask/pull/8393, cc @charlesbluca). This, plus @SultanOrazbayev's last code snippet [on SO](https://stackoverflow.com/a/69616798/17100540), makes me think DataFrame generally doesn't support duplicate divisions, and it's simply a bug that `set_index` doesn't deduplicate the output of `partition_quantiles`. That said, I think we should support duplicate divisions, since it's a reasonable thing to need when you have imbalanced data._\r\n\r\nThe problem is in the [`set_partitions_pre`](https://github.com/dask/dask/blob/a5aecac8313fea30c5503f534c71f325b1775b9c/dask/dataframe/shuffle.py#L793-L813) step of `set_index`, where we calculate which output partition number each row should belong to. We call `searchsorted` on `divisions` (as a Series); `s` is the values we're reindexing by:\r\nhttps://github.com/dask/dask/blob/a5aecac8313fea30c5503f534c71f325b1775b9c/dask/dataframe/shuffle.py#L796\r\n\r\nBecause of `side=\"right\"`, when there are duplicate values in `divisions`, `searchsorted` always returns the index of the last duplicate\u2014hence why all the data ends up in the last possible partition. With `side=\"left\"`, it would be the other way around (all data in the first partition).\r\n\r\nWith some clever counting, I think we could deal with this while still using `searchsorted`. We'd probably want to remove duplicates from `divisions` and keep an auxiliary list of how many duplicates each division has (basically [compute a run-length encoding](https://stackoverflow.com/a/69693227/17100540)). Then, if the output partition for a row has duplicates, we pick randomly between the N options? Or something like that.\r\n\r\nThe way the output partition is selected from N options is probably the trickiest part. Assuming that `divisions` represents an approximately uniform partitioning of the data, then I _think_ picking from the N options at random would maintain that desired distribution.\r\n\r\nThough I'm not sure how to handle the \"edge\" partitions. For `divisions=(0, 1, 1, 2)`, a value of `1` could go to any of the three output partitions. However, the first and last partitions will also get `0`s and `2`s, respectively, whereas the middle partition will only get `1`s. So to maintain uniform partition sizes, you'd want to send more `1`s to the middle partition than the others\u2014basically bias the random selection towards that? The problem is, you don't know how much to do so, because you don't know how many `1`s there are relative to `0`s and `2`s, or even how many other values there are between `0` and `1`.\r\n\r\n**Environment**:\r\n\r\n- Dask version: a5aecac8313fea30c5503f534c71f325b1775b9c\r\n- Python version: 3.8.8\r\n- Operating System: macOS\r\n- Install method (conda, pip, source): source",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/8437/reactions",
        "total_count": 4,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 2,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/8437/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}