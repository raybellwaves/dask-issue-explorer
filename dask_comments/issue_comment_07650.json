[
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/853961232",
        "html_url": "https://github.com/dask/dask/issues/7650#issuecomment-853961232",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/7650",
        "id": 853961232,
        "node_id": "MDEyOklzc3VlQ29tbWVudDg1Mzk2MTIzMg==",
        "user": {
            "login": "rjzamora",
            "id": 20461013,
            "node_id": "MDQ6VXNlcjIwNDYxMDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rjzamora",
            "html_url": "https://github.com/rjzamora",
            "followers_url": "https://api.github.com/users/rjzamora/followers",
            "following_url": "https://api.github.com/users/rjzamora/following{/other_user}",
            "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions",
            "organizations_url": "https://api.github.com/users/rjzamora/orgs",
            "repos_url": "https://api.github.com/users/rjzamora/repos",
            "events_url": "https://api.github.com/users/rjzamora/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rjzamora/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-06-03T15:33:18Z",
        "updated_at": "2021-06-03T15:33:18Z",
        "author_association": "MEMBER",
        "body": "I totally agree that we should try to move away from `dumps_task` in cases where it requires the task `callable`  to handle serialization at run time. Just some notes...\r\n\r\n>which leads to pickling on the scheduler, which we want to avoid.\r\n\r\nRight - we would like to avoid any use of pickle on the scheduler (in case pickle is disabled entirely), however the main concern is that we cannot call `pickle.loads` on the scheduler.  The cases you have highlighted above do not require `pickle.loads`.\r\n\r\n>Additionally, could this manual use of pickle.dumps in BroadcastJoinLayer.__dask_distributed_pack__ lead to a double-pickle scenario, where when the task actually gets executed, the kwarg values are bytestrings, not the actual unpickled values\r\n\r\nYes - This is exactly what is expected to happen now.  This is why the functions used within the broadcast-join tasks currently check if anything needs to be unpickled on the worker.  We avoided this issue in `Blockwise` by relying on `to_serialize`.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/853961232/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]