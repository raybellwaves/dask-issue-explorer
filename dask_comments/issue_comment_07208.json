[
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/779948085",
        "html_url": "https://github.com/dask/dask/issues/7208#issuecomment-779948085",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/7208",
        "id": 779948085,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc3OTk0ODA4NQ==",
        "user": {
            "login": "jsignell",
            "id": 4806877,
            "node_id": "MDQ6VXNlcjQ4MDY4Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4806877?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jsignell",
            "html_url": "https://github.com/jsignell",
            "followers_url": "https://api.github.com/users/jsignell/followers",
            "following_url": "https://api.github.com/users/jsignell/following{/other_user}",
            "gists_url": "https://api.github.com/users/jsignell/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jsignell/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jsignell/subscriptions",
            "organizations_url": "https://api.github.com/users/jsignell/orgs",
            "repos_url": "https://api.github.com/users/jsignell/repos",
            "events_url": "https://api.github.com/users/jsignell/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jsignell/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-02-16T16:21:54Z",
        "updated_at": "2021-02-16T16:21:54Z",
        "author_association": "MEMBER",
        "body": "hmm I am having trouble reproducing this. When I run your examples I see the same size and shape. Where you looking at something else?\r\n\r\n```python\r\nIn [1]: import numpy as np\r\n   ...: from skimage.util import view_as_windows  # cleaner than using stride_tricks directly\r\n   ...: import dask.array as da\r\n   ...: \r\n   ...: size= 10000\r\n   ...: \r\n   ...: numpy_array = view_as_windows(np.arange(size*size).reshape(size,size), (5,5))\r\n   ...: \r\n   ...: foo = da.from_array(numpy_array)\r\n\r\nIn [2]: numpy_array.shape, numpy_array.size\r\nOut[2]: ((9996, 9996, 5, 5), 2498000400)\r\n\r\nIn [3]: foo.shape, foo.size\r\nOut[3]: ((9996, 9996, 5, 5), 2498000400)\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/779948085/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/779984729",
        "html_url": "https://github.com/dask/dask/issues/7208#issuecomment-779984729",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/7208",
        "id": 779984729,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc3OTk4NDcyOQ==",
        "user": {
            "login": "FirefoxMetzger",
            "id": 4402489,
            "node_id": "MDQ6VXNlcjQ0MDI0ODk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4402489?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/FirefoxMetzger",
            "html_url": "https://github.com/FirefoxMetzger",
            "followers_url": "https://api.github.com/users/FirefoxMetzger/followers",
            "following_url": "https://api.github.com/users/FirefoxMetzger/following{/other_user}",
            "gists_url": "https://api.github.com/users/FirefoxMetzger/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/FirefoxMetzger/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/FirefoxMetzger/subscriptions",
            "organizations_url": "https://api.github.com/users/FirefoxMetzger/orgs",
            "repos_url": "https://api.github.com/users/FirefoxMetzger/repos",
            "events_url": "https://api.github.com/users/FirefoxMetzger/events{/privacy}",
            "received_events_url": "https://api.github.com/users/FirefoxMetzger/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-02-16T17:13:11Z",
        "updated_at": "2021-02-16T17:15:06Z",
        "author_association": "CONTRIBUTOR",
        "body": "Yes, the `size` and `shape` are exactly the same for both arrays. The amount of memory consumed, however, is not; that's the cool thing about custom striding. I don't know if I can show this when directly comparing to a dask array (couldn't find a strides attribute), so here is the comparison in pure numpy\r\n\r\n```python\r\nimport numpy as np\r\nfrom skimage.util import view_as_windows\r\nsize = 5000  # my workstation can't handle size=10000 inflated :(\r\n\r\n# occupies ~ 100Mb in memory\r\nstrided_array = view_as_windows(np.arange(size*size).reshape(size,size), (5,5))\r\n\r\n# occupies ~ 2.5Gb in memory\r\nnormal_array = strided_array.copy() \r\n\r\nprint(strided_array.strides)  # (400, 4, 400, 4)\r\nprint(normal_array.strides) # (9600, 100, 20, 4)\r\n```\r\n\r\nThe difference is subtle but really important. If you monitor the actual memory used by the process (task-manager / `htop` / etc.), you should see that creating `strided_array` barely allocates additional memory, but that creating `normal_array` significantly increases the memory consumed. Same story for `numpy_array` and `dask_array`",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/779984729/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/783520367",
        "html_url": "https://github.com/dask/dask/issues/7208#issuecomment-783520367",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/7208",
        "id": 783520367,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc4MzUyMDM2Nw==",
        "user": {
            "login": "jsignell",
            "id": 4806877,
            "node_id": "MDQ6VXNlcjQ4MDY4Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4806877?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jsignell",
            "html_url": "https://github.com/jsignell",
            "followers_url": "https://api.github.com/users/jsignell/followers",
            "following_url": "https://api.github.com/users/jsignell/following{/other_user}",
            "gists_url": "https://api.github.com/users/jsignell/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jsignell/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jsignell/subscriptions",
            "organizations_url": "https://api.github.com/users/jsignell/orgs",
            "repos_url": "https://api.github.com/users/jsignell/repos",
            "events_url": "https://api.github.com/users/jsignell/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jsignell/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-02-22T17:00:26Z",
        "updated_at": "2021-02-22T17:00:26Z",
        "author_association": "MEMBER",
        "body": "Thank you for adding the additional information. I am going to read more about strides but I suspect that there isn't any special handling for strides in the dask codebase. Maybe someone in @dask/array will be more helpful than me :)",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/783520367/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/783550296",
        "html_url": "https://github.com/dask/dask/issues/7208#issuecomment-783550296",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/7208",
        "id": 783550296,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc4MzU1MDI5Ng==",
        "user": {
            "login": "dcherian",
            "id": 2448579,
            "node_id": "MDQ6VXNlcjI0NDg1Nzk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2448579?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dcherian",
            "html_url": "https://github.com/dcherian",
            "followers_url": "https://api.github.com/users/dcherian/followers",
            "following_url": "https://api.github.com/users/dcherian/following{/other_user}",
            "gists_url": "https://api.github.com/users/dcherian/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dcherian/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dcherian/subscriptions",
            "organizations_url": "https://api.github.com/users/dcherian/orgs",
            "repos_url": "https://api.github.com/users/dcherian/repos",
            "events_url": "https://api.github.com/users/dcherian/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dcherian/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-02-22T17:45:19Z",
        "updated_at": "2021-02-22T17:45:42Z",
        "author_association": "MEMBER",
        "body": ":) #7234 implements the `as_strided` trick with `map_overlap`. Maybe you can test it out or do something similar\r\n\r\nTo be clear, are you concerned about memory usage while computing or memory usage when calling `from_array`. If the latter, I don't see it when profiling \r\n```\r\n%load_ext memory_profiler\r\n%mprun -f da.from_array da.from_array(numpy_array)\r\n```\r\n\r\n<details>\r\n<summary>Details</summary>\r\n\r\n```\r\nFilename: /home/deepak/miniconda3/envs/dcpy/lib/python3.8/site-packages/dask/array/core.py\r\n\r\nLine #    Mem usage    Increment  Occurences   Line Contents\r\n============================================================\r\n  2899    232.6 MiB    232.6 MiB           1   def from_array(\r\n  2900                                             x,\r\n  2901                                             chunks=\"auto\",\r\n  2902                                             name=None,\r\n  2903                                             lock=False,\r\n  2904                                             asarray=None,\r\n  2905                                             fancy=True,\r\n  2906                                             getitem=None,\r\n  2907                                             meta=None,\r\n  2908                                             inline_array=False,\r\n  2909                                         ):\r\n...\r\n  3036    232.6 MiB      0.0 MiB           1       if isinstance(x, Array):\r\n  3037                                                 raise ValueError(\r\n  3038                                                     \"Array is already a dask array. Use 'asarray' or \" \"'rechunk' instead.\"\r\n  3039                                                 )\r\n  3040    232.6 MiB      0.0 MiB           1       elif is_dask_collection(x):\r\n  3041                                                 warnings.warn(\r\n  3042                                                     \"Passing an object to dask.array.from_array which is already a \"\r\n  3043                                                     \"Dask collection. This can lead to unexpected behavior.\"\r\n  3044                                                 )\r\n  3045                                         \r\n  3046    232.6 MiB      0.0 MiB           1       if isinstance(x, (list, tuple, memoryview) + np.ScalarType):\r\n  3047                                                 x = np.array(x)\r\n  3048                                         \r\n  3049    232.6 MiB      0.0 MiB           1       if asarray is None:\r\n  3050    232.6 MiB      0.0 MiB           1           asarray = not hasattr(x, \"__array_function__\")\r\n  3051                                         \r\n  3052    232.6 MiB      0.0 MiB           1       previous_chunks = getattr(x, \"chunks\", None)\r\n  3053                                         \r\n  3054    232.6 MiB      0.0 MiB           2       chunks = normalize_chunks(\r\n  3055    232.6 MiB      0.0 MiB           1           chunks, x.shape, dtype=x.dtype, previous_chunks=previous_chunks\r\n  3056                                             )\r\n  3057                                         \r\n  3058    232.6 MiB      0.0 MiB           1       if name in (None, True):\r\n  3059    232.6 MiB      0.0 MiB           1           token = tokenize(x, chunks)\r\n  3060    232.6 MiB      0.0 MiB           1           original_name = \"array-original-\" + token\r\n  3061    232.6 MiB      0.0 MiB           1           name = name or \"array-\" + token\r\n  3062                                             elif name is False:\r\n  3063                                                 original_name = name = \"array-\" + str(uuid.uuid1())\r\n  3064                                             else:\r\n  3065                                                 original_name = name\r\n  3066                                         \r\n  3067    232.6 MiB      0.0 MiB           1       if lock is True:\r\n  3068                                                 lock = SerializableLock()\r\n  3069                                         \r\n  3070    232.6 MiB      0.0 MiB           1       is_ndarray = type(x) is np.ndarray\r\n  3071    232.6 MiB      0.0 MiB           4       is_single_block = all(len(c) == 1 for c in chunks)\r\n  3072                                             # Always use the getter for h5py etc. Not using isinstance(x, np.ndarray)\r\n  3073                                             # because np.matrix is a subclass of np.ndarray.\r\n  3074    232.6 MiB      0.0 MiB           1       if is_ndarray and not is_single_block and not lock:\r\n  3075                                                 # eagerly slice numpy arrays to prevent memory blowup\r\n  3076                                                 # GH5367, GH5601\r\n  3077    232.6 MiB      0.0 MiB           1           slices = slices_from_chunks(chunks)\r\n  3078    232.6 MiB      0.0 MiB          11           keys = product([name], *(range(len(bds)) for bds in chunks))\r\n  3079    232.6 MiB      0.0 MiB           7           values = [x[slc] for slc in slices]\r\n  3080    232.6 MiB      0.0 MiB           1           dsk = dict(zip(keys, values))\r\n  3081                                         \r\n  3082                                             elif is_ndarray and is_single_block:\r\n  3083                                                 # No slicing needed\r\n  3084                                                 dsk = {(name,) + (0,) * x.ndim: x}\r\n  3085                                             else:\r\n  3086                                                 if getitem is None:\r\n  3087                                                     if fancy:\r\n  3088                                                         getitem = getter\r\n  3089                                                     else:\r\n  3090                                                         getitem = getter_nofancy\r\n  3091                                         \r\n  3092                                                 if inline_array:\r\n  3093                                                     get_from = x\r\n  3094                                                 else:\r\n  3095                                                     get_from = original_name\r\n  3096                                         \r\n  3097                                                 dsk = getem(\r\n  3098                                                     get_from,\r\n  3099                                                     chunks,\r\n  3100                                                     getitem=getitem,\r\n  3101                                                     shape=x.shape,\r\n  3102                                                     out_name=name,\r\n  3103                                                     lock=lock,\r\n  3104                                                     asarray=asarray,\r\n  3105                                                     dtype=x.dtype,\r\n  3106                                                 )\r\n  3107                                                 if not inline_array:\r\n  3108                                                     dsk[original_name] = x\r\n  3109                                         \r\n  3110                                             # Workaround for TileDB, its indexing is 1-based,\r\n  3111                                             # and doesn't seems to support 0-length slicing\r\n  3112    232.6 MiB      0.0 MiB           1       if x.__class__.__module__.split(\".\")[0] == \"tiledb\" and hasattr(x, \"_ctx_\"):\r\n  3113                                                 return Array(dsk, name, chunks, dtype=x.dtype)\r\n  3114                                         \r\n  3115    232.6 MiB      0.0 MiB           1       if meta is None:\r\n  3116    232.6 MiB      0.0 MiB           1           meta = x\r\n  3117                                         \r\n  3118    232.6 MiB      0.0 MiB           1       return Array(dsk, name, chunks, meta=meta, dtype=getattr(x, \"dtype\", None))\r\n\r\n\r\n```\r\n\r\n\r\n</details>\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/783550296/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/783597114",
        "html_url": "https://github.com/dask/dask/issues/7208#issuecomment-783597114",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/7208",
        "id": 783597114,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc4MzU5NzExNA==",
        "user": {
            "login": "FirefoxMetzger",
            "id": 4402489,
            "node_id": "MDQ6VXNlcjQ0MDI0ODk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4402489?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/FirefoxMetzger",
            "html_url": "https://github.com/FirefoxMetzger",
            "followers_url": "https://api.github.com/users/FirefoxMetzger/followers",
            "following_url": "https://api.github.com/users/FirefoxMetzger/following{/other_user}",
            "gists_url": "https://api.github.com/users/FirefoxMetzger/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/FirefoxMetzger/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/FirefoxMetzger/subscriptions",
            "organizations_url": "https://api.github.com/users/FirefoxMetzger/orgs",
            "repos_url": "https://api.github.com/users/FirefoxMetzger/repos",
            "events_url": "https://api.github.com/users/FirefoxMetzger/events{/privacy}",
            "received_events_url": "https://api.github.com/users/FirefoxMetzger/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-02-22T18:57:22Z",
        "updated_at": "2021-02-22T18:59:35Z",
        "author_association": "CONTRIBUTOR",
        "body": "Yes, @dcherian I am talking about the `from_array` call. I am getting the same results as you when I try the snippet you posted:\r\n\r\n<details>\r\n<summary>mprun Output</summary>\r\n\r\n```\r\nLine #    Mem usage    Increment  Occurences   Line Contents\r\n============================================================\r\n  2683    321.0 MiB    321.0 MiB           1   def from_array(\r\n  2684                                             x,\r\n  2685                                             chunks=\"auto\",\r\n  2686                                             name=None,\r\n  2687                                             lock=False,\r\n  2688                                             asarray=None,\r\n  2689                                             fancy=True,\r\n  2690                                             getitem=None,\r\n  2691                                             meta=None,\r\n  2692                                         ):\r\n  2693                                             \"\"\" Create dask array from something that looks like an array\r\n  2694                                         \r\n  2695                                             Input must have a ``.shape``, ``.ndim``, ``.dtype`` and support numpy-style slicing.\r\n  2696                                         \r\n  2697                                             Parameters\r\n  2698                                             ----------\r\n  2699                                             x : array_like\r\n  2700                                             chunks : int, tuple\r\n  2701                                                 How to chunk the array. Must be one of the following forms:\r\n  2702                                         \r\n  2703                                                 - A blocksize like 1000.\r\n  2704                                                 - A blockshape like (1000, 1000).\r\n  2705                                                 - Explicit sizes of all blocks along all dimensions like\r\n  2706                                                   ((1000, 1000, 500), (400, 400)).\r\n  2707                                                 - A size in bytes, like \"100 MiB\" which will choose a uniform\r\n  2708                                                   block-like shape\r\n  2709                                                 - The word \"auto\" which acts like the above, but uses a configuration\r\n  2710                                                   value ``array.chunk-size`` for the chunk size\r\n  2711                                         \r\n  2712                                                 -1 or None as a blocksize indicate the size of the corresponding\r\n  2713                                                 dimension.\r\n  2714                                             name : str, optional\r\n  2715                                                 The key name to use for the array. Defaults to a hash of ``x``.\r\n  2716                                                 By default, hash uses python's standard sha1. This behaviour can be\r\n  2717                                                 changed by installing cityhash, xxhash or murmurhash. If installed,\r\n  2718                                                 a large-factor speedup can be obtained in the tokenisation step.\r\n  2719                                                 Use ``name=False`` to generate a random name instead of hashing (fast)\r\n  2720                                         \r\n  2721                                                 .. note::\r\n  2722                                         \r\n  2723                                                    Because this ``name`` is used as the key in task graphs, you should\r\n  2724                                                    ensure that it uniquely identifies the data contained within. If\r\n  2725                                                    you'd like to provide a descriptive name that is still unique, combine\r\n  2726                                                    the descriptive name with :func:`dask.base.tokenize` of the\r\n  2727                                                    ``array_like``. See :ref:`graphs` for more.\r\n  2728                                         \r\n  2729                                             lock : bool or Lock, optional\r\n  2730                                                 If ``x`` doesn't support concurrent reads then provide a lock here, or\r\n  2731                                                 pass in True to have dask.array create one for you.\r\n  2732                                             asarray : bool, optional\r\n  2733                                                 If True then call np.asarray on chunks to convert them to numpy arrays.\r\n  2734                                                 If False then chunks are passed through unchanged.\r\n  2735                                                 If None (default) then we use True if the ``__array_function__`` method\r\n  2736                                                 is undefined.\r\n  2737                                             fancy : bool, optional\r\n  2738                                                 If ``x`` doesn't support fancy indexing (e.g. indexing with lists or\r\n  2739                                                 arrays) then set to False. Default is True.\r\n  2740                                             meta : Array-like, optional\r\n  2741                                                 The metadata for the resulting dask array.  This is the kind of array\r\n  2742                                                 that will result from slicing the input array.\r\n  2743                                                 Defaults to the input array.\r\n  2744                                         \r\n  2745                                             Examples\r\n  2746                                             --------\r\n  2747                                         \r\n  2748                                             >>> x = h5py.File('...')['/data/path']  # doctest: +SKIP\r\n  2749                                             >>> a = da.from_array(x, chunks=(1000, 1000))  # doctest: +SKIP\r\n  2750                                         \r\n  2751                                             If your underlying datastore does not support concurrent reads then include\r\n  2752                                             the ``lock=True`` keyword argument or ``lock=mylock`` if you want multiple\r\n  2753                                             arrays to coordinate around the same lock.\r\n  2754                                         \r\n  2755                                             >>> a = da.from_array(x, chunks=(1000, 1000), lock=True)  # doctest: +SKIP\r\n  2756                                         \r\n  2757                                             If your underlying datastore has a ``.chunks`` attribute (as h5py and zarr\r\n  2758                                             datasets do) then a multiple of that chunk shape will be used if you\r\n  2759                                             do not provide a chunk shape.\r\n  2760                                         \r\n  2761                                             >>> a = da.from_array(x, chunks='auto')  # doctest: +SKIP\r\n  2762                                             >>> a = da.from_array(x, chunks='100 MiB')  # doctest: +SKIP\r\n  2763                                             >>> a = da.from_array(x)  # doctest: +SKIP\r\n  2764                                         \r\n  2765                                             If providing a name, ensure that it is unique\r\n  2766                                         \r\n  2767                                             >>> import dask.base\r\n  2768                                             >>> token = dask.base.tokenize(x)  # doctest: +SKIP\r\n  2769                                             >>> a = da.from_array('myarray-' + token)  # doctest: +SKIP\r\n  2770                                             \"\"\"\r\n  2771    321.0 MiB      0.0 MiB           1       if isinstance(x, Array):\r\n  2772                                                 raise ValueError(\r\n  2773                                                     \"Array is already a dask array. Use 'asarray' or \" \"'rechunk' instead.\"\r\n  2774                                                 )\r\n  2775    321.0 MiB      0.0 MiB           1       elif is_dask_collection(x):\r\n  2776                                                 warnings.warn(\r\n  2777                                                     \"Passing an object to dask.array.from_array which is already a \"\r\n  2778                                                     \"Dask collection. This can lead to unexpected behavior.\"\r\n  2779                                                 )\r\n  2780                                         \r\n  2781    321.0 MiB      0.0 MiB           1       if isinstance(x, (list, tuple, memoryview) + np.ScalarType):\r\n  2782                                                 x = np.array(x)\r\n  2783                                         \r\n  2784    321.0 MiB      0.0 MiB           1       if asarray is None:\r\n  2785    321.0 MiB      0.0 MiB           1           asarray = not hasattr(x, \"__array_function__\")\r\n  2786                                         \r\n  2787    321.0 MiB      0.0 MiB           1       previous_chunks = getattr(x, \"chunks\", None)\r\n  2788                                         \r\n  2789    321.0 MiB      0.0 MiB           1       chunks = normalize_chunks(\r\n  2790    321.1 MiB      0.0 MiB           1           chunks, x.shape, dtype=x.dtype, previous_chunks=previous_chunks\r\n  2791                                             )\r\n  2792                                         \r\n  2793    321.1 MiB      0.1 MiB           1       if name in (None, True):\r\n  2794    321.1 MiB      0.0 MiB           1           token = tokenize(x, chunks)\r\n  2795    321.1 MiB      0.0 MiB           1           original_name = \"array-original-\" + token\r\n  2796    321.1 MiB      0.0 MiB           1           name = name or \"array-\" + token\r\n  2797                                             elif name is False:\r\n  2798                                                 original_name = name = \"array-\" + str(uuid.uuid1())\r\n  2799                                             else:\r\n  2800                                                 original_name = name\r\n  2801                                         \r\n  2802    321.1 MiB      0.0 MiB           1       if lock is True:\r\n  2803                                                 lock = SerializableLock()\r\n  2804                                         \r\n  2805                                             # Always use the getter for h5py etc. Not using isinstance(x, np.ndarray)\r\n  2806                                             # because np.matrix is a subclass of np.ndarray.\r\n  2807    321.1 MiB      0.0 MiB           4       if type(x) is np.ndarray and all(len(c) == 1 for c in chunks):\r\n  2808                                                 # No slicing needed\r\n  2809                                                 dsk = {(name,) + (0,) * x.ndim: x}\r\n  2810                                             else:\r\n  2811    321.1 MiB      0.0 MiB           1           if getitem is None:\r\n  2812    321.1 MiB      0.0 MiB           1               if type(x) is np.ndarray and not lock:\r\n  2813                                                         # simpler and cleaner, but missing all the nuances of getter\r\n  2814    321.1 MiB      0.0 MiB           1                   getitem = operator.getitem\r\n  2815                                                     elif fancy:\r\n  2816                                                         getitem = getter\r\n  2817                                                     else:\r\n  2818                                                         getitem = getter_nofancy\r\n  2819                                         \r\n  2820    321.1 MiB      0.0 MiB           1           dsk = getem(\r\n  2821    321.1 MiB      0.0 MiB           1               original_name,\r\n  2822    321.1 MiB      0.0 MiB           1               chunks,\r\n  2823    321.1 MiB      0.0 MiB           1               getitem=getitem,\r\n  2824    321.1 MiB      0.0 MiB           1               shape=x.shape,\r\n  2825    321.1 MiB      0.0 MiB           1               out_name=name,\r\n  2826    321.1 MiB      0.0 MiB           1               lock=lock,\r\n  2827    321.1 MiB      0.0 MiB           1               asarray=asarray,\r\n  2828    321.1 MiB      0.0 MiB           1               dtype=x.dtype,\r\n  2829                                                 )\r\n  2830    321.1 MiB      0.0 MiB           1           dsk[original_name] = x\r\n  2831                                         \r\n  2832                                             # Workaround for TileDB, its indexing is 1-based,\r\n  2833                                             # and doesn't seems to support 0-length slicing\r\n  2834    321.1 MiB      0.0 MiB           1       if x.__class__.__module__.split(\".\")[0] == \"tiledb\" and hasattr(x, \"_ctx_\"):\r\n  2835                                                 return Array(dsk, name, chunks, dtype=x.dtype)\r\n  2836                                         \r\n  2837    321.1 MiB      0.0 MiB           1       if meta is None:\r\n  2838    321.1 MiB      0.0 MiB           1           meta = x\r\n  2839                                         \r\n  2840    321.1 MiB      0.0 MiB           1       return Array(dsk, name, chunks, meta=meta, dtype=getattr(x, \"dtype\", None))\r\n```\r\n</details>\r\n\r\nHowever, when I monitor the system's memory usage in the task manager I see a (temporary) spike of several GB when calling `from_array`. This also happens during the call that is being profiled by `mprun`.\r\n\r\n![dask_array_running](https://user-images.githubusercontent.com/4402489/108755019-001d9a80-7547-11eb-929c-56a031ef6d4f.png)\r\n\r\nFor comparison, my base usage (after having reset the kernel and restarted VSCode to free any residual memory) is around 8GB, so the call to `from_array` temporarily consumes ~6 GB for `size=8000`, which is very close to the size of the default-strided (I call it \"inflated\") array of 6.1GB.\r\n![base_memory_usage](https://user-images.githubusercontent.com/4402489/108755123-23e0e080-7547-11eb-95ce-44accaa73cc6.png)\r\n\r\nApparently, the spike is temporary and vanishes after the array has been created\r\n\r\n![dask_spike](https://user-images.githubusercontent.com/4402489/108755359-715d4d80-7547-11eb-9ec7-13df74fc9b33.png)\r\n\r\nI'm trying to come up with a good way to measure it in python, but so far I have nothing. Ideas are very welcome.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/783597114/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/783601069",
        "html_url": "https://github.com/dask/dask/issues/7208#issuecomment-783601069",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/7208",
        "id": 783601069,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc4MzYwMTA2OQ==",
        "user": {
            "login": "jakirkham",
            "id": 3019665,
            "node_id": "MDQ6VXNlcjMwMTk2NjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3019665?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jakirkham",
            "html_url": "https://github.com/jakirkham",
            "followers_url": "https://api.github.com/users/jakirkham/followers",
            "following_url": "https://api.github.com/users/jakirkham/following{/other_user}",
            "gists_url": "https://api.github.com/users/jakirkham/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jakirkham/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jakirkham/subscriptions",
            "organizations_url": "https://api.github.com/users/jakirkham/orgs",
            "repos_url": "https://api.github.com/users/jakirkham/repos",
            "events_url": "https://api.github.com/users/jakirkham/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jakirkham/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-02-22T19:03:44Z",
        "updated_at": "2021-02-22T19:03:44Z",
        "author_association": "MEMBER",
        "body": "Sorry if I missed it, but did you try the linked PR as well?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/783601069/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/783619588",
        "html_url": "https://github.com/dask/dask/issues/7208#issuecomment-783619588",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/7208",
        "id": 783619588,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc4MzYxOTU4OA==",
        "user": {
            "login": "FirefoxMetzger",
            "id": 4402489,
            "node_id": "MDQ6VXNlcjQ0MDI0ODk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4402489?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/FirefoxMetzger",
            "html_url": "https://github.com/FirefoxMetzger",
            "followers_url": "https://api.github.com/users/FirefoxMetzger/followers",
            "following_url": "https://api.github.com/users/FirefoxMetzger/following{/other_user}",
            "gists_url": "https://api.github.com/users/FirefoxMetzger/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/FirefoxMetzger/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/FirefoxMetzger/subscriptions",
            "organizations_url": "https://api.github.com/users/FirefoxMetzger/orgs",
            "repos_url": "https://api.github.com/users/FirefoxMetzger/repos",
            "events_url": "https://api.github.com/users/FirefoxMetzger/events{/privacy}",
            "received_events_url": "https://api.github.com/users/FirefoxMetzger/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-02-22T19:33:43Z",
        "updated_at": "2021-02-22T19:33:43Z",
        "author_association": "CONTRIBUTOR",
        "body": "@jakirkham No, I didn't get to play around with the PR yet. I hope to give it a shot tomorrow and will report back if it improves the situation.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/783619588/reactions",
            "total_count": 2,
            "+1": 2,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/784123093",
        "html_url": "https://github.com/dask/dask/issues/7208#issuecomment-784123093",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/7208",
        "id": 784123093,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc4NDEyMzA5Mw==",
        "user": {
            "login": "FirefoxMetzger",
            "id": 4402489,
            "node_id": "MDQ6VXNlcjQ0MDI0ODk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4402489?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/FirefoxMetzger",
            "html_url": "https://github.com/FirefoxMetzger",
            "followers_url": "https://api.github.com/users/FirefoxMetzger/followers",
            "following_url": "https://api.github.com/users/FirefoxMetzger/following{/other_user}",
            "gists_url": "https://api.github.com/users/FirefoxMetzger/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/FirefoxMetzger/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/FirefoxMetzger/subscriptions",
            "organizations_url": "https://api.github.com/users/FirefoxMetzger/orgs",
            "repos_url": "https://api.github.com/users/FirefoxMetzger/repos",
            "events_url": "https://api.github.com/users/FirefoxMetzger/events{/privacy}",
            "received_events_url": "https://api.github.com/users/FirefoxMetzger/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-02-23T11:10:11Z",
        "updated_at": "2021-02-23T11:10:11Z",
        "author_association": "CONTRIBUTOR",
        "body": "Using #7234 I see the same spike when using `da.from_array` on a custom strided array. However, doing something like\r\n\r\n```\r\nfrom dask.array.overlap import sliding_window_view\r\ndask_overlap = sliding_window_view(da.from_array(np.arange(size*size).reshape(size,size)), (5,5), (0,1))\r\n```\r\n\r\nworks without producing a temporary memory spike.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/784123093/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/784195048",
        "html_url": "https://github.com/dask/dask/issues/7208#issuecomment-784195048",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/7208",
        "id": 784195048,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc4NDE5NTA0OA==",
        "user": {
            "login": "dcherian",
            "id": 2448579,
            "node_id": "MDQ6VXNlcjI0NDg1Nzk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2448579?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dcherian",
            "html_url": "https://github.com/dcherian",
            "followers_url": "https://api.github.com/users/dcherian/followers",
            "following_url": "https://api.github.com/users/dcherian/following{/other_user}",
            "gists_url": "https://api.github.com/users/dcherian/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dcherian/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dcherian/subscriptions",
            "organizations_url": "https://api.github.com/users/dcherian/orgs",
            "repos_url": "https://api.github.com/users/dcherian/repos",
            "events_url": "https://api.github.com/users/dcherian/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dcherian/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-02-23T13:15:57Z",
        "updated_at": "2021-02-23T13:15:57Z",
        "author_association": "MEMBER",
        "body": "Yes `dask_overlap` is the intended use. Can you apply your kernel and confirm that the memory use is as expected when you compute? Memory usage for `func(dask_overlap)` should be much less than memory usage of `func(dask_overlap.map_blocks(np.copy))`",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/784195048/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/784909463",
        "html_url": "https://github.com/dask/dask/issues/7208#issuecomment-784909463",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/7208",
        "id": 784909463,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc4NDkwOTQ2Mw==",
        "user": {
            "login": "bmerry",
            "id": 1963944,
            "node_id": "MDQ6VXNlcjE5NjM5NDQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1963944?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bmerry",
            "html_url": "https://github.com/bmerry",
            "followers_url": "https://api.github.com/users/bmerry/followers",
            "following_url": "https://api.github.com/users/bmerry/following{/other_user}",
            "gists_url": "https://api.github.com/users/bmerry/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bmerry/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bmerry/subscriptions",
            "organizations_url": "https://api.github.com/users/bmerry/orgs",
            "repos_url": "https://api.github.com/users/bmerry/repos",
            "events_url": "https://api.github.com/users/bmerry/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bmerry/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-02-24T08:42:58Z",
        "updated_at": "2021-02-24T08:42:58Z",
        "author_association": "MEMBER",
        "body": "It seems to be caused by the hashing used to generate the name. If you pass `name=False` to `da.from_array` the problem goes away. I'll take a look to see if there is an obvious reason that hashing is expanding the array, but even if the memory usage is fixed I would guess the hashing would be very slow since it would need to iterate over the large \"virtual\" array created by `view_as_windows`. See the documentation of `da.from_array` for an explanation of `name`.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/784909463/reactions",
            "total_count": 2,
            "+1": 2,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/784923238",
        "html_url": "https://github.com/dask/dask/issues/7208#issuecomment-784923238",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/7208",
        "id": 784923238,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc4NDkyMzIzOA==",
        "user": {
            "login": "bmerry",
            "id": 1963944,
            "node_id": "MDQ6VXNlcjE5NjM5NDQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1963944?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bmerry",
            "html_url": "https://github.com/bmerry",
            "followers_url": "https://api.github.com/users/bmerry/followers",
            "following_url": "https://api.github.com/users/bmerry/following{/other_user}",
            "gists_url": "https://api.github.com/users/bmerry/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bmerry/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bmerry/subscriptions",
            "organizations_url": "https://api.github.com/users/bmerry/orgs",
            "repos_url": "https://api.github.com/users/bmerry/repos",
            "events_url": "https://api.github.com/users/bmerry/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bmerry/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-02-24T09:05:34Z",
        "updated_at": "2021-02-24T09:05:34Z",
        "author_association": "MEMBER",
        "body": "The hash functions operate on a 1D contiguous block of memory. So the only way to avoid the expansion when hashing would be to feed contiguous pieces to it. In general an array might be composed of many small contiguous pieces (at the extreme end, consider `np.ones(10000)[::2]`) which would be terrible for performance. It also looks like `from_array` is designed to accept things that are array-like but not exactly `ndarray`, and trying to do too much clever introspection on them could easily go wrong.\r\n\r\nPersonally I've never liked the default of trying to hash the argument to `from_array`, and my preferred fix would be to use a time machine to change the default in the past. Without a time machine, I'd suggest that the best that can be done is to improve the documentation, which I can have a look at.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/784923238/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/785119178",
        "html_url": "https://github.com/dask/dask/issues/7208#issuecomment-785119178",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/7208",
        "id": 785119178,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc4NTExOTE3OA==",
        "user": {
            "login": "TomAugspurger",
            "id": 1312546,
            "node_id": "MDQ6VXNlcjEzMTI1NDY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1312546?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/TomAugspurger",
            "html_url": "https://github.com/TomAugspurger",
            "followers_url": "https://api.github.com/users/TomAugspurger/followers",
            "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
            "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
            "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
            "repos_url": "https://api.github.com/users/TomAugspurger/repos",
            "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
            "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-02-24T14:36:18Z",
        "updated_at": "2021-02-24T14:36:18Z",
        "author_association": "MEMBER",
        "body": "We can also teach `dask.base.tokenize` about strided arrays I think. Is there some combination of a base array + strides that uniquely identifies a strided array? Perhaps something like\r\n\r\n```python\r\nIn [18]: dask.base.tokenize(strided_array.base.base, strided_array.strides)\r\nOut[18]: 'b49a5b9147024e0564b2532e06e927c8'\r\n```\r\n\r\nFor reference, \r\n\r\n```python\r\nIn [23]: strided_array.base\r\nOut[23]: <numpy.lib.stride_tricks.DummyArray at 0x7f371dcd2490>\r\n\r\nIn [24]: strided_array.base.base\r\nOut[24]:\r\narray([[       0,        1,        2, ...,     4997,     4998,     4999],\r\n       [    5000,     5001,     5002, ...,     9997,     9998,     9999],\r\n       [   10000,    10001,    10002, ...,    14997,    14998,    14999],\r\n       ...,\r\n       [24985000, 24985001, 24985002, ..., 24989997, 24989998, 24989999],\r\n       [24990000, 24990001, 24990002, ..., 24994997, 24994998, 24994999],\r\n       [24995000, 24995001, 24995002, ..., 24999997, 24999998, 24999999]])\r\n```\r\n\r\nSo tokenize could check for the presence of `.base`, and if it's a `DummyArray` then tokenize its base + strides (+ anything else needed?)",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/785119178/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/785141923",
        "html_url": "https://github.com/dask/dask/issues/7208#issuecomment-785141923",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/7208",
        "id": 785141923,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc4NTE0MTkyMw==",
        "user": {
            "login": "bmerry",
            "id": 1963944,
            "node_id": "MDQ6VXNlcjE5NjM5NDQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1963944?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bmerry",
            "html_url": "https://github.com/bmerry",
            "followers_url": "https://api.github.com/users/bmerry/followers",
            "following_url": "https://api.github.com/users/bmerry/following{/other_user}",
            "gists_url": "https://api.github.com/users/bmerry/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bmerry/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bmerry/subscriptions",
            "organizations_url": "https://api.github.com/users/bmerry/orgs",
            "repos_url": "https://api.github.com/users/bmerry/repos",
            "events_url": "https://api.github.com/users/bmerry/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bmerry/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-02-24T15:08:41Z",
        "updated_at": "2021-02-24T15:09:51Z",
        "author_association": "MEMBER",
        "body": "That might work in theory, but it's a bit scary:\r\n- The numpy docs don't mention DummyArray, so is it guaranteed to continue to exist?\r\n- Even if it still exists, is sliding_window_view guaranteed to use it?\r\n- Does its use guarantee that the current array is a view of the base of the DummyArray? DummyArray could be hijacked for other purposes, either by numpy itself or a user.\r\n- It won't detect all cases. For example, `np.broadcast_to` doesn't appear to use it, and if one slices the result of `sliding_window_view` (even with `[:]`) then `x.base` is not a DummyArray (one has to follow the chain of `.base` objects, which again gets fraught if one is using array-likes instead of arrays).\r\n- In general there is no guarantee that the view references the entirety of the base. If not, then irrelevant data will be included in the hash, possibly leading to false mismatches, and possibly making it much *slower* instead of faster.\r\n\r\nAn alternative would be to directly examine the shape and strides and figure out the memory footprint. That sounds pretty complicated though, and would probably slow things down a lot for small simple arrays.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/785141923/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/785148407",
        "html_url": "https://github.com/dask/dask/issues/7208#issuecomment-785148407",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/7208",
        "id": 785148407,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc4NTE0ODQwNw==",
        "user": {
            "login": "FirefoxMetzger",
            "id": 4402489,
            "node_id": "MDQ6VXNlcjQ0MDI0ODk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4402489?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/FirefoxMetzger",
            "html_url": "https://github.com/FirefoxMetzger",
            "followers_url": "https://api.github.com/users/FirefoxMetzger/followers",
            "following_url": "https://api.github.com/users/FirefoxMetzger/following{/other_user}",
            "gists_url": "https://api.github.com/users/FirefoxMetzger/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/FirefoxMetzger/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/FirefoxMetzger/subscriptions",
            "organizations_url": "https://api.github.com/users/FirefoxMetzger/orgs",
            "repos_url": "https://api.github.com/users/FirefoxMetzger/repos",
            "events_url": "https://api.github.com/users/FirefoxMetzger/events{/privacy}",
            "received_events_url": "https://api.github.com/users/FirefoxMetzger/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-02-24T15:17:51Z",
        "updated_at": "2021-02-24T15:18:39Z",
        "author_association": "CONTRIBUTOR",
        "body": ">Is there some combination of a base array + strides that uniquely identifies a strided array?\r\n\r\nWould it make sense to do it for general views instead? A view can have a `dtype`, `shape`, `offset`, `strides`, or `order` that is different from the underlying `base` array, while still pointing to the same buffer.\r\n\r\n> The numpy docs don't mention DummyArray, so is it guaranteed to continue to exist?\r\n\r\nNot exactly, but I'm not a numpy dev, so you may want to take my word with a pinch of salt. When I last dug into this `DummyArray` was a trick to avoid problems elsewhere. It has been around, but I wouldn't rely on it.\r\n\r\n> An alternative would be to directly examine the shape and strides and figure out the memory footprint. That sounds pretty complicated though, and would probably slow things down a lot for small simple arrays.\r\n\r\nYes, this seems like a safer route. It doesn't have to be slower for simple arrays, because they can take a different code path by checking the [`OWNDATA` Flag](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.flags.html).",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/785148407/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]