{
    "url": "https://api.github.com/repos/dask/dask/issues/10467",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/10467/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/10467/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/10467/events",
    "html_url": "https://github.com/dask/dask/issues/10467",
    "id": 1869930931,
    "node_id": "I_kwDOAbcwm85vdOGz",
    "number": 10467,
    "title": "How to upload dataframe with numpy array column using to_parquet in dask.dataframe? ",
    "user": {
        "login": "hjlee9182",
        "id": 46337218,
        "node_id": "MDQ6VXNlcjQ2MzM3MjE4",
        "avatar_url": "https://avatars.githubusercontent.com/u/46337218?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/hjlee9182",
        "html_url": "https://github.com/hjlee9182",
        "followers_url": "https://api.github.com/users/hjlee9182/followers",
        "following_url": "https://api.github.com/users/hjlee9182/following{/other_user}",
        "gists_url": "https://api.github.com/users/hjlee9182/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/hjlee9182/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/hjlee9182/subscriptions",
        "organizations_url": "https://api.github.com/users/hjlee9182/orgs",
        "repos_url": "https://api.github.com/users/hjlee9182/repos",
        "events_url": "https://api.github.com/users/hjlee9182/events{/privacy}",
        "received_events_url": "https://api.github.com/users/hjlee9182/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 3468123446,
            "node_id": "LA_kwDOAbcwm87Ot102",
            "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention",
            "name": "needs attention",
            "color": "6d626c",
            "default": false,
            "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."
        },
        {
            "id": 3880424463,
            "node_id": "LA_kwDOAbcwm87nSpQP",
            "url": "https://api.github.com/repos/dask/dask/labels/needs%20triage",
            "name": "needs triage",
            "color": "eeeeee",
            "default": false,
            "description": "Needs a response from a contributor"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2023-08-28T14:56:43Z",
    "updated_at": "2024-05-30T16:00:06Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "I want to upload dataframe with array column!\r\nUnder code rise type error.\r\nAny suggestions on how to further troubleshoot, how to fix this, or where else I could ask for help would be greatly appreciated!\r\nOr if this function is not working, can you add a function?\r\n\r\n```\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom dask import dataframe as dd. ## dask version == 2023.5.0\r\n\r\ndata = {\r\n    'float_array_column': [\r\n        np.array([1.1, 2.2, 3.3]),\r\n        np.array([4.4, 5.5]),\r\n        np.array([6.6, 7.7, 8.8, 9.9])\r\n    ]\r\n}\r\npath = {storage_path}\r\nstorage_option = {storage_option}\r\n\r\ndf = pd.DataFrame(data)\r\ndf = dd.from_pandas(df, chunksize=5368709)\r\n\r\ndd.to_parquet(df, path, engine='pyarrow', storage_options=storage_option)\r\n```\r\n\r\n```\r\nValueError: Failed to convert partition to expected pyarrow schema:\r\n    `ArrowTypeError(\"Expected bytes, got a 'numpy.ndarray' object\", 'Conversion failed for column float_array_column with type object')`\r\n\r\nExpected partition schema:\r\n    float_array_column: string\r\n    __null_dask_index__: int64\r\n\r\nReceived partition schema:\r\n    float_array_column: list<item: double>\r\n      child 0, item: double\r\n    __null_dask_index__: int64\r\n\r\nThis error *may* be resolved by passing in schema information for\r\nthe mismatched column(s) using the `schema` keyword in `to_parquet`.\r\n````\r\n\r\n\r\nChange data numpy to list is also got errored.\r\n\r\n```\r\ndata = {\r\n    'float_array_column': [\r\n        [1.1, 2.2, 3.3],\r\n        [4.4, 5.5],\r\n        [6.6, 7.7, 8.8, 9.9]\r\n    ]\r\n}\r\n```\r\n\r\n```\r\nValueError: Failed to convert partition to expected pyarrow schema:\r\n    `ArrowTypeError(\"Expected bytes, got a 'list' object\", 'Conversion failed for column float_array_column with type object')`\r\n\r\nExpected partition schema:\r\n    float_array_column: string\r\n    __null_dask_index__: int64\r\n\r\nReceived partition schema:\r\n    float_array_column: list<item: double>\r\n      child 0, item: double\r\n    __null_dask_index__: int64\r\n\r\nThis error *may* be resolved by passing in schema information for\r\nthe mismatched column(s) using the `schema` keyword in `to_parquet`.\r\n````\r\n\r\nWhen using dd.from_array is also got errored.\r\n\r\n```\r\ndata = {\r\n    'float_array_column': [\r\n        dd.from_array(np.array([1.1, 2.2, 3.3])),\r\n        dd.from_array(np.array([4.4, 5.5])),\r\n        dd.from_array(np.array([6.6, 7.7, 8.8, 9.9]))\r\n    ]\r\n}\r\n```\r\n\r\n```\r\nArrowTypeError: (\"Expected bytes, got a 'Series' object\", 'Conversion failed for column float_array_column with type object')\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n```",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/10467/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/10467/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}