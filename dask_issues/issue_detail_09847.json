{
    "url": "https://api.github.com/repos/dask/dask/issues/9847",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/9847/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/9847/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/9847/events",
    "html_url": "https://github.com/dask/dask/issues/9847",
    "id": 1538364356,
    "node_id": "I_kwDOAbcwm85bsZPE",
    "number": 9847,
    "title": "We should rethink categorize()",
    "user": {
        "login": "crusaderky",
        "id": 6213168,
        "node_id": "MDQ6VXNlcjYyMTMxNjg=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6213168?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/crusaderky",
        "html_url": "https://github.com/crusaderky",
        "followers_url": "https://api.github.com/users/crusaderky/followers",
        "following_url": "https://api.github.com/users/crusaderky/following{/other_user}",
        "gists_url": "https://api.github.com/users/crusaderky/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/crusaderky/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/crusaderky/subscriptions",
        "organizations_url": "https://api.github.com/users/crusaderky/orgs",
        "repos_url": "https://api.github.com/users/crusaderky/repos",
        "events_url": "https://api.github.com/users/crusaderky/events{/privacy}",
        "received_events_url": "https://api.github.com/users/crusaderky/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        },
        {
            "id": 1372867996,
            "node_id": "MDU6TGFiZWwxMzcyODY3OTk2",
            "url": "https://api.github.com/repos/dask/dask/labels/discussion",
            "name": "discussion",
            "color": "bebaf4",
            "default": false,
            "description": "Discussing a topic with no specific actions yet"
        },
        {
            "id": 3468123446,
            "node_id": "LA_kwDOAbcwm87Ot102",
            "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention",
            "name": "needs attention",
            "color": "6d626c",
            "default": false,
            "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2023-01-18T17:06:42Z",
    "updated_at": "2024-04-01T01:47:14Z",
    "closed_at": null,
    "author_association": "MEMBER",
    "active_lock_reason": null,
    "body": "As far as I understand, there are three use cases for why someone would want to convert a regular dtype into a categorical one, which need different implementations:\r\n\r\n1. To shrink down the size of the dataframe, and/or to make string types more performant (even faster than with string[pyarrow]), and/or to make string types easy to manipulate with C/Cython/numba/CUDA/etc. - with the caveat that non-python functions are constrained to a single partition, and that it's straightforward to do domain mapping afterwards\r\n2. To make string types easy to manipulate with C/Cython/numba/CUDA/etc., using an algorithm that spans across multiple partitions, e.g. machine learning, or in preparation of some other kind of very heavy interaction between the partitions - so that the categorical domains must be the same across all partitions.\r\n3. To inspect the categorical domains in the GUI, or because for whatever reason they must be known ahead of the graph computation.\r\n\r\nIt's important to understand that this distinction is dask-specific. \r\nNo such nuance is needed in pandas due to all data being eagerly stored on the user's machine at once.\r\n\r\nAs of today,\r\n- use case (1) is implemented by `dd.Dataframe.astype(\"category\")`, like in pandas.\r\n- use cases (2) and (3) are implemented by `dd.Dataframe.categorize()`.\r\n- there is no implementation for use case (2) without (3), where you want domains to be global but you don't care about knowing them in the metadata.\r\n\r\nThe `categorize()` method **computes the whole dask graph until that moment**, sends the global domains back to the client, and then adds a simple map step to the original dask graph. By the end of the day, the whole graph until categorize will be computed twice:\r\n\r\n![2023-01-18 15 54 25](https://user-images.githubusercontent.com/6213168/213231548-9ad44a99-1670-4623-bcc4-10b4ecc39097.jpg)\r\n\r\nOne can avoid this by prepending persist():\r\n```python\r\n< df = df.categorize()\r\n> df = df.persist().categorize()\r\n```\r\n\r\n![2023-01-18 15 54 59](https://user-images.githubusercontent.com/6213168/213231602-9f2d9335-8def-40c3-8f3f-4d03d23ddbfa.jpg)\r\n\r\n...which is great, except that now the whole graph until categorize() needs to be in memory at the same time on the cluster.\r\nA better way to to do this is to understand that local (intra-partition) categorization can shrink the size of the dataframe substantially:\r\n\r\n```python\r\n< df = df.persist().categorize()\r\n> df = df.astype(\"category\").persist().categorize()\r\n```\r\n\r\n![2023-01-18 15 55 38](https://user-images.githubusercontent.com/6213168/213231653-d5746c0a-ee2d-442f-bde0-1e46eee207de.jpg)\r\n\r\nRegardless, the call blocks until the first computation is complete - which precludes the option to call `client.publish_dataset`, close the laptop, and go home. We don't need to block in use case (2) - we *could* add two new layers without recomputing anything:\r\n\r\n![2023-01-18 15 56 06](https://user-images.githubusercontent.com/6213168/213231714-ba591765-e3a9-47ca-8f62-0cf2b3d148dd.jpg)\r\n\r\n# User's perspective\r\n\r\nI think it is unreasonable to expect a typical data scientist, proficient in pandas but not so hot in dask, to appreciate the difference between the three use cases without first either being explained at length or crashing and burning.\r\n\r\nA lot of users will end up computing everything twice, particularly if the categorize() call is in the middle of a complex algorithm.\r\n\r\nA lot of users will end up with local domains when they actually need to be global. In a realistic worst case situation, for the whole dev process their data will accidentally conjure local domains that are identical across partitions (because each partition has all the use cases), then move to production, and a fated Friday night have everything crash down because a single partition is missing a single value and now the domains are misaligned.\r\n\r\nUsers that figured out the `persist()` trick will end up with a lot of memory usage, which could be slimmed down considerably - except that they didn't figure out the triple-flip jump `astype(\"category\").persist().categorize()`.\r\n\r\n# Proposed design\r\n\r\nAdd parameters to categorize():\r\n```\r\ntopology: \"global\" | \"local\"\r\n    \"global\"\r\n        Align the categorical domains across partitions. This will cost either more time or memory\r\n        (see 'compute' below), but may be necessary for cross-partition numerical algorithms that require\r\n        consistent domains (e.g. machine learning).\r\n    \"local\"\r\n        Domains may differ across partitions. This is much faster and lighter and should be preferred as long\r\n        as it's not too onerous for any inter-partition interactions down the line to perform domain mapping.\r\n\r\ncompute: \"twice\" | \"persisted\" | False, optional\r\n    \"twice\"\r\n        Only permitted if topology=\"global\". Compute the whole graph so far in real-time, as soon as you invoke\r\n        categorize(), and populate the global domains in the metadata. The whole graph since the latest call to\r\n        persist() will be recomputed from scratch once you eventually compute the output of categorize().\r\n        This may be desirable e.g. if your graph so far consists in very large data which is fast to recompute.\r\n    \"persisted\"\r\n        Only permitted if topology=\"global\". Compute the whole graph so far in real-time, as soon as you invoke\r\n        categorize(), and populate the global domains in the metadata. However, persist the graph just before that,\r\n        so that the graph so far ends up being computed only once. This however will mean that the whole graph\r\n        needs to be in memory at the same time.\r\n    False (default)\r\n        Do not compute the graph. categorize() will return almost immediately, without sending anything to the\r\n        cluster yet. The metadata on the client will remain unknown.\r\n        Note that, if topology=\"global\", this means that the whole dataframe will need to be in memory at the\r\n        same time at some point.\r\n\r\n*Deprecated:* if both topology and compute are omitted, default to topology=\"global\", compute=\"twice\".\r\nNote that when topology is explicit, the default for compute is False.\r\nThe topology parameter will become mandatory in the future.\r\n```\r\n\r\n- `.categorize(\"global\", \"twice\")` is the same as the current `.categorize()`\r\n- `.categorize(\"global\", \"persisted\")` is the same as the current `.astype(\"category\").persist().categorize()`\r\n- `.categorize(\"global\", False)` is use case (2) at the beginning of this post, which is currently impossible.\r\n- `.categorize(\"local\")` is the same as the current `.astype(\"category\")`\r\n\r\nFinally, `.astype(\"category\")` should be deprecated in favor of an explicit decision with categorize().",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/9847/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/9847/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}