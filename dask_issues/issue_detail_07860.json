{
    "url": "https://api.github.com/repos/dask/dask/issues/7860",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/7860/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/7860/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/7860/events",
    "html_url": "https://github.com/dask/dask/issues/7860",
    "id": 936041940,
    "node_id": "MDU6SXNzdWU5MzYwNDE5NDA=",
    "number": 7860,
    "title": "map_partitions or map_blocks with large objects eats up scheduler memory",
    "user": {
        "login": "rikturr",
        "id": 8964039,
        "node_id": "MDQ6VXNlcjg5NjQwMzk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/8964039?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/rikturr",
        "html_url": "https://github.com/rikturr",
        "followers_url": "https://api.github.com/users/rikturr/followers",
        "following_url": "https://api.github.com/users/rikturr/following{/other_user}",
        "gists_url": "https://api.github.com/users/rikturr/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/rikturr/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/rikturr/subscriptions",
        "organizations_url": "https://api.github.com/users/rikturr/orgs",
        "repos_url": "https://api.github.com/users/rikturr/repos",
        "events_url": "https://api.github.com/users/rikturr/events{/privacy}",
        "received_events_url": "https://api.github.com/users/rikturr/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 386719400,
            "node_id": "MDU6TGFiZWwzODY3MTk0MDA=",
            "url": "https://api.github.com/repos/dask/dask/labels/scheduler",
            "name": "scheduler",
            "color": "D10945",
            "default": false,
            "description": ""
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 5,
    "created_at": "2021-07-02T20:10:19Z",
    "updated_at": "2021-10-14T08:18:15Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "Opening this report from investigation in https://github.com/dask/dask-ml/issues/842 and https://github.com/dask/dask-ml/pull/843\r\n\r\nWhen passing some large objects as arguments to map_blocks / map_partitions, the scheduler memory can quickly be overwhelmed. Large objects _should_ be wrapped in delayed to add them to graph and avoid this issue ([see here](https://github.com/dask/dask/blob/626cc724ffa1d14cd74f48ff4f21ef443d832afa/dask/array/core.py#L428)) , but the way the object sizes are determined miss some large objects. In the cases I've encountered, it does not correctly compute the size of scikit-learn estimators.\r\n\r\nThis is because sys.getsizeof does not properly traverse object references to compute the \"real\" size of an object. This is a notoriously difficult thing to do in Python, so not sure what the best course of action here should be. \r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\nRunning on machine with 2 cores and 16 GB of RAM\r\n\r\n```python\r\nfrom dask_ml.datasets import make_classification\r\nfrom sklearn.ensemble import RandomForestClassifier\r\nimport numpy as np\r\nimport pickle\r\nimport sys\r\nimport dask\r\nfrom dask.distributed import Client\r\n\r\nclient = Client()\r\n\r\nX, y = make_classification(\r\n    n_samples=50000,\r\n    chunks=1000,\r\n    random_state=42,\r\n)\r\n\r\nrf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\r\n_ = rf.fit(X, y)\r\n\r\n\r\ndef dask_predict(part, model):\r\n    return model.predict(part)\r\n\r\npreds = X.map_blocks(\r\n    dask_predict,\r\n    model=rf,\r\n    dtype=\"int\",\r\n    drop_axis=1,\r\n)\r\npreds.compute()\r\n```\r\n\r\nScheduler memory ballons up to this:\r\n\r\n<img width=\"458\" alt=\"image\" src=\"https://user-images.githubusercontent.com/8964039/124323726-c7727b00-db4f-11eb-9b2b-4ae9f02b282b.png\">\r\n\r\nAnd ends up with this error:\r\n\r\n```\r\nKilledWorker: (\"('normal-dask_predict-4b858b85224825aeb2d45678c4c91d39', 27)\", <WorkerState 'tcp://127.0.0.1:33369', name: 0, memory: 0, processing: 50>)\r\n```\r\n\r\nIf we explictly delayed the rf object, \r\n\r\n```python\r\nrf_delayed = dask.delayed(rf)\r\npreds = X.map_blocks(\r\n    dask_predict,\r\n    model=rf_delayed,\r\n    dtype=\"int\",\r\n    drop_axis=1,\r\n    meta=np.array([1]),\r\n)\r\npreds.compute()\r\n```\r\n\r\nthe memory use looks like this:\r\n\r\n<img width=\"750\" alt=\"Screen Shot 2021-07-02 at 4 00 52 PM\" src=\"https://user-images.githubusercontent.com/8964039/124323750-d1947980-db4f-11eb-826f-9bf82e334202.png\">\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2021.5.1\r\n- Python version: 3.7\r\n- Operating System: ubuntu\r\n- Install method (conda, pip, source): conda\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/7860/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/7860/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}