{
    "url": "https://api.github.com/repos/dask/dask/issues/9076",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/9076/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/9076/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/9076/events",
    "html_url": "https://github.com/dask/dask/pull/9076",
    "id": 1234396863,
    "node_id": "PR_kwDOAbcwm843vfD6",
    "number": 9076,
    "title": "[WIP][POC] Rough implementation of HLG/Layer Alternative",
    "user": {
        "login": "rjzamora",
        "id": 20461013,
        "node_id": "MDQ6VXNlcjIwNDYxMDEz",
        "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/rjzamora",
        "html_url": "https://github.com/rjzamora",
        "followers_url": "https://api.github.com/users/rjzamora/followers",
        "following_url": "https://api.github.com/users/rjzamora/following{/other_user}",
        "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions",
        "organizations_url": "https://api.github.com/users/rjzamora/orgs",
        "repos_url": "https://api.github.com/users/rjzamora/repos",
        "events_url": "https://api.github.com/users/rjzamora/events{/privacy}",
        "received_events_url": "https://api.github.com/users/rjzamora/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        },
        {
            "id": 365513534,
            "node_id": "MDU6TGFiZWwzNjU1MTM1MzQ=",
            "url": "https://api.github.com/repos/dask/dask/labels/io",
            "name": "io",
            "color": "6f871c",
            "default": false,
            "description": ""
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 11,
    "created_at": "2022-05-12T19:28:18Z",
    "updated_at": "2022-05-24T17:25:13Z",
    "closed_at": null,
    "author_association": "MEMBER",
    "active_lock_reason": null,
    "draft": true,
    "pull_request": {
        "url": "https://api.github.com/repos/dask/dask/pulls/9076",
        "html_url": "https://github.com/dask/dask/pull/9076",
        "diff_url": "https://github.com/dask/dask/pull/9076.diff",
        "patch_url": "https://github.com/dask/dask/pull/9076.patch",
        "merged_at": null
    },
    "body": "**WARNING: DO NOT MERGE**\r\n\r\nThis is a rough/experimental implementation of the plan suggested in [here](https://github.com/dask/dask/issues/8980#issuecomment-1122832415) in https://github.com/dask/dask/issues/8980. The specific design needs a lot of work, but I am hoping this PR will eventually serve as a basic reference implementation for the general \"plan\" if we eventually decide to pursue it.\r\n\r\n**General Idea**: Rather than depending on the `HighLevelGraph`/`Layer` for graph optimization and materialization, this PR proposes that we add a `Layer`-like class, called `CollectionOperation`, and use it to manage collection metadata **and** graph materialization/optimization logic.  The key advantage being that we resolve the longstanding challenge of having the HLG know nothing about the  collection that created it.\r\n\r\n**What this POC has so far**:\r\n\r\nSo far, this PR only implements `CollectionOperation` support for DataFrame collections, and it only supports `read_parquet`, `from_map`, and element-wise operations (via `elemwise`). The following limitations are also important to consider:\r\n\r\n- In order to use the `CollectionOperation` backend, `use_operation_api=True` must be passed to the IO function.\r\n- After the collection is already created, the other supported operations will automatically use the `CollectionOperation` backend if is not a place-holder `CompatFrameOperation` (which simply wraps a traditional `HighLevelGraph`. Operations that do **not** support the `CollectionOperation` backend will simply force input collection(s) to generate an HLG (with a single `MaterializedLayer`) (when their `dask` attribute is called). In the future, when HLG-Pickle support is finished, we can define a special compatibiliy `Layer` object to avoid premature materialization.\r\n- When the `dask` attribute is called on a `CollectionOperation`-based collection, the raw graph is materialized with culling and fusion baked into the `generate_graph` logic defined in the `CollectionOperation`. In the future, it probably makes sense to add an option to avoid fusion, but the long-term plan is to avoid the need for an explicit `cull` operation.\r\n- The current PR enables column porjection, but does not include predicate pusdown yet.\r\n\r\nBasic usage example:\r\n\r\n```python\r\nimport dask.dataframe as dd\r\nfrom dask.datasets import timeseries\r\n\r\ntimeseries().to_parquet(\"timeseries\")\r\nddf = dd.read_parquet(\r\n    [\"timeseries/part.0.parquet\", \"timeseries/part.1.parquet\"],\r\n    use_operation_api=True,\r\n)\r\n\r\n# Various elemwise operations\r\nddf2 = ddf[operator.and_(ddf[\"id\"] > 995, ddf[\"id\"] < 1005)]\r\nddf3 = ddf2[[\"id\"]]\r\nddf3 += 1\r\nddf4 = ddf3.assign(new=\"A\")\r\n\r\n# Visualize underlying CollectionOperation\r\nddf4.operation.visualize()\r\n```\r\n\r\n![Screen Shot 2022-05-12 at 2 01 02 PM](https://user-images.githubusercontent.com/20461013/168149146-3da1f5ff-fa2f-478c-8c92-9b1427458a5b.png)\r\n\r\nNote that, since element-wise operations will be automatically fused at graph materialization time, using `ddf4.visualize()` shows something a bit different:\r\n\r\n![Screen Shot 2022-05-12 at 2 02 11 PM](https://user-images.githubusercontent.com/20461013/168149351-e0c01664-773a-444d-bfb7-37c313242fef.png)\r\n\r\nNote that we can also call `optimize_operation` on the `CollectionOperation`-based collection to perform column projection:\r\n\r\n```python\r\nddf4 = ddf4.optimize_operation()\r\nddf4.operation.projected_columns\r\n```\r\n\r\n```\r\n{'id'}\r\n```\r\n\r\n**What is still missing**:\r\n\r\nA lot. This is not even close to ready.\r\n\r\nStill need to iterate on this design (probably a lot) to get an idea if it will both simplify development **and** enable useful graph optimizations in the future. I could certainly use help from people with expertise related to high-level expressions (cc @eriknw)",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/9076/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/9076/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}