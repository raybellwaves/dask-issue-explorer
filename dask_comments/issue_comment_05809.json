[
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/576693362",
        "html_url": "https://github.com/dask/dask/issues/5809#issuecomment-576693362",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/5809",
        "id": 576693362,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU3NjY5MzM2Mg==",
        "user": {
            "login": "TomAugspurger",
            "id": 1312546,
            "node_id": "MDQ6VXNlcjEzMTI1NDY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1312546?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/TomAugspurger",
            "html_url": "https://github.com/TomAugspurger",
            "followers_url": "https://api.github.com/users/TomAugspurger/followers",
            "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
            "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
            "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
            "repos_url": "https://api.github.com/users/TomAugspurger/repos",
            "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
            "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-01-21T13:57:54Z",
        "updated_at": "2020-01-21T13:57:54Z",
        "author_association": "MEMBER",
        "body": "Can you share a small example so its easier to know when this feature request has been satisfied?\r\n\r\nDask does have some optimizations like this. https://github.com/dask/dask/blob/a27f111b7bd327ad74bc2aff088e30de91ecf7df/dask/dataframe/optimize.py#L37 does it for a `read_parquet` followed by a getitem. We could explore something similar for a `dd.merge` followed by a getitem.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/576693362/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/578361638",
        "html_url": "https://github.com/dask/dask/issues/5809#issuecomment-578361638",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/5809",
        "id": 578361638,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU3ODM2MTYzOA==",
        "user": {
            "login": "VibhuJawa",
            "id": 4837571,
            "node_id": "MDQ6VXNlcjQ4Mzc1NzE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4837571?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/VibhuJawa",
            "html_url": "https://github.com/VibhuJawa",
            "followers_url": "https://api.github.com/users/VibhuJawa/followers",
            "following_url": "https://api.github.com/users/VibhuJawa/following{/other_user}",
            "gists_url": "https://api.github.com/users/VibhuJawa/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/VibhuJawa/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/VibhuJawa/subscriptions",
            "organizations_url": "https://api.github.com/users/VibhuJawa/orgs",
            "repos_url": "https://api.github.com/users/VibhuJawa/repos",
            "events_url": "https://api.github.com/users/VibhuJawa/events{/privacy}",
            "received_events_url": "https://api.github.com/users/VibhuJawa/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-01-25T01:22:43Z",
        "updated_at": "2020-01-25T01:23:19Z",
        "author_association": "MEMBER",
        "body": "> Can you share a small example so its easier to know when this feature request has been satisfied?\r\n> \r\n> Dask does have some optimizations like this.\r\n> \r\n> https://github.com/dask/dask/blob/a27f111b7bd327ad74bc2aff088e30de91ecf7df/dask/dataframe/optimize.py#L37\r\n> \r\n> does it for a `read_parquet` followed by a getitem. We could explore something similar for a `dd.merge` followed by a getitem.\r\n\r\nSorry for the delay on this,  I will share a minimal reproducer soon (early next week), its not super simple to show the benefits without a big table and multiple workers . \r\n\r\nFWIW, The example will likely involve using `left_on` and `right_on` to do a merge on multiple columns as that introduces a lot of extra columns after each merge. \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/578361638/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/634291208",
        "html_url": "https://github.com/dask/dask/issues/5809#issuecomment-634291208",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/5809",
        "id": 634291208,
        "node_id": "MDEyOklzc3VlQ29tbWVudDYzNDI5MTIwOA==",
        "user": {
            "login": "VibhuJawa",
            "id": 4837571,
            "node_id": "MDQ6VXNlcjQ4Mzc1NzE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4837571?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/VibhuJawa",
            "html_url": "https://github.com/VibhuJawa",
            "followers_url": "https://api.github.com/users/VibhuJawa/followers",
            "following_url": "https://api.github.com/users/VibhuJawa/following{/other_user}",
            "gists_url": "https://api.github.com/users/VibhuJawa/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/VibhuJawa/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/VibhuJawa/subscriptions",
            "organizations_url": "https://api.github.com/users/VibhuJawa/orgs",
            "repos_url": "https://api.github.com/users/VibhuJawa/repos",
            "events_url": "https://api.github.com/users/VibhuJawa/events{/privacy}",
            "received_events_url": "https://api.github.com/users/VibhuJawa/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-05-26T21:32:38Z",
        "updated_at": "2020-05-26T21:38:34Z",
        "author_association": "MEMBER",
        "body": "Dask Example for this issue: \r\n\r\n#### Random Data Creation Helper \r\n```python\r\n\r\nimport dask\r\nimport dask.array as da\r\n\r\nfrom dask.distributed import Client,LocalCluster,wait\r\ncluster = LocalCluster(n_workers=40,ip='10.33.227.151')\r\nclient = Client(cluster) \r\n\r\n\r\ndef create_random_data(n_rows=1000, n_parts = 10, n_keys=30_000_000, col_prefix = 'a'):\r\n    \r\n    chunks = n_rows//n_parts\r\n\r\n    df = dd.concat([\r\n        da.random.randint(0, n_keys, size=n_rows, chunks = chunks).to_dask_dataframe(columns= col_prefix + '_0'),\r\n        da.random.randint(0, n_keys, size=n_rows, chunks = chunks).to_dask_dataframe(columns= col_prefix + '_1'),\r\n        da.random.randint(0, n_keys, size=n_rows, chunks = chunks).to_dask_dataframe(columns= col_prefix + '_2'),\r\n        da.random.randint(0, n_keys, size=n_rows, chunks = chunks).to_dask_dataframe(columns= col_prefix + '_3'),\r\n        da.random.randint(0, n_keys, size=n_rows, chunks = chunks).to_dask_dataframe(columns= col_prefix + '_val_col')\r\n        \r\n    ], axis=1).persist()\r\n    \r\n    _ = wait(df)\r\n    del _\r\n    \r\n    return df\r\n\r\n\r\nimport dask.dataframe as dd\r\nn_rows = 50_000_000\r\nn_parts = 160\r\n\r\ndf_1 = create_random_data(n_rows = n_rows, n_parts = n_parts, col_prefix = 'a')\r\ndf_2 = create_random_data(n_rows = n_rows, n_parts = n_parts, col_prefix = 'b')\r\ndf_3 = create_random_data(n_rows = n_rows, n_parts = n_parts, col_prefix = 'c')\r\ndf_4 = create_random_data(n_rows = n_rows, n_parts = n_parts, col_prefix = 'd')\r\ndf_5 = create_random_data(n_rows = n_rows, n_parts = n_parts, col_prefix = 'e')\r\n```\r\n\r\n\r\n### Without Filtering in merges\r\nTime: 1min 32s\r\nPeak Memory:  ~150 GB+\r\n\r\n```python\r\nmerged_df = df_1.merge(df_2, left_on = ['a_0'], right_on = ['b_0'])\r\nmerged_df = merged_df.merge(df_3, left_on = ['b_1'], right_on = ['c_1'])\r\nmerged_df = merged_df.merge(df_4, left_on = ['c_2'], right_on = ['d_2'])\r\nmerged_df = merged_df.merge(df_5, left_on = ['d_3'], right_on = ['e_3'])\r\nfinal_cols = [prefix + '_val_col' for prefix in ['a','b','c','d']]\r\nmerged_df = merged_df[final_cols]\r\n\r\n%time len(merged_df)\r\n```\r\n```\r\nCPU times: user 1min 16s, sys: 12.4 s, total: 1min 28s\r\nWall time: 1min 32s\r\n385780301\r\n```\r\n\r\n### With Filtering in merges\r\nTime:  56.7 s\r\nPeak Memory:  ~80 Gb ish\r\n\r\n\r\n```python\r\nmerged_df = df_1.merge(df_2, left_on = ['a_0'], right_on = ['b_0'])\r\nmerged_df = merged_df[['a_val_col','b_val_col','b_1']]\r\n\r\nmerged_df = merged_df.merge(df_3, left_on = ['b_1'], right_on = ['c_1'])\r\nmerged_df = merged_df[['a_val_col','b_val_col','c_val_col','c_2']]\r\n\r\nmerged_df = merged_df.merge(df_4, left_on = ['c_2'], right_on = ['d_2'])\r\nmerged_df = merged_df[['a_val_col','b_val_col','c_val_col','d_val_col','d_3']]\r\n\r\nmerged_df = merged_df.merge(df_5, left_on = ['d_3'], right_on = ['e_3'])\r\nfinal_cols = [prefix + '_val_col' for prefix in ['a','b','c','d']]\r\nmerged_df = merged_df[final_cols]\r\n\r\n%time len(merged_df)\r\n```\r\n\r\n\r\n```\r\nCPU times: user 49.5 s, sys: 6.1 s, total: 55.6 s\r\nWall time: 56.7 s\r\n385780301\r\n```\r\n\r\nGist: https://gist.github.com/VibhuJawa/bcabfec1506b9b30df7d5d1dd3c1eecd\r\n\r\n\r\nThe main point is that without filtering we end up with a lot more columns that is really needed. \r\n\r\nIn the above example we have below without filtering:\r\n\r\n```\r\nIndex(['a_0', 'a_1', 'a_2', 'a_3', 'a_val_col', 'b_0', 'b_1', 'b_2', 'b_3',\r\n       'b_val_col', 'c_0', 'c_1', 'c_2', 'c_3', 'c_val_col', 'd_0', 'd_1',\r\n       'd_2', 'd_3', 'd_val_col', 'e_0', 'e_1', 'e_2', 'e_3', 'e_val_col'],\r\n      dtype='object')\r\n\r\n```\r\n\r\nAnd with filtering we have:\r\n\r\n```\r\nIndex(['a_val_col', 'b_val_col', 'c_val_col', 'd_val_col', 'd_3', 'e_0', 'e_1',\r\n       'e_2', 'e_3', 'e_val_col'],\r\n      dtype='object')\r\n\r\n```\r\n\r\n\r\nReally sorry for the delay in getting around to this. This slipped through cracks . Hope above example helps. \r\n\r\nCC: @rjzamora / @quasiben ",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/634291208/reactions",
            "total_count": 2,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 2,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/635825914",
        "html_url": "https://github.com/dask/dask/issues/5809#issuecomment-635825914",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/5809",
        "id": 635825914,
        "node_id": "MDEyOklzc3VlQ29tbWVudDYzNTgyNTkxNA==",
        "user": {
            "login": "jakirkham",
            "id": 3019665,
            "node_id": "MDQ6VXNlcjMwMTk2NjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3019665?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jakirkham",
            "html_url": "https://github.com/jakirkham",
            "followers_url": "https://api.github.com/users/jakirkham/followers",
            "following_url": "https://api.github.com/users/jakirkham/following{/other_user}",
            "gists_url": "https://api.github.com/users/jakirkham/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jakirkham/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jakirkham/subscriptions",
            "organizations_url": "https://api.github.com/users/jakirkham/orgs",
            "repos_url": "https://api.github.com/users/jakirkham/repos",
            "events_url": "https://api.github.com/users/jakirkham/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jakirkham/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-05-29T08:03:05Z",
        "updated_at": "2020-05-29T08:03:05Z",
        "author_association": "MEMBER",
        "body": "cc @madsbk",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/635825914/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/692899817",
        "html_url": "https://github.com/dask/dask/issues/5809#issuecomment-692899817",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/5809",
        "id": 692899817,
        "node_id": "MDEyOklzc3VlQ29tbWVudDY5Mjg5OTgxNw==",
        "user": {
            "login": "calebwin",
            "id": 20741909,
            "node_id": "MDQ6VXNlcjIwNzQxOTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/20741909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/calebwin",
            "html_url": "https://github.com/calebwin",
            "followers_url": "https://api.github.com/users/calebwin/followers",
            "following_url": "https://api.github.com/users/calebwin/following{/other_user}",
            "gists_url": "https://api.github.com/users/calebwin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/calebwin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/calebwin/subscriptions",
            "organizations_url": "https://api.github.com/users/calebwin/orgs",
            "repos_url": "https://api.github.com/users/calebwin/repos",
            "events_url": "https://api.github.com/users/calebwin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/calebwin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-09-15T18:38:08Z",
        "updated_at": "2020-09-15T18:39:27Z",
        "author_association": "NONE",
        "body": "Are there workflows that don't necessarily have multiple merges where this would be useful?\r\n\r\nI think in theory there could be and the more general thing you would want to optimize for is to minimize the number of columns present at all stages of task graph execution. And you could do that by dropping columns at the latest point in the graph where they are used. But I don't know if there are cases in practice where this more general optimization would be useful. (edit: or maybe this is already done, I don't know)",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/692899817/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]