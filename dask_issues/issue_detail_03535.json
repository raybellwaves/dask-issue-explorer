{
    "url": "https://api.github.com/repos/dask/dask/issues/3535",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/3535/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/3535/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/3535/events",
    "html_url": "https://github.com/dask/dask/issues/3535",
    "id": 326575178,
    "node_id": "MDU6SXNzdWUzMjY1NzUxNzg=",
    "number": 3535,
    "title": "possible optimization for slice / concatenate operations over contiguous chunks",
    "user": {
        "login": "rabernat",
        "id": 1197350,
        "node_id": "MDQ6VXNlcjExOTczNTA=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1197350?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/rabernat",
        "html_url": "https://github.com/rabernat",
        "followers_url": "https://api.github.com/users/rabernat/followers",
        "following_url": "https://api.github.com/users/rabernat/following{/other_user}",
        "gists_url": "https://api.github.com/users/rabernat/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/rabernat/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/rabernat/subscriptions",
        "organizations_url": "https://api.github.com/users/rabernat/orgs",
        "repos_url": "https://api.github.com/users/rabernat/repos",
        "events_url": "https://api.github.com/users/rabernat/events{/privacy}",
        "received_events_url": "https://api.github.com/users/rabernat/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862305,
            "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=",
            "url": "https://api.github.com/repos/dask/dask/labels/array",
            "name": "array",
            "color": "006b75",
            "default": false,
            "description": null
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 4,
    "created_at": "2018-05-25T15:44:41Z",
    "updated_at": "2018-06-08T15:00:00Z",
    "closed_at": null,
    "author_association": "MEMBER",
    "active_lock_reason": null,
    "body": "Dask's [`array.roll`](https://github.com/dask/dask/blob/4020cb97a1d356d0b05c9c9b5c96f1aa277f3bf9/dask/array/routines.py#L875-L920) function shifts the positions of array elements along an axis, wrapping around the edge of the array. This operation is very important for many numerical calculations. It does this by slicing the array and then calling `concatenate` to piece it back together in the new order.\r\n\r\nXarray's [`roll` method](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.roll.html) basically [re-implements](https://github.com/pydata/xarray/blob/master/xarray/core/variable.py#L985-L1003) the same logic. In [xgcm](http://xgcm.readthedocs.io/en/latest/), we we also do something similar, but possibly using more complex topological connections between elements of the array than the simple periodicity assumed by `roll`. I am motivated to raise this issue here because of scalability challenges related to xgcm on very large datasets.\r\n\r\nI think there is an opportunity for optimization of these operations in the **special case where the roll occurs over a contiguous chunk**. (In practice, this is often the case.) Consider the following example.\r\n\r\n```python\r\nimport numpy as np\r\nimport dask.array as dsa\r\n\r\nnt = 2\r\nnx = 500\r\ndata = dsa.random.random(size=(nt, nx), chunks=(1, nx))\r\ndsa.roll(data, 1, axis=-1).visualize()\r\n```\r\n![image](https://user-images.githubusercontent.com/1197350/40553065-8f80d2aa-600f-11e8-9d14-8ec40ea46a8f.png)\r\n\r\nIt is instructive to re-implement our own roll function the way dask does it to see that it works the same:\r\n\r\n```python\r\ndef roll_with_dask(array, split_point):\r\n    left = array[..., :split_point]\r\n    right = array[..., split_point:]\r\n    return dsa.concatenate([right, left], axis=-1)\r\nroll_with_dask(data, 1).visualize()\r\n```\r\n![image](https://user-images.githubusercontent.com/1197350/40553059-862b2412-600f-11e8-83ae-fc6bdd2f45a9.png)\r\n\r\nNow I implement the same function in numpy and apply it with map blocks:\r\n```python\r\ndef roll_with_numpy(array, split_point):\r\n    left = array[..., :split_point]\r\n    right = array[..., split_point:]\r\n    return np.concatenate([right, left], axis=-1)\r\ndata.map_blocks(roll_with_numpy, 1).visualize()\r\n```\r\n![image](https://user-images.githubusercontent.com/1197350/40553157-ce6241d4-600f-11e8-8753-029274ff8039.png)\r\n\r\nThese two give the same answer:\r\n```python\r\nnp.testing.assert_allclose(\r\n    data.map_blocks(roll_with_numpy, 1),\r\n    roll_with_dask(data, 1)\r\n)\r\n```\r\n\r\nBut the `map_blocks` version has fewer chunks and consequently is much more efficient. Furthermore, no rechunking is required down the line if we want to combine this rolled array with other non-rolled array (e.g. when taking a finite difference). These things make a big difference when working with very large arrays.\r\n\r\nTo generalize this example, it seems that all slice and concat operations over contiguous chunks should be able to be accomplished at the numpy level. Is this something that could conceivably be detected at the optimization stage and in-lined?",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/3535/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/3535/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}