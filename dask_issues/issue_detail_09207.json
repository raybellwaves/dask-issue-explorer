{
    "url": "https://api.github.com/repos/dask/dask/issues/9207",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/9207/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/9207/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/9207/events",
    "html_url": "https://github.com/dask/dask/issues/9207",
    "id": 1280688152,
    "node_id": "I_kwDOAbcwm85MVcAY",
    "number": 9207,
    "title": "repartitioning dataframe with unknown divisions results in poorly-distributed chunk sizes",
    "user": {
        "login": "delgadom",
        "id": 3698640,
        "node_id": "MDQ6VXNlcjM2OTg2NDA=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3698640?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/delgadom",
        "html_url": "https://github.com/delgadom",
        "followers_url": "https://api.github.com/users/delgadom/followers",
        "following_url": "https://api.github.com/users/delgadom/following{/other_user}",
        "gists_url": "https://api.github.com/users/delgadom/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/delgadom/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/delgadom/subscriptions",
        "organizations_url": "https://api.github.com/users/delgadom/orgs",
        "repos_url": "https://api.github.com/users/delgadom/repos",
        "events_url": "https://api.github.com/users/delgadom/events{/privacy}",
        "received_events_url": "https://api.github.com/users/delgadom/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        },
        {
            "id": 996497175,
            "node_id": "MDU6TGFiZWw5OTY0OTcxNzU=",
            "url": "https://api.github.com/repos/dask/dask/labels/good%20second%20issue",
            "name": "good second issue",
            "color": "5319e7",
            "default": false,
            "description": "Clearly described, educational, but less trivial than \"good first issue\"."
        },
        {
            "id": 3798602129,
            "node_id": "LA_kwDOAbcwm87iahGR",
            "url": "https://api.github.com/repos/dask/dask/labels/enhancement",
            "name": "enhancement",
            "color": "C2E0C6",
            "default": true,
            "description": "Improve existing functionality or make things work better"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2022-06-22T18:21:14Z",
    "updated_at": "2022-06-22T19:36:48Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "active_lock_reason": null,
    "body": "When a dask.dataframe has unknown division sizes (because it's been read from file or from delayed), repartition's heuristics for allocating the partitions could probably be a bit smarter. If not, a bit of extra docs might be helpful\r\n\r\nMRE:\r\n```python\r\nimport dask.dataframe, pandas as pd, numpy as np, dask\r\nfrom dask.delayed import delayed\r\n\r\nddf = dask.dataframe.from_delayed(\r\n    [delayed(pd.DataFrame({'A': np.arange(100)})) for _ in range(4)]\r\n    + [delayed(pd.DataFrame({'A': np.arange(50)}))]\r\n).persist()\r\n```\r\nThis dataframe has 5 chunks of 100 rows each, and a final chunk of 50 rows. This is a pretty common partition structure for a file (e.g. lots of big chunks and a small final one):\r\n```python\r\nIn [2]: ddf.map_partitions(len, meta={'A': int}).compute()\r\nOut[2]:\r\n0    100\r\n1    100\r\n2    100\r\n3    100\r\n4     50\r\ndtype: int64\r\n```\r\nGiven this data, it might make sense to repartition to 9 partitions, splitting each of the first four in half, and leaving the last one alone. Since the partitions are unknown, it makes sense if dask wouldn't automatically do this exactly how you'd like based on the data, but I'd expect some sort of even allocation of extra partitions to each of the current partitions. However, if we repartition using npartitions _which is not an exact multiple of the current number of partitions_, any extra partitions are allocated to the final partition:\r\n```python\r\nIn [3]: ddf.repartition(9).map_partitions(len, meta={'A': int}).compute()\r\nOut[3]:\r\n0    100\r\n1    100\r\n2    100\r\n3    100\r\n4     10\r\n5     10\r\n6     10\r\n7     10\r\n8     10\r\ndtype: int64\r\n```\r\nThis results in a sub-optimal case where you still have the original four large partitions, with the last partition being split a number of ways. This is true for larger numbers of partitions as well - it seems the algorithm currently allocates `npartitions % current_npartitions` all to the final chunk.\r\n\r\nfull disclosure I did run this on `'2022.04.0'`. I didn't see a recent issue for it but it's possible this isn't a current issue?\r\n\r\nI don't have bandwidth to tackle this right now but it seems to me like this could be a good first issue.\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/9207/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/9207/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}