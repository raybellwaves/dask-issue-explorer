[
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1074058377",
        "html_url": "https://github.com/dask/dask/issues/8829#issuecomment-1074058377",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/8829",
        "id": 1074058377,
        "node_id": "IC_kwDOAbcwm85ABNSJ",
        "user": {
            "login": "bryanwweber",
            "id": 4396228,
            "node_id": "MDQ6VXNlcjQzOTYyMjg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4396228?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bryanwweber",
            "html_url": "https://github.com/bryanwweber",
            "followers_url": "https://api.github.com/users/bryanwweber/followers",
            "following_url": "https://api.github.com/users/bryanwweber/following{/other_user}",
            "gists_url": "https://api.github.com/users/bryanwweber/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bryanwweber/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bryanwweber/subscriptions",
            "organizations_url": "https://api.github.com/users/bryanwweber/orgs",
            "repos_url": "https://api.github.com/users/bryanwweber/repos",
            "events_url": "https://api.github.com/users/bryanwweber/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bryanwweber/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-21T15:41:51Z",
        "updated_at": "2022-03-21T15:41:51Z",
        "author_association": "CONTRIBUTOR",
        "body": "I think the existing behavior is expected. The parts of the file are lexicographically sorted before they're read. This is implied by the docstring for `to_parquet(..., name_function=...)` which says that the name function must preserve the lexicographic ordering of the partitions. Checking the code for `read_parquet()`, I can see that the paths are sorted before reading, here: https://github.com/dask/dask/blob/e54f1c6453455b3e26891702f6cfc547fb861121/dask/dataframe/io/parquet/core.py#L371\r\n\r\nCertainly, this could be better documented. I'll leave it to someone else to decide if and option should be added to specify that files should be loaded in the order they're passed \ud83d\ude04 ",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1074058377/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1074070394",
        "html_url": "https://github.com/dask/dask/issues/8829#issuecomment-1074070394",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/8829",
        "id": 1074070394,
        "node_id": "IC_kwDOAbcwm85ABQN6",
        "user": {
            "login": "rajeee",
            "id": 12487392,
            "node_id": "MDQ6VXNlcjEyNDg3Mzky",
            "avatar_url": "https://avatars.githubusercontent.com/u/12487392?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rajeee",
            "html_url": "https://github.com/rajeee",
            "followers_url": "https://api.github.com/users/rajeee/followers",
            "following_url": "https://api.github.com/users/rajeee/following{/other_user}",
            "gists_url": "https://api.github.com/users/rajeee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rajeee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rajeee/subscriptions",
            "organizations_url": "https://api.github.com/users/rajeee/orgs",
            "repos_url": "https://api.github.com/users/rajeee/repos",
            "events_url": "https://api.github.com/users/rajeee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rajeee/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-21T15:52:34Z",
        "updated_at": "2022-03-21T15:52:49Z",
        "author_association": "NONE",
        "body": "I think this behavior is a limitation. If you want to load the files in a custom order, there is currently no way to do so unless you rename the files. It makes sense to sort the paths if the list of paths is created by automatically listing the files. However, I think, it makes the most sense to not sort the user supplied list so that the user can load the files in the order they want. And it seems like it wouldn't be too hard to lift this limitation. ",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1074070394/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1074206879",
        "html_url": "https://github.com/dask/dask/issues/8829#issuecomment-1074206879",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/8829",
        "id": 1074206879,
        "node_id": "IC_kwDOAbcwm85ABxif",
        "user": {
            "login": "bryanwweber",
            "id": 4396228,
            "node_id": "MDQ6VXNlcjQzOTYyMjg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4396228?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bryanwweber",
            "html_url": "https://github.com/bryanwweber",
            "followers_url": "https://api.github.com/users/bryanwweber/followers",
            "following_url": "https://api.github.com/users/bryanwweber/following{/other_user}",
            "gists_url": "https://api.github.com/users/bryanwweber/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bryanwweber/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bryanwweber/subscriptions",
            "organizations_url": "https://api.github.com/users/bryanwweber/orgs",
            "repos_url": "https://api.github.com/users/bryanwweber/repos",
            "events_url": "https://api.github.com/users/bryanwweber/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bryanwweber/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-21T17:30:48Z",
        "updated_at": "2022-03-21T17:31:23Z",
        "author_association": "CONTRIBUTOR",
        "body": "> If you want to load the files in a custom order\r\n\r\nCan you add something about why you want to do this? Perhaps there's another way. Not saying it doesn't make sense, just that if there's another way to do this, we can unblock you now to keep doing your work \ud83d\ude04 ",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1074206879/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1074218266",
        "html_url": "https://github.com/dask/dask/issues/8829#issuecomment-1074218266",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/8829",
        "id": 1074218266,
        "node_id": "IC_kwDOAbcwm85AB0Ua",
        "user": {
            "login": "rajeee",
            "id": 12487392,
            "node_id": "MDQ6VXNlcjEyNDg3Mzky",
            "avatar_url": "https://avatars.githubusercontent.com/u/12487392?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rajeee",
            "html_url": "https://github.com/rajeee",
            "followers_url": "https://api.github.com/users/rajeee/followers",
            "following_url": "https://api.github.com/users/rajeee/following{/other_user}",
            "gists_url": "https://api.github.com/users/rajeee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rajeee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rajeee/subscriptions",
            "organizations_url": "https://api.github.com/users/rajeee/orgs",
            "repos_url": "https://api.github.com/users/rajeee/repos",
            "events_url": "https://api.github.com/users/rajeee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rajeee/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-21T17:42:11Z",
        "updated_at": "2022-03-21T17:42:11Z",
        "author_association": "NONE",
        "body": "Sure, I understand :). Also, good to have a use case in mind rather than a generic \"makes sense\" feature request. \r\nThe use case is like this: I have about 10k parquet files that holds timeseries values for 10k homes. Since these are too many files, I want to group a bunch of them together. However, I want to group them intelligently so that each group only contains houses belonging to, let's say, same city. One way to do this is repartitioning with custom divisions. But for this to work, I need to have the files be partitioned in a certain order to begin with.  \r\n\r\n[This SO question](https://stackoverflow.com/questions/71486742/dask-dataframe-to-parquet-fails-on-read-repartition-write-operation) I asked might provide more context.  I attempted to do that using dask.delayed (which would allow me to decide which file goes into which partition). But using dask.delayed has its own limitation and I would rather use read_parquet directly. But then, read_parquet doesn't honor the order in the input list. Which brings me to this issue. :)\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1074218266/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1074274812",
        "html_url": "https://github.com/dask/dask/issues/8829#issuecomment-1074274812",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/8829",
        "id": 1074274812,
        "node_id": "IC_kwDOAbcwm85ACCH8",
        "user": {
            "login": "bryanwweber",
            "id": 4396228,
            "node_id": "MDQ6VXNlcjQzOTYyMjg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4396228?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bryanwweber",
            "html_url": "https://github.com/bryanwweber",
            "followers_url": "https://api.github.com/users/bryanwweber/followers",
            "following_url": "https://api.github.com/users/bryanwweber/following{/other_user}",
            "gists_url": "https://api.github.com/users/bryanwweber/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bryanwweber/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bryanwweber/subscriptions",
            "organizations_url": "https://api.github.com/users/bryanwweber/orgs",
            "repos_url": "https://api.github.com/users/bryanwweber/repos",
            "events_url": "https://api.github.com/users/bryanwweber/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bryanwweber/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-21T18:38:14Z",
        "updated_at": "2022-03-21T18:38:14Z",
        "author_association": "CONTRIBUTOR",
        "body": "Can you use the `filters` keyword argument to filter the data, or the `columns` argument? It's not quite clear to me how your files are organized. Is it 1 house's timeseries per parquet file, or 1 house per column? How do you know which files are associated with each, say, city?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1074274812/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1074349978",
        "html_url": "https://github.com/dask/dask/issues/8829#issuecomment-1074349978",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/8829",
        "id": 1074349978,
        "node_id": "IC_kwDOAbcwm85ACUea",
        "user": {
            "login": "rajeee",
            "id": 12487392,
            "node_id": "MDQ6VXNlcjEyNDg3Mzky",
            "avatar_url": "https://avatars.githubusercontent.com/u/12487392?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rajeee",
            "html_url": "https://github.com/rajeee",
            "followers_url": "https://api.github.com/users/rajeee/followers",
            "following_url": "https://api.github.com/users/rajeee/following{/other_user}",
            "gists_url": "https://api.github.com/users/rajeee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rajeee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rajeee/subscriptions",
            "organizations_url": "https://api.github.com/users/rajeee/orgs",
            "repos_url": "https://api.github.com/users/rajeee/repos",
            "events_url": "https://api.github.com/users/rajeee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rajeee/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-21T19:52:55Z",
        "updated_at": "2022-03-21T19:53:58Z",
        "author_association": "NONE",
        "body": "It's one house per parquet file. Each columns could be power consumption of different circuits. The mapping of buildings to cities is stored in a separate file. I don't see how \"filters\" argument could help here. ",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1074349978/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1075266027",
        "html_url": "https://github.com/dask/dask/issues/8829#issuecomment-1075266027",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/8829",
        "id": 1075266027,
        "node_id": "IC_kwDOAbcwm85AF0Hr",
        "user": {
            "login": "jsignell",
            "id": 4806877,
            "node_id": "MDQ6VXNlcjQ4MDY4Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4806877?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jsignell",
            "html_url": "https://github.com/jsignell",
            "followers_url": "https://api.github.com/users/jsignell/followers",
            "following_url": "https://api.github.com/users/jsignell/following{/other_user}",
            "gists_url": "https://api.github.com/users/jsignell/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jsignell/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jsignell/subscriptions",
            "organizations_url": "https://api.github.com/users/jsignell/orgs",
            "repos_url": "https://api.github.com/users/jsignell/repos",
            "events_url": "https://api.github.com/users/jsignell/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jsignell/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-22T14:39:14Z",
        "updated_at": "2022-03-22T14:39:14Z",
        "author_association": "MEMBER",
        "body": "This seems like a valid request, but I'm not sure how feasible it is. The sorting seems really baked in. I tried naively removing the sorted line that Bryan pointed out above, but the output is still sorted. There is a lot of path sorting that goes on in the backend, which makes me worried about the implications of trying to make this more flexible. \r\n\r\nWould it be possible to load different cities into separate dataframes and the concatenate them into one large dataframe?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1075266027/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1075457378",
        "html_url": "https://github.com/dask/dask/issues/8829#issuecomment-1075457378",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/8829",
        "id": 1075457378,
        "node_id": "IC_kwDOAbcwm85AGi1i",
        "user": {
            "login": "rajeee",
            "id": 12487392,
            "node_id": "MDQ6VXNlcjEyNDg3Mzky",
            "avatar_url": "https://avatars.githubusercontent.com/u/12487392?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rajeee",
            "html_url": "https://github.com/rajeee",
            "followers_url": "https://api.github.com/users/rajeee/followers",
            "following_url": "https://api.github.com/users/rajeee/following{/other_user}",
            "gists_url": "https://api.github.com/users/rajeee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rajeee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rajeee/subscriptions",
            "organizations_url": "https://api.github.com/users/rajeee/orgs",
            "repos_url": "https://api.github.com/users/rajeee/repos",
            "events_url": "https://api.github.com/users/rajeee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rajeee/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-22T18:04:03Z",
        "updated_at": "2022-03-22T18:04:03Z",
        "author_association": "NONE",
        "body": "Thanks @jsignell.\r\n\r\nI also had [another hurdle](https://stackoverflow.com/questions/71549122/how-to-read-list-of-parquets-with-partially-overlapping-set-of-columns-in-dask/71552863?noredirect=1#comment126500576_71552863) which required me to pre-process the files anyway. So I ended up renaming the files during the pre-process. \r\nBut, yeah, for a general case, it would be nice if dask would honor the order of files in the input path list.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1075457378/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1075600810",
        "html_url": "https://github.com/dask/dask/issues/8829#issuecomment-1075600810",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/8829",
        "id": 1075600810,
        "node_id": "IC_kwDOAbcwm85AHF2q",
        "user": {
            "login": "rjzamora",
            "id": 20461013,
            "node_id": "MDQ6VXNlcjIwNDYxMDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rjzamora",
            "html_url": "https://github.com/rjzamora",
            "followers_url": "https://api.github.com/users/rjzamora/followers",
            "following_url": "https://api.github.com/users/rjzamora/following{/other_user}",
            "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions",
            "organizations_url": "https://api.github.com/users/rjzamora/orgs",
            "repos_url": "https://api.github.com/users/rjzamora/repos",
            "events_url": "https://api.github.com/users/rjzamora/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rjzamora/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-22T20:21:22Z",
        "updated_at": "2022-03-22T20:21:22Z",
        "author_association": "MEMBER",
        "body": "\r\nWe can certainly avoid sorting the file names, but it couldn't be the default behavior (since current users/tests expect dask to correct input glob ordering to be numerical ordering).  Therefore, we would probably need to add another argument to `read_parquet`, and I get the sense that it is not an option many people would be using.  With that said, I will be happy to work on this if enough people can confirm that the current behavior is a problem.\r\n\r\nIf I understand correctly, the larger problem you are facing is that you need to aggregate many small files into a parquet dataset with fewer files. The most common approach to doing this for an arbitrary file pattern is definitely to use  `from_delayed`. However, in your SO question, I see that you are defining a distinct delayed function for every file. This should \"work\", but will result in a very large graph. If you already know the mapping between file names and \u201ccity\u201d, for example, I\u2019d want my delayed partitions to originate from a function designed to read in and concatenate data for multiple files (rather than just one).\r\n\r\nIf you want to try to use the `read_parquet` API for this, you can also try `read_parquet(..., aggregate_files=True)` (along with a `chunksize=` or `split_row_groups=` setting to specify the size of the output partitions).   However, this will not result in each partition cleanly mapping to the same city as you want (it will just give you fewer partitions).  I think the most common way to \"partition\" the parquet dataset on disk is to do something like:\r\n\r\n`dd.read_parquet(paths, aggregate_files=True, chunksize=\u20181GB\u2019).to_parquet(partitioned_path, partition_on=[\"city\"])`\r\n\r\nThis will not result in a smaller number of files, but you could always read the dataset back as\r\n\r\n`dd.read_parquet(partitioned_path, aggregate_files=\"city\")` to get a distinct city in each dask partition.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1075600810/reactions",
            "total_count": 2,
            "+1": 2,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1075660405",
        "html_url": "https://github.com/dask/dask/issues/8829#issuecomment-1075660405",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/8829",
        "id": 1075660405,
        "node_id": "IC_kwDOAbcwm85AHUZ1",
        "user": {
            "login": "rajeee",
            "id": 12487392,
            "node_id": "MDQ6VXNlcjEyNDg3Mzky",
            "avatar_url": "https://avatars.githubusercontent.com/u/12487392?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rajeee",
            "html_url": "https://github.com/rajeee",
            "followers_url": "https://api.github.com/users/rajeee/followers",
            "following_url": "https://api.github.com/users/rajeee/following{/other_user}",
            "gists_url": "https://api.github.com/users/rajeee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rajeee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rajeee/subscriptions",
            "organizations_url": "https://api.github.com/users/rajeee/orgs",
            "repos_url": "https://api.github.com/users/rajeee/repos",
            "events_url": "https://api.github.com/users/rajeee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rajeee/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-22T21:26:26Z",
        "updated_at": "2022-03-22T21:26:26Z",
        "author_association": "NONE",
        "body": "Thanks for detailed reply @rjzamora. Yes, I also tried dataframe.from_delayed where each delayed object is returning a concatenation of a bunch of files. It did work okay but started breaking (taking forever to schedule) once the number of such delayed objects reached around 6K (happens when aggregating largish ~500K files). I finally transitioned to using a simple map of delayed objects that would directly write concatenated files to disk independently without forming a dataframe. \r\n\r\nI am personally not blocked by this anymore; so it's up to you guys to decide if adding an option to not sort the input path is a worthwhile feature to add or not. I am kinda wondering why the decision was made to sort the input path list in dask; if people want sorted path, it's not hard to sort in the application code before passing to dask. ",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1075660405/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1075893414",
        "html_url": "https://github.com/dask/dask/issues/8829#issuecomment-1075893414",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/8829",
        "id": 1075893414,
        "node_id": "IC_kwDOAbcwm85AINSm",
        "user": {
            "login": "rjzamora",
            "id": 20461013,
            "node_id": "MDQ6VXNlcjIwNDYxMDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rjzamora",
            "html_url": "https://github.com/rjzamora",
            "followers_url": "https://api.github.com/users/rjzamora/followers",
            "following_url": "https://api.github.com/users/rjzamora/following{/other_user}",
            "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions",
            "organizations_url": "https://api.github.com/users/rjzamora/orgs",
            "repos_url": "https://api.github.com/users/rjzamora/repos",
            "events_url": "https://api.github.com/users/rjzamora/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rjzamora/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-23T04:06:51Z",
        "updated_at": "2022-03-23T04:06:51Z",
        "author_association": "MEMBER",
        "body": ">I finally transitioned to using a simple map of delayed objects that would directly write concatenated files to disk independently without forming a dataframe\u2028\u2028\r\n\r\nYeah - If your only goal is to write a new dataset, then skipping the from_delayed part makes a lot of sense.  I know most people use delayed over a custom graph, but I personally do something like the following for simple cases like these:\u2028\u2028\r\n\r\n```python\r\nimport pandas as pd\r\nfrom dask.dataframe.core import Scalar\r\n\r\nfiles_per_task = 10\r\ninput_paths = [\"tmpdir/part.0.parquet\", \"tmpdir/part.1.parquet\", \u2026]\r\noutput_dir = \"new_tmpdir\"\r\n\r\ndef read_concat_write(input_paths, output_path):\r\n    pd.concat(\r\n        [pd.read_parquet(path) for path in input_paths]\r\n    ).to_parquet(output_path)\r\n\r\ngraph = {\r\n    (\"read-files\", i): (\r\n        read_concat_write,\r\n        input_paths[j:j+files_per_task],\r\n        f\"{output_dir}/part.{i}.parquet\",\r\n    )\r\n    for i, j in enumerate(range(0, len(input_paths), files_per_task))\r\n}\r\ngraph[(\"finish\", 0)] = (lambda x: None, list(graph.keys()))\r\nScalar(graph, \"finish\", \"\").compute()\r\n```\r\n\r\n>I am personally not blocked by this anymore; so it's up to you guys to decide if adding an option to not sort the input path is a worthwhile feature to add or not.\r\n\r\nRegardless of it is currently blocking you, I am interested to know if the path-sorting has been a problem for anyone else.  This is the first issue I have seen about this, but it is certainly possible that others have run into the same problem but didn\u2019t bother to share their experience on GitHub. (So, thank you for sharing - I encourage you to keep doing so when behavior seems \u201coff\u201d)\r\n\r\n >I am kinda wondering why the decision was made to sort the input path list in dask; if people want sorted path, it's not hard to sort in the application code before passing to dask.\u2028\u2028\r\n\r\nFair question - The different engines have historically discovered paths in a slightly different order for directory-partitioned datasets. I think I remember this complicating aggregation behavior and parallel metadata parsing. The backends have also tended to use \u201cglob\u201d ordering instead of numerical ordering.  For these reasons, among others, the implicit sorting behavior was probably just introduced without much of an explicit decision. This is probably because no one ever asked for `read_parquet` to preserve the input path order, but people did ask for numerical ordering (and the directory-partitioning features that motivated the sorting).\r\n\r\nAll this is to say that: \u201cYes. It does seem to me like the user **should** have the option to preserve the order of the paths specified to read_parquet.  The reason that is isn\u2019t supported is just that (1) no one has raised an issue about this yet, and (2) always sorting the paths has simplified other features in `read_parquet`.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1075893414/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1076515049",
        "html_url": "https://github.com/dask/dask/issues/8829#issuecomment-1076515049",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/8829",
        "id": 1076515049,
        "node_id": "IC_kwDOAbcwm85AKlDp",
        "user": {
            "login": "rajeee",
            "id": 12487392,
            "node_id": "MDQ6VXNlcjEyNDg3Mzky",
            "avatar_url": "https://avatars.githubusercontent.com/u/12487392?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rajeee",
            "html_url": "https://github.com/rajeee",
            "followers_url": "https://api.github.com/users/rajeee/followers",
            "following_url": "https://api.github.com/users/rajeee/following{/other_user}",
            "gists_url": "https://api.github.com/users/rajeee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rajeee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rajeee/subscriptions",
            "organizations_url": "https://api.github.com/users/rajeee/orgs",
            "repos_url": "https://api.github.com/users/rajeee/repos",
            "events_url": "https://api.github.com/users/rajeee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rajeee/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-23T16:04:40Z",
        "updated_at": "2022-03-23T16:05:23Z",
        "author_association": "NONE",
        "body": "Thanks for the explanation and a bit of a history and context, Rick.\r\n\r\nYour example code looks too raw for my experience (I don't have experience with raw task graph or Scalar construct), so I am using something like this:\r\n\r\n```python\r\nfiles_groups = np.array_split(input_paths, files_per_task)\r\noutput_paths = [f\"{output_idr\"/part.{i}.parquet\" for i in range(len(files_groups))]\r\ndask.compute(map(dask.delayed(read_concat_write), files_groups, output_paths))\r\n```\r\nI assume this might be similar to your code though, under the hood.\r\n\r\nI have created only a couple of issues so far in this repo, and the engagements and feedbacks have been awesome. This definitely increases my confidence in using dask on my data processing projects. So, kudos to you guys and keep up the good work!  \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1076515049/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1079448125",
        "html_url": "https://github.com/dask/dask/issues/8829#issuecomment-1079448125",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/8829",
        "id": 1079448125,
        "node_id": "IC_kwDOAbcwm85AVxI9",
        "user": {
            "login": "rjzamora",
            "id": 20461013,
            "node_id": "MDQ6VXNlcjIwNDYxMDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rjzamora",
            "html_url": "https://github.com/rjzamora",
            "followers_url": "https://api.github.com/users/rjzamora/followers",
            "following_url": "https://api.github.com/users/rjzamora/following{/other_user}",
            "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions",
            "organizations_url": "https://api.github.com/users/rjzamora/orgs",
            "repos_url": "https://api.github.com/users/rjzamora/repos",
            "events_url": "https://api.github.com/users/rjzamora/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rjzamora/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-25T21:28:28Z",
        "updated_at": "2022-03-25T21:28:28Z",
        "author_association": "MEMBER",
        "body": "Just a note here that #8852 will likely improve `from_delayed` performance for applications like this.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1079448125/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]