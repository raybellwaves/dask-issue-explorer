{
    "url": "https://api.github.com/repos/dask/dask/issues/9051",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/9051/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/9051/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/9051/events",
    "html_url": "https://github.com/dask/dask/issues/9051",
    "id": 1228166857,
    "node_id": "I_kwDOAbcwm85JNFbJ",
    "number": 9051,
    "title": "Should we deprecate aggregate_files from read_parquet?",
    "user": {
        "login": "rjzamora",
        "id": 20461013,
        "node_id": "MDQ6VXNlcjIwNDYxMDEz",
        "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/rjzamora",
        "html_url": "https://github.com/rjzamora",
        "followers_url": "https://api.github.com/users/rjzamora/followers",
        "following_url": "https://api.github.com/users/rjzamora/following{/other_user}",
        "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions",
        "organizations_url": "https://api.github.com/users/rjzamora/orgs",
        "repos_url": "https://api.github.com/users/rjzamora/repos",
        "events_url": "https://api.github.com/users/rjzamora/events{/privacy}",
        "received_events_url": "https://api.github.com/users/rjzamora/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        },
        {
            "id": 365513534,
            "node_id": "MDU6TGFiZWwzNjU1MTM1MzQ=",
            "url": "https://api.github.com/repos/dask/dask/labels/io",
            "name": "io",
            "color": "6f871c",
            "default": false,
            "description": ""
        },
        {
            "id": 2949099791,
            "node_id": "MDU6TGFiZWwyOTQ5MDk5Nzkx",
            "url": "https://api.github.com/repos/dask/dask/labels/parquet",
            "name": "parquet",
            "color": "77A66C",
            "default": false,
            "description": ""
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2022-05-06T17:58:57Z",
    "updated_at": "2022-05-18T15:15:05Z",
    "closed_at": null,
    "author_association": "MEMBER",
    "active_lock_reason": null,
    "body": "This issue is similar to #8937 (already done) and #9043 in the sense that it aims to remove unnecessary (and rarely-utilized) options from `dd.read_parquet`.\r\n\r\nTLDR: I\u2019d like to propose that we deprecate the `aggregate_files` argument from `dd.read_parquet`.\r\n\r\nAlthough I do believe there is strong motivation for a file-aggregation feature (especially for hive/directory-partitioned datasets), the current implementation of this feature actually aggregates row-groups (rather than files), which is extremely inefficient at scale (or on remote storage). This implementation \u201csnafu\u201d is my own fault. However, rather than directly changing the current behavior, I suggest that we simply remove the option altogether.  Removing both `aggregate_files` and `chunksize` (see #9043) should allow us to cut out a lot of unnecessarily-complex core/engine code and reduce general maintenance burden.\r\n\r\nIn the future, we may wish to re-introduce an `aggregate_files`-like feature, but that (simpler) feature should be designed to aggregate full files (rather than arbitrary row-groups). Users (or down-stream libraries) that need more flexibility than simple \u201cper-row-groups\u201d or \u201cper-files\u201d partitioning should be able to feed their own custom logic into the new `from_map` API.",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/9051/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/9051/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}