{
    "url": "https://api.github.com/repos/dask/dask/issues/6070",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/6070/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/6070/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/6070/events",
    "html_url": "https://github.com/dask/dask/issues/6070",
    "id": 595964051,
    "node_id": "MDU6SXNzdWU1OTU5NjQwNTE=",
    "number": 6070,
    "title": "Groupby followed by another groupby raising error",
    "user": {
        "login": "victor-ab",
        "id": 26576394,
        "node_id": "MDQ6VXNlcjI2NTc2Mzk0",
        "avatar_url": "https://avatars.githubusercontent.com/u/26576394?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/victor-ab",
        "html_url": "https://github.com/victor-ab",
        "followers_url": "https://api.github.com/users/victor-ab/followers",
        "following_url": "https://api.github.com/users/victor-ab/following{/other_user}",
        "gists_url": "https://api.github.com/users/victor-ab/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/victor-ab/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/victor-ab/subscriptions",
        "organizations_url": "https://api.github.com/users/victor-ab/orgs",
        "repos_url": "https://api.github.com/users/victor-ab/repos",
        "events_url": "https://api.github.com/users/victor-ab/events{/privacy}",
        "received_events_url": "https://api.github.com/users/victor-ab/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2020-04-07T15:40:06Z",
    "updated_at": "2021-03-12T14:59:26Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "Two groupby in a row is raising an error if the first groupby uses two columns. May be related to the unsupported multi-indexing. #1493 \r\n\r\n```\r\nddf = dd.from_pandas(\r\n    pd.DataFrame(\r\n        {\r\n            \"ID\": [1, 1, 2, 2],\r\n            \"a\": [1, 2, 3, 4],\r\n            \"date\": [\r\n                datetime(2018, 1, 1),\r\n                datetime(2018, 1, 2),\r\n                datetime(2018, 1, 3),\r\n                datetime(2018, 1, 1),\r\n            ],\r\n        }\r\n    ),\r\n    npartitions=2,\r\n)\r\n\r\nddf.groupby([\"ID\", \"date\"])[[\"a\"]].sum().groupby([\"ID\"]).apply(\r\n    lambda x: x, meta=pd.DataFrame(columns=[\"ID\", \"date\", \"a\"])\r\n).compute()\r\n```\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-101-20089f0ac304> in <module>\r\n     16 \r\n     17 A.groupby([\"ID\", \"date\"])[[\"a\"]].sum().groupby([\"ID\"]).apply(\r\n---> 18     lambda x: x, meta=pd.DataFrame(columns=[\"ID\", \"date\", \"a\"])\r\n     19 ).compute()\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\base.py in compute(self, **kwargs)\r\n    164         dask.base.compute\r\n    165         \"\"\"\r\n--> 166         (result,) = compute(self, traverse=False, **kwargs)\r\n    167         return result\r\n    168 \r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\base.py in compute(*args, **kwargs)\r\n    435     keys = [x.__dask_keys__() for x in collections]\r\n    436     postcomputes = [x.__dask_postcompute__() for x in collections]\r\n--> 437     results = schedule(dsk, keys, **kwargs)\r\n    438     return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\r\n    439 \r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\threaded.py in get(dsk, result, cache, num_workers, pool, **kwargs)\r\n     82         get_id=_thread_get_id,\r\n     83         pack_exception=pack_exception,\r\n---> 84         **kwargs\r\n     85     )\r\n     86 \r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\local.py in get_async(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\r\n    484                         _execute_task(task, data)  # Re-execute locally\r\n    485                     else:\r\n--> 486                         raise_exception(exc, tb)\r\n    487                 res, worker_id = loads(res_info)\r\n    488                 state[\"cache\"][key] = res\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\local.py in reraise(exc, tb)\r\n    314     if exc.__traceback__ is not tb:\r\n    315         raise exc.with_traceback(tb)\r\n--> 316     raise exc\r\n    317 \r\n    318 \r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\local.py in execute_task(key, task_info, dumps, loads, get_id, pack_exception)\r\n    220     try:\r\n    221         task, data = loads(task_info)\r\n--> 222         result = _execute_task(task, data)\r\n    223         id = get_id()\r\n    224         result = dumps((result, id))\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\core.py in _execute_task(arg, cache, dsk)\r\n    119         # temporaries by their reference count and can execute certain\r\n    120         # operations in-place.\r\n--> 121         return func(*(_execute_task(a, cache) for a in args))\r\n    122     elif not ishashable(arg):\r\n    123         return arg\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\optimization.py in __call__(self, *args)\r\n    980         if not len(args) == len(self.inkeys):\r\n    981             raise ValueError(\"Expected %d args, got %d\" % (len(self.inkeys), len(args)))\r\n--> 982         return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\r\n    983 \r\n    984     def __reduce__(self):\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\core.py in get(dsk, out, cache)\r\n    149     for key in toposort(dsk):\r\n    150         task = dsk[key]\r\n--> 151         result = _execute_task(task, cache)\r\n    152         cache[key] = result\r\n    153     result = _execute_task(out, cache)\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\core.py in _execute_task(arg, cache, dsk)\r\n    119         # temporaries by their reference count and can execute certain\r\n    120         # operations in-place.\r\n--> 121         return func(*(_execute_task(a, cache) for a in args))\r\n    122     elif not ishashable(arg):\r\n    123         return arg\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\core.py in <genexpr>(.0)\r\n    119         # temporaries by their reference count and can execute certain\r\n    120         # operations in-place.\r\n--> 121         return func(*(_execute_task(a, cache) for a in args))\r\n    122     elif not ishashable(arg):\r\n    123         return arg\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\core.py in _execute_task(arg, cache, dsk)\r\n    119         # temporaries by their reference count and can execute certain\r\n    120         # operations in-place.\r\n--> 121         return func(*(_execute_task(a, cache) for a in args))\r\n    122     elif not ishashable(arg):\r\n    123         return arg\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\utils.py in apply(func, args, kwargs)\r\n     28 def apply(func, args, kwargs=None):\r\n     29     if kwargs:\r\n---> 30         return func(*args, **kwargs)\r\n     31     else:\r\n     32         return func(*args)\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py in apply_and_enforce(*args, **kwargs)\r\n   5072     func = kwargs.pop(\"_func\")\r\n   5073     meta = kwargs.pop(\"_meta\")\r\n-> 5074     df = func(*args, **kwargs)\r\n   5075     if is_dataframe_like(df) or is_series_like(df) or is_index_like(df):\r\n   5076         if not len(df):\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\shuffle.py in partitioning_index(df, npartitions)\r\n    604         An array of int64 values mapping each record to a partition.\r\n    605     \"\"\"\r\n--> 606     return hash_object_dispatch(df, index=False) % int(npartitions)\r\n    607 \r\n    608 \r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\utils.py in __call__(self, arg, *args, **kwargs)\r\n    504         \"\"\"\r\n    505         meth = self.dispatch(type(arg))\r\n--> 506         return meth(arg, *args, **kwargs)\r\n    507 \r\n    508     @property\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py in hash_object_pandas(obj, index, encoding, hash_key, categorize)\r\n    470 ):\r\n    471     return pd.util.hash_pandas_object(\r\n--> 472         obj, index=index, encoding=encoding, hash_key=hash_key, categorize=categorize\r\n    473     )\r\n    474 \r\n\r\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\util\\hashing.py in hash_pandas_object(obj, index, encoding, hash_key, categorize)\r\n    137         h = _combine_hash_arrays(hashes, num_items)\r\n    138 \r\n--> 139         h = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n    140     else:\r\n    141         raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n\r\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py in __init__(self, data, index, dtype, name, copy, fastpath)\r\n    290                     if len(index) != len(data):\r\n    291                         raise ValueError(\r\n--> 292                             f\"Length of passed values is {len(data)}, \"\r\n    293                             f\"index implies {len(index)}.\"\r\n    294                         )\r\n\r\nValueError: Length of passed values is 0, index implies 4.\r\n```\r\n\r\nif reset_index() is applied after the first groupby, it works:\r\n```\r\nA.groupby([\"ID\", \"date\"])[[\"a\"]].sum().reset_index().groupby([\"ID\"]).apply(\r\n    lambda x: x, meta=pd.DataFrame(columns=[\"ID\", \"date\", \"a\"])\r\n).compute()\r\n```\r\n```\r\n\tID\tdate\t\ta\r\n0\t1\t2018-01-01\t1\r\n1\t1\t2018-01-02\t2\r\n2\t2\t2018-01-01\t4\r\n3\t2\t2018-01-03\t3\r\n```\r\ndask.__version__: '2.12.0'\r\npandas.__version__: '1.0.1'",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/6070/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/6070/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}