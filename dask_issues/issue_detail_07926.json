{
    "url": "https://api.github.com/repos/dask/dask/issues/7926",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/7926/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/7926/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/7926/events",
    "html_url": "https://github.com/dask/dask/issues/7926",
    "id": 951142711,
    "node_id": "MDU6SXNzdWU5NTExNDI3MTE=",
    "number": 7926,
    "title": "dd.to_hdf produces HDF5ExtError ( unable to lock file, errno = 11, error message = 'Resource temporarily unavailable') on local cluster",
    "user": {
        "login": "N4321D",
        "id": 35295509,
        "node_id": "MDQ6VXNlcjM1Mjk1NTA5",
        "avatar_url": "https://avatars.githubusercontent.com/u/35295509?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/N4321D",
        "html_url": "https://github.com/N4321D",
        "followers_url": "https://api.github.com/users/N4321D/followers",
        "following_url": "https://api.github.com/users/N4321D/following{/other_user}",
        "gists_url": "https://api.github.com/users/N4321D/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/N4321D/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/N4321D/subscriptions",
        "organizations_url": "https://api.github.com/users/N4321D/orgs",
        "repos_url": "https://api.github.com/users/N4321D/repos",
        "events_url": "https://api.github.com/users/N4321D/events{/privacy}",
        "received_events_url": "https://api.github.com/users/N4321D/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 365513534,
            "node_id": "MDU6TGFiZWwzNjU1MTM1MzQ=",
            "url": "https://api.github.com/repos/dask/dask/labels/io",
            "name": "io",
            "color": "6f871c",
            "default": false,
            "description": ""
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2021-07-22T23:56:20Z",
    "updated_at": "2021-07-26T16:16:12Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "dask.dataframe (dd) produces a HDF5ExtError when running on local cluster.\r\n\r\nsome data (~100MB) is written to the file, so I suspect it is an parallel writing issue maybe? \r\n\r\nThe script works if not using client\r\n\r\n**Minimal example:**\r\n```\r\nimport dask.dataframe as dd\r\nimport dask.array as da\r\n\r\n# load dask client\r\nfrom dask.distributed import Client\r\nclient = Client()\r\nclient\r\n\r\nddf = da.random.randint(0, 0xFFFF, (int(1e8), 10)).to_dask_dataframe(columns=[f\"test {i}\" for i in range (10)])\r\n\r\nddf.to_hdf(\"delme.h5\", \r\n           key='/data*',\r\n           complevel=5, \r\n           complib=\"blosc:lz4hc\", \r\n)\r\n\r\n```\r\n\r\n**Output:**\r\n```\r\n---------------------------------------------------------------------------\r\nHDF5ExtError                              Traceback (most recent call last)\r\n<ipython-input-6-557a3a58ea58> in <module>\r\n----> 1 ddf.to_hdf(\"delme.h5\", \r\n      2            key='/data*',\r\n      3            complevel=5,\r\n      4            complib=\"blosc:lz4hc\",\r\n      5            mode='w'\r\n\r\n~/anaconda3/lib/python3.8/site-packages/dask/dataframe/core.py in to_hdf(self, path_or_buf, key, mode, append, **kwargs)\r\n   1464         from .io import to_hdf\r\n   1465 \r\n-> 1466         return to_hdf(self, path_or_buf, key, mode, append, **kwargs)\r\n   1467 \r\n   1468     def to_csv(self, filename, **kwargs):\r\n\r\n~/anaconda3/lib/python3.8/site-packages/dask/dataframe/io/hdf.py in to_hdf(df, path, key, mode, append, scheduler, name_function, compute, lock, dask_kwargs, **kwargs)\r\n    249 \r\n    250     if compute:\r\n--> 251         compute_as_if_collection(\r\n    252             DataFrame, dsk, keys, scheduler=scheduler, **dask_kwargs\r\n    253         )\r\n\r\n~/anaconda3/lib/python3.8/site-packages/dask/base.py in compute_as_if_collection(cls, dsk, keys, scheduler, get, **kwargs)\r\n    311     schedule = get_scheduler(scheduler=scheduler, cls=cls, get=get)\r\n    312     dsk2 = optimization_function(cls)(ensure_dict(dsk), keys, **kwargs)\r\n--> 313     return schedule(dsk2, keys, **kwargs)\r\n    314 \r\n    315 \r\n\r\n~/anaconda3/lib/python3.8/site-packages/distributed/client.py in get(self, dsk, keys, workers, allow_other_workers, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\r\n   2702                     should_rejoin = False\r\n   2703             try:\r\n-> 2704                 results = self.gather(packed, asynchronous=asynchronous, direct=direct)\r\n   2705             finally:\r\n   2706                 for f in futures.values():\r\n\r\n~/anaconda3/lib/python3.8/site-packages/distributed/client.py in gather(self, futures, errors, direct, asynchronous)\r\n   2016             else:\r\n   2017                 local_worker = None\r\n-> 2018             return self.sync(\r\n   2019                 self._gather,\r\n   2020                 futures,\r\n\r\n~/anaconda3/lib/python3.8/site-packages/distributed/client.py in sync(self, func, asynchronous, callback_timeout, *args, **kwargs)\r\n    857             return future\r\n    858         else:\r\n--> 859             return sync(\r\n    860                 self.loop, func, *args, callback_timeout=callback_timeout, **kwargs\r\n    861             )\r\n\r\n~/anaconda3/lib/python3.8/site-packages/distributed/utils.py in sync(loop, func, callback_timeout, *args, **kwargs)\r\n    324     if error[0]:\r\n    325         typ, exc, tb = error[0]\r\n--> 326         raise exc.with_traceback(tb)\r\n    327     else:\r\n    328         return result[0]\r\n\r\n~/anaconda3/lib/python3.8/site-packages/distributed/utils.py in f()\r\n    307             if callback_timeout is not None:\r\n    308                 future = asyncio.wait_for(future, callback_timeout)\r\n--> 309             result[0] = yield future\r\n    310         except Exception:\r\n    311             error[0] = sys.exc_info()\r\n\r\n~/anaconda3/lib/python3.8/site-packages/tornado/gen.py in run(self)\r\n    760 \r\n    761                     try:\r\n--> 762                         value = future.result()\r\n    763                     except Exception:\r\n    764                         exc_info = sys.exc_info()\r\n\r\n~/anaconda3/lib/python3.8/site-packages/distributed/client.py in _gather(self, futures, errors, direct, local_worker)\r\n   1881                             exc = CancelledError(key)\r\n   1882                         else:\r\n-> 1883                             raise exception.with_traceback(traceback)\r\n   1884                         raise exc\r\n   1885                     if errors == \"skip\":\r\n\r\n~/anaconda3/lib/python3.8/site-packages/dask/dataframe/io/hdf.py in _pd_to_hdf()\r\n     25         lock.acquire()\r\n     26     try:\r\n---> 27         pd_to_hdf(*args, **kwargs)\r\n     28     finally:\r\n     29         if lock:\r\n\r\n~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py in to_hdf()\r\n   2698         from pandas.io import pytables\r\n   2699 \r\n-> 2700         pytables.to_hdf(\r\n   2701             path_or_buf,\r\n   2702             key,\r\n\r\n~/anaconda3/lib/python3.8/site-packages/pandas/io/pytables.py in to_hdf()\r\n    309     path_or_buf = stringify_path(path_or_buf)\r\n    310     if isinstance(path_or_buf, str):\r\n--> 311         with HDFStore(\r\n    312             path_or_buf, mode=mode, complevel=complevel, complib=complib\r\n    313         ) as store:\r\n\r\n~/anaconda3/lib/python3.8/site-packages/pandas/io/pytables.py in __init__()\r\n    589         self._fletcher32 = fletcher32\r\n    590         self._filters = None\r\n--> 591         self.open(mode=mode, **kwargs)\r\n    592 \r\n    593     def __fspath__(self):\r\n\r\n~/anaconda3/lib/python3.8/site-packages/pandas/io/pytables.py in open()\r\n    738             raise ValueError(msg)\r\n    739 \r\n--> 740         self._handle = tables.open_file(self._path, self._mode, **kwargs)\r\n    741 \r\n    742     def close(self):\r\n\r\n~/anaconda3/lib/python3.8/site-packages/tables/file.py in open_file()\r\n    313 \r\n    314     # Finally, create the File instance, and return it\r\n--> 315     return File(filename, mode, title, root_uep, filters, **kwargs)\r\n    316 \r\n    317 \r\n\r\n~/anaconda3/lib/python3.8/site-packages/tables/file.py in __init__()\r\n    776 \r\n    777         # Now, it is time to initialize the File extension\r\n--> 778         self._g_new(filename, mode, **params)\r\n    779 \r\n    780         # Check filters and set PyTables format version for new files.\r\n\r\ntables/hdf5extension.pyx in tables.hdf5extension.File._g_new()\r\n\r\nHDF5ExtError: HDF5 error back trace\r\n\r\n  File \"H5F.c\", line 509, in H5Fopen\r\n    unable to open file\r\n  File \"H5Fint.c\", line 1400, in H5F__open\r\n    unable to open file\r\n  File \"H5Fint.c\", line 1615, in H5F_open\r\n    unable to lock the file\r\n  File \"H5FD.c\", line 1640, in H5FD_lock\r\n    driver lock request failed\r\n  File \"H5FDsec2.c\", line 941, in H5FD_sec2_lock\r\n    unable to lock file, errno = 11, error message = 'Resource temporarily unavailable'\r\n\r\nEnd of HDF5 error back trace\r\n\r\nUnable to open/create file 'delme.h5'\r\n```\r\n\r\n**Environment**:\r\n\r\n- Dask version: '2021.07.0'\r\n- tables version: '3.6.1'\r\n- Python version:   Python 3.8.2  (Ananconda)\r\n- Operating System: Ubuntu 21.04\r\n- Install method (conda, pip, source): conda\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/7926/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/7926/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}