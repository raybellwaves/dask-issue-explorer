{
    "url": "https://api.github.com/repos/dask/dask/issues/8307",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/8307/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/8307/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/8307/events",
    "html_url": "https://github.com/dask/dask/issues/8307",
    "id": 1037685892,
    "node_id": "I_kwDOAbcwm8492dSE",
    "number": 8307,
    "title": "Groupby + split_out fails when key columns have the same name",
    "user": {
        "login": "ayushdg",
        "id": 19949207,
        "node_id": "MDQ6VXNlcjE5OTQ5MjA3",
        "avatar_url": "https://avatars.githubusercontent.com/u/19949207?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ayushdg",
        "html_url": "https://github.com/ayushdg",
        "followers_url": "https://api.github.com/users/ayushdg/followers",
        "following_url": "https://api.github.com/users/ayushdg/following{/other_user}",
        "gists_url": "https://api.github.com/users/ayushdg/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/ayushdg/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/ayushdg/subscriptions",
        "organizations_url": "https://api.github.com/users/ayushdg/orgs",
        "repos_url": "https://api.github.com/users/ayushdg/repos",
        "events_url": "https://api.github.com/users/ayushdg/events{/privacy}",
        "received_events_url": "https://api.github.com/users/ayushdg/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        },
        {
            "id": 3468123446,
            "node_id": "LA_kwDOAbcwm87Ot102",
            "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention",
            "name": "needs attention",
            "color": "6d626c",
            "default": false,
            "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2021-10-27T17:37:26Z",
    "updated_at": "2021-12-06T01:48:45Z",
    "closed_at": null,
    "author_association": "MEMBER",
    "active_lock_reason": null,
    "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**What happened**:\r\nPerforming a groupby+aggregate while using the `split_out` argument fails in the corner case when the key columns being used to `split_out` might use the same name.\r\n\r\n**What you expected to happen**:\r\nSame behavior as when not using `split_out`\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nfrom dask import dataframe as dd\r\nimport pandas as pd\r\n\r\ndf = pd.DataFrame({'key':[1,2,1], 'val':[4,5,6]})\r\nddf = dd.from_pandas(df,2)\r\nddf.groupby(by=[df[\"key\"].isna(), df[\"key\"]]).count(split_out=2).compute()\r\n```\r\n\r\n<details>\r\n<summary>Stacktrace</summary>\r\n----> 6 ddf.groupby(by=[df[\"key\"].isna(), df[\"key\"]]).count(split_out=2).compute()\r\n\r\n/miniconda3/envs/rapids-21.12/lib/python3.8/site-packages/dask/base.py in compute(self, **kwargs)\r\n    286         dask.base.compute\r\n    287         \"\"\"\r\n--> 288         (result,) = compute(self, traverse=False, **kwargs)\r\n    289         return result\r\n    290 \r\n\r\n/miniconda3/envs/rapids-21.12/lib/python3.8/site-packages/dask/base.py in compute(*args, **kwargs)\r\n    568         postcomputes.append(x.__dask_postcompute__())\r\n    569 \r\n--> 570     results = schedule(dsk, keys, **kwargs)\r\n    571     return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\r\n    572 \r\n\r\n/miniconda3/envs/rapids-21.12/lib/python3.8/site-packages/dask/threaded.py in get(dsk, result, cache, num_workers, pool, **kwargs)\r\n     77             pool = MultiprocessingPoolExecutor(pool)\r\n     78 \r\n---> 79     results = get_async(\r\n     80         pool.submit,\r\n     81         pool._max_workers,\r\n\r\n/miniconda3/envs/rapids-21.12/lib/python3.8/site-packages/dask/local.py in get_async(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\r\n    515                             _execute_task(task, data)  # Re-execute locally\r\n    516                         else:\r\n--> 517                             raise_exception(exc, tb)\r\n    518                     res, worker_id = loads(res_info)\r\n    519                     state[\"cache\"][key] = res\r\n\r\n/miniconda3/envs/rapids-21.12/lib/python3.8/site-packages/dask/local.py in reraise(exc, tb)\r\n    323     if exc.__traceback__ is not tb:\r\n    324         raise exc.with_traceback(tb)\r\n--> 325     raise exc\r\n    326 \r\n    327 \r\n\r\n/miniconda3/envs/rapids-21.12/lib/python3.8/site-packages/dask/local.py in execute_task(key, task_info, dumps, loads, get_id, pack_exception)\r\n    221     try:\r\n    222         task, data = loads(task_info)\r\n--> 223         result = _execute_task(task, data)\r\n    224         id = get_id()\r\n    225         result = dumps((result, id))\r\n\r\n/miniconda3/envs/rapids-21.12/lib/python3.8/site-packages/dask/core.py in _execute_task(arg, cache, dsk)\r\n    119         # temporaries by their reference count and can execute certain\r\n    120         # operations in-place.\r\n--> 121         return func(*(_execute_task(a, cache) for a in args))\r\n    122     elif not ishashable(arg):\r\n    123         return arg\r\n\r\n/miniconda3/envs/rapids-21.12/lib/python3.8/site-packages/dask/dataframe/core.py in hash_shard(df, nparts, split_out_setup, split_out_setup_kwargs, ignore_index)\r\n   5492 ):\r\n   5493     if split_out_setup:\r\n-> 5494         h = split_out_setup(df, **(split_out_setup_kwargs or {}))\r\n   5495     else:\r\n   5496         h = df\r\n\r\n/miniconda3/envs/rapids-21.12/lib/python3.8/site-packages/dask/dataframe/core.py in split_out_on_index(df)\r\n   5512     h = df.index\r\n   5513     if isinstance(h, pd.MultiIndex):\r\n-> 5514         h = pd.DataFrame([], index=h).reset_index()\r\n   5515     return h\r\n   5516 \r\n\r\n/miniconda3/envs/rapids-21.12/lib/python3.8/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs)\r\n    309                     stacklevel=stacklevel,\r\n    310                 )\r\n--> 311             return func(*args, **kwargs)\r\n    312 \r\n    313         return wrapper\r\n\r\n/miniconda3/envs/rapids-21.12/lib/python3.8/site-packages/pandas/core/frame.py in reset_index(self, level, drop, inplace, col_level, col_fill)\r\n   5797                     )\r\n   5798 \r\n-> 5799                 new_obj.insert(0, name, level_values)\r\n   5800 \r\n   5801         new_obj.index = new_index\r\n\r\n/miniconda3/envs/rapids-21.12/lib/python3.8/site-packages/pandas/core/frame.py in insert(self, loc, column, value, allow_duplicates)\r\n   4412         if not allow_duplicates and column in self.columns:\r\n   4413             # Should this be a different kind of error??\r\n-> 4414             raise ValueError(f\"cannot insert {column}, already exists\")\r\n   4415         if not isinstance(loc, int):\r\n   4416             raise TypeError(\"loc must be int\")\r\n\r\nValueError: cannot insert key, already exists\r\n\r\n</details>\r\n\r\n\r\n**Anything else we need to know?**: N/A\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2021.9.1\r\n- Python version: 3.8\r\n- Operating System: ubuntu 18.04\r\n- Install method (conda, pip, source): conda\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/8307/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/8307/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}