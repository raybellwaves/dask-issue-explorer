{
    "url": "https://api.github.com/repos/dask/dask/issues/6705",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/6705/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/6705/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/6705/events",
    "html_url": "https://github.com/dask/dask/issues/6705",
    "id": 715081263,
    "node_id": "MDU6SXNzdWU3MTUwODEyNjM=",
    "number": 6705,
    "title": "Nested parallel processes: how to handle them?",
    "user": {
        "login": "gioxc88",
        "id": 41852601,
        "node_id": "MDQ6VXNlcjQxODUyNjAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/41852601?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/gioxc88",
        "html_url": "https://github.com/gioxc88",
        "followers_url": "https://api.github.com/users/gioxc88/followers",
        "following_url": "https://api.github.com/users/gioxc88/following{/other_user}",
        "gists_url": "https://api.github.com/users/gioxc88/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/gioxc88/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/gioxc88/subscriptions",
        "organizations_url": "https://api.github.com/users/gioxc88/orgs",
        "repos_url": "https://api.github.com/users/gioxc88/repos",
        "events_url": "https://api.github.com/users/gioxc88/events{/privacy}",
        "received_events_url": "https://api.github.com/users/gioxc88/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 15,
    "created_at": "2020-10-05T18:54:30Z",
    "updated_at": "2020-12-16T19:43:54Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "I couldn't find any satisfactory question (and answer) either in the opened issues or on stackoverflow, so I thought I might as well open an issue myself.\r\n\r\nI'll illustrate the problem with my use-case (which is oversimplified below).\r\n\r\n1. My dataset contains 30 observations which I divide in 3 subsamples of 10 observation each.\r\n(the real dataset is much bigger and the number of subsamples is much higher)\r\n\r\n```\r\n>>> print(len(X))\r\n>>> 30\r\n\r\n     subsample1            subsample2            subsample3 \r\nx x x x x x x x x x | x x x x x x x x x x | x x x x x x x x x x | \r\n0 1 2 3 4 5 6 7 8 9 | 0 1 2 3 4 5 6 7 8 9 | 0 1 2 3 4 5 6 7 8 9 | \r\n\r\n```\r\n\r\n2. For each subsample I train a model which needs to be tuned via cross-validation, for example using `GridSearchCV` or `HyperbandSearchCV`. \r\nSay that I want to validate the `l1` penalty of a `Lasso` regressor using a grid of 50 points, such that I train 50 models for every subsample.\r\n\r\n```\r\nfrom dask import compute, delayed\r\nfrom dask_ml.model_selection import GridSearchCV\r\nfrom sklearn.linear_model import Lasso\r\n\r\nreg = Lasso()\r\nparam_space = np.logspace(1, -9, num=50)\r\nparam_grid ={'alpha': param_space}\r\nmodel = GridSearchCV(reg)\r\n```\r\n\r\nIn this case the schema would look something like:\r\n\r\n```          \r\n              | model0\r\n              | model1\r\nsubsample1 -> | ...\r\n              | model49\r\n------------------------\r\n              | model0\r\n              | model1\r\nsubsample2 -> | ...\r\n              | model49\r\n------------------------\r\n              | model0\r\n              | model1\r\nsubsample3 -> | ...\r\n              | model49\r\n```\r\n\r\n\r\nAs I said, in the real world application I have more than 100 subsamples on which I cross validate the model by training 50 different hyperparameter combinations for each subsample.\r\n\r\nI could easily write a code like this:\r\n\r\n```\r\nfrom dask import compute, delayed\r\nfrom . import load_data, get_subsample\r\n\r\nX, y = load_dada()  # load_data is an imaginary function for loading the data\r\nn_subsamples = 100\r\n\r\nresults = []\r\nfor subsample in range(n_subsamples):\r\n    X_train, y_train = get_subsample(X, y, subsample)  # get_subsample is an imaginary function which slices X and y\r\n    results.append(delayed(model.fit)(X_train, y_train))\r\nresults = compute(*results)\r\n```\r\n\r\nTo summarize:\r\n1. Since I parallelized computations across subsamples `dask` is spawning one process for each subsample. \r\n2. Since within each subsample I use `GridSearchCV`, which also makes use of multiprocessing, this will also try to spawn processes within the process.\r\n\r\nIn this case we could talk about nested processes.\r\nMy questions are:\r\n1. How does dask handle this? If it doesn't handle it already, should it be able to?\r\n2. Is this a bad design and does not have anything to do with dask in the first place?\r\n\r\nMany thanks\r\n\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/6705/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/6705/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}