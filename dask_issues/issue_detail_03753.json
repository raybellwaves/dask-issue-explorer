{
    "url": "https://api.github.com/repos/dask/dask/issues/3753",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/3753/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/3753/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/3753/events",
    "html_url": "https://github.com/dask/dask/issues/3753",
    "id": 341134066,
    "node_id": "MDU6SXNzdWUzNDExMzQwNjY=",
    "number": 3753,
    "title": "Custom aggregate functions removing index labels on output",
    "user": {
        "login": "cjalmeida",
        "id": 704920,
        "node_id": "MDQ6VXNlcjcwNDkyMA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/704920?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/cjalmeida",
        "html_url": "https://github.com/cjalmeida",
        "followers_url": "https://api.github.com/users/cjalmeida/followers",
        "following_url": "https://api.github.com/users/cjalmeida/following{/other_user}",
        "gists_url": "https://api.github.com/users/cjalmeida/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/cjalmeida/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/cjalmeida/subscriptions",
        "organizations_url": "https://api.github.com/users/cjalmeida/orgs",
        "repos_url": "https://api.github.com/users/cjalmeida/repos",
        "events_url": "https://api.github.com/users/cjalmeida/events{/privacy}",
        "received_events_url": "https://api.github.com/users/cjalmeida/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2018-07-13T19:28:34Z",
    "updated_at": "2019-04-30T19:07:51Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "active_lock_reason": null,
    "body": "Minimal example, based on \r\n\r\nhttps://stackoverflow.com/questions/46080171/constructing-mode-and-corresponding-count-functions-using-custom-aggregation-fun/46082075#46082075\r\n\r\n```python\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\n\r\n\r\ndef chunk(s):\r\n    return s.value_counts()\r\n\r\n\r\ndef agg(s):\r\n    return s.apply(lambda s: s.groupby(level=-1).sum())\r\n\r\n\r\ndef finalize(s):\r\n    level = list(range(s.index.nlevels - 1))\r\n    return (\r\n        s.groupby(level=level)\r\n            .apply(lambda s: s.reset_index(level=level, drop=True).idxmax()))\r\n\r\nmode = dd.Aggregation('mode', chunk, agg, finalize)\r\n\r\ndf = pd.DataFrame({\r\n    'col0': [0, 1, 1, 2, 3] * 10,\r\n    'col1': [4, 5, 5, 6, 7] * 10,\r\n    'g0': [0, 0, 0, 1, 1] * 10,\r\n    'g1': [0, 0, 0, 1, 1] * 10,\r\n})\r\nddf = dd.from_pandas(df, npartitions=3)\r\nres = ddf.groupby(['g0', 'g1']).agg({'col0':mode, 'col1':mode})\r\nres.compute()\r\n```\r\nThe output is\r\n```\r\n\t\tcol0\tcol1\r\n0\t0\t1\t5\r\n1\t1\t2\t6\r\n```\r\nMind the missing index labels. Due to the missing labels, if you change the last line to\r\n\r\n```python\r\nres.reset_index().compute()\r\n```\r\n\r\nYou'll get the following stack trace:\r\n\r\n```python-traceback\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-10-ffe69b3913d9> in <module>()\r\n     29 ddf = dd.from_pandas(df, npartitions=3)\r\n     30 res = ddf.groupby(['g0', 'g1']).agg({'col0':mode, 'col1':mode})\r\n---> 31 res.reset_index().compute()\r\n\r\n~/store_markdown/venv/lib/python3.6/site-packages/dask/base.py in compute(self, **kwargs)\r\n    154         dask.base.compute\r\n    155         \"\"\"\r\n--> 156         (result,) = compute(self, traverse=False, **kwargs)\r\n    157         return result\r\n    158 \r\n\r\n~/store_markdown/venv/lib/python3.6/site-packages/dask/base.py in compute(*args, **kwargs)\r\n    400     keys = [x.__dask_keys__() for x in collections]\r\n    401     postcomputes = [x.__dask_postcompute__() for x in collections]\r\n--> 402     results = schedule(dsk, keys, **kwargs)\r\n    403     return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\r\n    404 \r\n\r\n~/store_markdown/venv/lib/python3.6/site-packages/dask/threaded.py in get(dsk, result, cache, num_workers, **kwargs)\r\n     73     results = get_async(pool.apply_async, len(pool._pool), dsk, result,\r\n     74                         cache=cache, get_id=_thread_get_id,\r\n---> 75                         pack_exception=pack_exception, **kwargs)\r\n     76 \r\n     77     # Cleanup pools associated to dead threads\r\n\r\n~/store_markdown/venv/lib/python3.6/site-packages/dask/local.py in get_async(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\r\n    519                         _execute_task(task, data)  # Re-execute locally\r\n    520                     else:\r\n--> 521                         raise_exception(exc, tb)\r\n    522                 res, worker_id = loads(res_info)\r\n    523                 state['cache'][key] = res\r\n\r\n~/store_markdown/venv/lib/python3.6/site-packages/dask/compatibility.py in reraise(exc, tb)\r\n     67         if exc.__traceback__ is not tb:\r\n     68             raise exc.with_traceback(tb)\r\n---> 69         raise exc\r\n     70 \r\n     71 else:\r\n\r\n~/store_markdown/venv/lib/python3.6/site-packages/dask/local.py in execute_task(key, task_info, dumps, loads, get_id, pack_exception)\r\n    288     try:\r\n    289         task, data = loads(task_info)\r\n--> 290         result = _execute_task(task, data)\r\n    291         id = get_id()\r\n    292         result = dumps((result, id))\r\n\r\n~/store_markdown/venv/lib/python3.6/site-packages/dask/local.py in _execute_task(arg, cache, dsk)\r\n    269         func, args = arg[0], arg[1:]\r\n    270         args2 = [_execute_task(a, cache) for a in args]\r\n--> 271         return func(*args2)\r\n    272     elif not ishashable(arg):\r\n    273         return arg\r\n\r\n~/store_markdown/venv/lib/python3.6/site-packages/dask/dataframe/core.py in apply_and_enforce(func, args, kwargs, meta)\r\n   3561             if not np.array_equal(np.nan_to_num(meta.columns),\r\n   3562                                   np.nan_to_num(df.columns)):\r\n-> 3563                 raise ValueError(\"The columns in the computed data do not match\"\r\n   3564                                  \" the columns in the provided metadata\")\r\n   3565             else:\r\n\r\nValueError: The columns in the computed data do not match the columns in the provided metadata\r\n```",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/3753/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/3753/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}