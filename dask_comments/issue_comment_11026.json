[
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/2025485224",
        "html_url": "https://github.com/dask/dask/issues/11026#issuecomment-2025485224",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/11026",
        "id": 2025485224,
        "node_id": "IC_kwDOAbcwm854unOo",
        "user": {
            "login": "fjetter",
            "id": 8629629,
            "node_id": "MDQ6VXNlcjg2Mjk2Mjk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8629629?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fjetter",
            "html_url": "https://github.com/fjetter",
            "followers_url": "https://api.github.com/users/fjetter/followers",
            "following_url": "https://api.github.com/users/fjetter/following{/other_user}",
            "gists_url": "https://api.github.com/users/fjetter/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fjetter/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fjetter/subscriptions",
            "organizations_url": "https://api.github.com/users/fjetter/orgs",
            "repos_url": "https://api.github.com/users/fjetter/repos",
            "events_url": "https://api.github.com/users/fjetter/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fjetter/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-03-28T15:21:23Z",
        "updated_at": "2024-03-28T15:21:23Z",
        "author_association": "MEMBER",
        "body": "I only very briefly looked into this so far but it looks like the very first groupby tasks generate very large partitions, pretty much regardless of how the initial input partitions look like\r\n\r\n<img width=\"613\" alt=\"image\" src=\"https://github.com/dask/dask/assets/8629629/4d35a820-d2f4-42ce-98ef-0896ecbfd520\">\r\n\r\nI get many, many of those 600MiB chunks and this is clogging the cluster. From what I can tell, scheduling is working as intended. The reason why this isn't moving along is because some of those chunks end up on different workers and have to be moved around using network, i.e. the final reducer tasks are delayed since the workers have to fetch that data. While that is being fetched, the worker is attempting to run other tasks.\r\n\r\nI'm a little surprised to see these large intermediate results on a map-reduce workflow but I don't have sufficient knowledge about flox to judge this properly.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/2025485224/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/2025492116",
        "html_url": "https://github.com/dask/dask/issues/11026#issuecomment-2025492116",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/11026",
        "id": 2025492116,
        "node_id": "IC_kwDOAbcwm854uo6U",
        "user": {
            "login": "dcherian",
            "id": 2448579,
            "node_id": "MDQ6VXNlcjI0NDg1Nzk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2448579?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dcherian",
            "html_url": "https://github.com/dcherian",
            "followers_url": "https://api.github.com/users/dcherian/followers",
            "following_url": "https://api.github.com/users/dcherian/following{/other_user}",
            "gists_url": "https://api.github.com/users/dcherian/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dcherian/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dcherian/subscriptions",
            "organizations_url": "https://api.github.com/users/dcherian/orgs",
            "repos_url": "https://api.github.com/users/dcherian/repos",
            "events_url": "https://api.github.com/users/dcherian/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dcherian/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-03-28T15:24:20Z",
        "updated_at": "2024-03-28T15:25:03Z",
        "author_association": "MEMBER",
        "body": "The input chunk sizes are large here, so that's fixable in theory. I did notice that no root tasks were identified in the dashboard. @ivirshup's comment suggest that this is happening with Zarr inputs as well, not just `random`. Do you see this too?\r\n\r\nEDIT: Those `chunk` tasks are `blockwise` reduction tasks fused with the `random` data generation task.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/2025492116/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/2026122276",
        "html_url": "https://github.com/dask/dask/issues/11026#issuecomment-2026122276",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/11026",
        "id": 2026122276,
        "node_id": "IC_kwDOAbcwm854xCwk",
        "user": {
            "login": "ivirshup",
            "id": 8238804,
            "node_id": "MDQ6VXNlcjgyMzg4MDQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8238804?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ivirshup",
            "html_url": "https://github.com/ivirshup",
            "followers_url": "https://api.github.com/users/ivirshup/followers",
            "following_url": "https://api.github.com/users/ivirshup/following{/other_user}",
            "gists_url": "https://api.github.com/users/ivirshup/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ivirshup/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ivirshup/subscriptions",
            "organizations_url": "https://api.github.com/users/ivirshup/orgs",
            "repos_url": "https://api.github.com/users/ivirshup/repos",
            "events_url": "https://api.github.com/users/ivirshup/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ivirshup/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-03-28T21:06:32Z",
        "updated_at": "2024-03-28T21:06:32Z",
        "author_association": "NONE",
        "body": "@dcherian, adding an intermediate (computed) zarr store like this:\r\n\r\n```python\r\nM, N = 500_000, 20_000\r\nN_CATEGORIES = 2_000\r\nSCRATCH = Path(\"/scratch/tmp\")\r\nX_pth = SCRATCH / \"X.zarr\"\r\n\r\nX_orig = da.random.normal(size=(M, N), chunks=(5_000, N))\r\n\r\nX_orig.to_zarr(X_pth, overwrite=True, compute=True)\r\nX = da.from_zarr(X_pth)\r\nby = np.random.choice(N_CATEGORIES, size=M)\r\n```\r\n\r\nHas the same behaviour for me.\r\n\r\n----\r\n\r\n@fjetter, what is that task representation?\r\n\r\nI'm not familiar enough with dask to know what my expectations should be of the high level graph representations, but some stuff there does seem a little off.\r\n\r\n<img width=\"856\" alt=\"image\" src=\"https://github.com/dask/dask/assets/8238804/792bb341-508d-447b-8a5b-48c663b6db70\">\r\n\r\nMy expectation would be that each groupby-sum chunk would be `(N, N_CATEGORIES)` with a total shape of `(N, N_CATEGORIES * len(X.chunks[1])`. Each partial aggregation layer after that reports chunk sizes to be `(20000, 1)` which also seems wrong. Not sure if this is related though.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/2026122276/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/2026282584",
        "html_url": "https://github.com/dask/dask/issues/11026#issuecomment-2026282584",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/11026",
        "id": 2026282584,
        "node_id": "IC_kwDOAbcwm854xp5Y",
        "user": {
            "login": "dcherian",
            "id": 2448579,
            "node_id": "MDQ6VXNlcjI0NDg1Nzk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2448579?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dcherian",
            "html_url": "https://github.com/dcherian",
            "followers_url": "https://api.github.com/users/dcherian/followers",
            "following_url": "https://api.github.com/users/dcherian/following{/other_user}",
            "gists_url": "https://api.github.com/users/dcherian/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dcherian/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dcherian/subscriptions",
            "organizations_url": "https://api.github.com/users/dcherian/orgs",
            "repos_url": "https://api.github.com/users/dcherian/repos",
            "events_url": "https://api.github.com/users/dcherian/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dcherian/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-03-28T23:01:03Z",
        "updated_at": "2024-03-28T23:06:03Z",
        "author_association": "MEMBER",
        "body": "> Each partial aggregation layer after that reports chunk sizes to be (20000, 1) which also seems wrong.\r\n\r\nYes this is (intentionally) wrong. \r\n\r\nNumber of outputs is more indicative of the reduction tree. You start with 200 chunks -> 50 -> 13 -> 4 -> 1 (The default \"split-size\" for the tree reduction is 4, so at each stage 4 outputs get combined to 1).\r\n\r\nI think Florian's image is a result of large initial chunk sizes. It's certaily matches the input chunk size.\r\n\r\n<img width=\"569\" alt=\"image\" src=\"https://github.com/dask/dask/assets/2448579/15f81c9a-fb46-40dd-ae5c-c188c1251481\">\r\n\r\nI'll also note that number of categories ~ chunksize of input along the reduction dimension, so the blockwise reduction isn't too effective at reducing memory. It is doing a factor of 2 reduction in your latest example (5000->2000). \r\n\r\nNote: You could try passing `reindex=False`, this would control memory at the expense of slower stages during the tree reduction. But make sure to do this for your actual data, it shouldn't show too much difference (on average) with purely random groups, but will definitely be slower.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/2026282584/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/2027442846",
        "html_url": "https://github.com/dask/dask/issues/11026#issuecomment-2027442846",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/11026",
        "id": 2027442846,
        "node_id": "IC_kwDOAbcwm8542FKe",
        "user": {
            "login": "ivirshup",
            "id": 8238804,
            "node_id": "MDQ6VXNlcjgyMzg4MDQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8238804?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ivirshup",
            "html_url": "https://github.com/ivirshup",
            "followers_url": "https://api.github.com/users/ivirshup/followers",
            "following_url": "https://api.github.com/users/ivirshup/following{/other_user}",
            "gists_url": "https://api.github.com/users/ivirshup/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ivirshup/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ivirshup/subscriptions",
            "organizations_url": "https://api.github.com/users/ivirshup/orgs",
            "repos_url": "https://api.github.com/users/ivirshup/repos",
            "events_url": "https://api.github.com/users/ivirshup/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ivirshup/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-03-29T16:19:23Z",
        "updated_at": "2024-03-29T17:08:29Z",
        "author_association": "NONE",
        "body": "> Number of outputs is more indicative of the reduction tree. You start with 200 chunks -> 50 -> 13 -> 4 -> 1 (The default \"split-size\" for the tree reduction is 4, so at each stage 4 outputs get combined to 1).\r\n\r\nThat makes sense, but I guess I would have expected to have arrays that look like: \r\n\r\n* `shape=(N_FEATURES, N_CATEGORIES, N_REDUCTIONS), chunks=(FEATURE_CHUNKS, N_CATEGORIES, 1)`\r\n\r\nInstead of:\r\n\r\n* `shape=(N_FEATURES, N_REDUCTIONS), chunks=(FEATURE_CHUNKS, 1)`\r\n\r\nWhy does the `groupby_sum-chunk` task output an array the same size as the input?\r\n\r\n----\r\n\r\nFWIW, I tried this with the threading scheduler and it seemed to work great with no memory issues. So definitely speeks to high cost of transfer.\r\n\r\n-----\r\n\r\nI was under the impression that the scheduler would try to reduce the number of data transfers necessary. Is this explicitly done, or is this just expected to happen due to last-in-first-out task distribution? ",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/2027442846/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/2027500770",
        "html_url": "https://github.com/dask/dask/issues/11026#issuecomment-2027500770",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/11026",
        "id": 2027500770,
        "node_id": "IC_kwDOAbcwm8542TTi",
        "user": {
            "login": "dcherian",
            "id": 2448579,
            "node_id": "MDQ6VXNlcjI0NDg1Nzk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2448579?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dcherian",
            "html_url": "https://github.com/dcherian",
            "followers_url": "https://api.github.com/users/dcherian/followers",
            "following_url": "https://api.github.com/users/dcherian/following{/other_user}",
            "gists_url": "https://api.github.com/users/dcherian/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dcherian/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dcherian/subscriptions",
            "organizations_url": "https://api.github.com/users/dcherian/orgs",
            "repos_url": "https://api.github.com/users/dcherian/repos",
            "events_url": "https://api.github.com/users/dcherian/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dcherian/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-03-29T17:06:03Z",
        "updated_at": "2024-03-29T17:06:03Z",
        "author_association": "MEMBER",
        "body": "> Why does the groupby_sum-chunk task output an array the same size as the input?\r\n\r\nThis is interesting, I don't actually update the sizes. \r\n\r\n@fjetter would the scheduling algorithm work better if the size/shapes were more accurate at the blockwise step?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/2027500770/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/2027587408",
        "html_url": "https://github.com/dask/dask/issues/11026#issuecomment-2027587408",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/11026",
        "id": 2027587408,
        "node_id": "IC_kwDOAbcwm8542odQ",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-03-29T18:36:41Z",
        "updated_at": "2024-03-29T18:36:41Z",
        "author_association": "MEMBER",
        "body": "As a heads-up, Florian is travelling today and may not be very responsive.\r\n\r\nOn Fri, Mar 29, 2024 at 12:06\u202fPM Deepak Cherian ***@***.***>\r\nwrote:\r\n\r\n> Why does the groupby_sum-chunk task output an array the same size as the\r\n> input?\r\n>\r\n> This is interesting, I don't actually update the sizes.\r\n>\r\n> @fjetter <https://github.com/fjetter> would the scheduling algorithm work\r\n> better if the size/shapes were more accurate at the blockwise step?\r\n>\r\n> \u2014\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/dask/dask/issues/11026#issuecomment-2027500770>, or\r\n> unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AACKZTF5N6XZKBT2D24AE2DY2WNRFAVCNFSM6AAAAABFJUPHQCVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDAMRXGUYDANZXGA>\r\n> .\r\n> You are receiving this because you are subscribed to this thread.Message\r\n> ID: ***@***.***>\r\n>\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/2027587408/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/2150568201",
        "html_url": "https://github.com/dask/dask/issues/11026#issuecomment-2150568201",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/11026",
        "id": 2150568201,
        "node_id": "IC_kwDOAbcwm86ALxEJ",
        "user": {
            "login": "ivirshup",
            "id": 8238804,
            "node_id": "MDQ6VXNlcjgyMzg4MDQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8238804?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ivirshup",
            "html_url": "https://github.com/ivirshup",
            "followers_url": "https://api.github.com/users/ivirshup/followers",
            "following_url": "https://api.github.com/users/ivirshup/following{/other_user}",
            "gists_url": "https://api.github.com/users/ivirshup/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ivirshup/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ivirshup/subscriptions",
            "organizations_url": "https://api.github.com/users/ivirshup/orgs",
            "repos_url": "https://api.github.com/users/ivirshup/repos",
            "events_url": "https://api.github.com/users/ivirshup/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ivirshup/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-06-05T17:15:50Z",
        "updated_at": "2024-06-05T17:15:50Z",
        "author_association": "NONE",
        "body": "@fjetter, did you ever get a chance to look at this? I'm starting to look into it again and would appreciate any guidance!",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/2150568201/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/2150758126",
        "html_url": "https://github.com/dask/dask/issues/11026#issuecomment-2150758126",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/11026",
        "id": 2150758126,
        "node_id": "IC_kwDOAbcwm86AMfbu",
        "user": {
            "login": "dcherian",
            "id": 2448579,
            "node_id": "MDQ6VXNlcjI0NDg1Nzk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2448579?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dcherian",
            "html_url": "https://github.com/dcherian",
            "followers_url": "https://api.github.com/users/dcherian/followers",
            "following_url": "https://api.github.com/users/dcherian/following{/other_user}",
            "gists_url": "https://api.github.com/users/dcherian/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dcherian/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dcherian/subscriptions",
            "organizations_url": "https://api.github.com/users/dcherian/orgs",
            "repos_url": "https://api.github.com/users/dcherian/repos",
            "events_url": "https://api.github.com/users/dcherian/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dcherian/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-06-05T19:01:49Z",
        "updated_at": "2024-06-05T19:01:49Z",
        "author_association": "MEMBER",
        "body": "Is there a real dataset, preferably on public cloud, that we can use as an example?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/2150758126/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/2150901649",
        "html_url": "https://github.com/dask/dask/issues/11026#issuecomment-2150901649",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/11026",
        "id": 2150901649,
        "node_id": "IC_kwDOAbcwm86ANCeR",
        "user": {
            "login": "ivirshup",
            "id": 8238804,
            "node_id": "MDQ6VXNlcjgyMzg4MDQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8238804?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ivirshup",
            "html_url": "https://github.com/ivirshup",
            "followers_url": "https://api.github.com/users/ivirshup/followers",
            "following_url": "https://api.github.com/users/ivirshup/following{/other_user}",
            "gists_url": "https://api.github.com/users/ivirshup/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ivirshup/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ivirshup/subscriptions",
            "organizations_url": "https://api.github.com/users/ivirshup/orgs",
            "repos_url": "https://api.github.com/users/ivirshup/repos",
            "events_url": "https://api.github.com/users/ivirshup/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ivirshup/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-06-05T20:22:42Z",
        "updated_at": "2024-06-05T20:22:42Z",
        "author_association": "NONE",
        "body": "It would require a little bit of manipulation. Most of the \"real data\" cases easily available I can think go off the top of my head are in a sparse format in either hdf5 or tiledb. I could share a link with some code to construct the Dask arrays?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/2150901649/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/2150908396",
        "html_url": "https://github.com/dask/dask/issues/11026#issuecomment-2150908396",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/11026",
        "id": 2150908396,
        "node_id": "IC_kwDOAbcwm86ANEHs",
        "user": {
            "login": "dcherian",
            "id": 2448579,
            "node_id": "MDQ6VXNlcjI0NDg1Nzk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2448579?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dcherian",
            "html_url": "https://github.com/dcherian",
            "followers_url": "https://api.github.com/users/dcherian/followers",
            "following_url": "https://api.github.com/users/dcherian/following{/other_user}",
            "gists_url": "https://api.github.com/users/dcherian/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dcherian/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dcherian/subscriptions",
            "organizations_url": "https://api.github.com/users/dcherian/orgs",
            "repos_url": "https://api.github.com/users/dcherian/repos",
            "events_url": "https://api.github.com/users/dcherian/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dcherian/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-06-05T20:27:22Z",
        "updated_at": "2024-06-05T20:27:22Z",
        "author_association": "MEMBER",
        "body": "> I could share a link with some code to construct the Dask arrays?\r\n\r\nI think that would help.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/2150908396/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/2151141540",
        "html_url": "https://github.com/dask/dask/issues/11026#issuecomment-2151141540",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/11026",
        "id": 2151141540,
        "node_id": "IC_kwDOAbcwm86AN9Ck",
        "user": {
            "login": "ivirshup",
            "id": 8238804,
            "node_id": "MDQ6VXNlcjgyMzg4MDQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8238804?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ivirshup",
            "html_url": "https://github.com/ivirshup",
            "followers_url": "https://api.github.com/users/ivirshup/followers",
            "following_url": "https://api.github.com/users/ivirshup/following{/other_user}",
            "gists_url": "https://api.github.com/users/ivirshup/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ivirshup/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ivirshup/subscriptions",
            "organizations_url": "https://api.github.com/users/ivirshup/orgs",
            "repos_url": "https://api.github.com/users/ivirshup/repos",
            "events_url": "https://api.github.com/users/ivirshup/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ivirshup/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-06-05T23:58:08Z",
        "updated_at": "2024-06-05T23:58:08Z",
        "author_association": "NONE",
        "body": "Here is a gist with examples using both hdf5 and tiledb: https://gist.github.com/ivirshup/eb4f5beb1bb33724b8c11bd0eacf03a6\r\n\r\nI was able to get a little further today, and was able to get a few use-cases to actually run, but I am on a larger machine than I was using previously.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/2151141540/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/2152756418",
        "html_url": "https://github.com/dask/dask/issues/11026#issuecomment-2152756418",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/11026",
        "id": 2152756418,
        "node_id": "IC_kwDOAbcwm86AUHTC",
        "user": {
            "login": "dcherian",
            "id": 2448579,
            "node_id": "MDQ6VXNlcjI0NDg1Nzk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2448579?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dcherian",
            "html_url": "https://github.com/dcherian",
            "followers_url": "https://api.github.com/users/dcherian/followers",
            "following_url": "https://api.github.com/users/dcherian/following{/other_user}",
            "gists_url": "https://api.github.com/users/dcherian/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dcherian/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dcherian/subscriptions",
            "organizations_url": "https://api.github.com/users/dcherian/orgs",
            "repos_url": "https://api.github.com/users/dcherian/repos",
            "events_url": "https://api.github.com/users/dcherian/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dcherian/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-06-06T14:59:24Z",
        "updated_at": "2024-06-06T15:36:19Z",
        "author_association": "MEMBER",
        "body": "**TLDR** This isn't a dask problem. The core \"array\"/read tasks are treated as root-ish.\r\n\r\n-----\r\n\r\nThis works on my laptop with 32GB RAM with some spilling\r\n\r\n```python\r\nres, codes = flox.groupby_reduce(\r\n    X_dense.T,\r\n    by,\r\n    func=\"sum\",\r\n    fill_value=0,\r\n)\r\n```\r\n\r\nEDIT: I've moved discussion to https://github.com/xarray-contrib/flox/issues/346\r\n\r\nEDIT3: Memory issues can be controlled by using `numbagg` and `nansum`. It's also 5X faster (approx). I guess we should look in to how to make `flox` just handle sparse matrices directly.\r\n\r\n```python\r\nres, codes = flox.groupby_reduce(\r\n    X_dense.T,\r\n    by,\r\n    func=\"nansum\",\r\n    fill_value=0,\r\n    engine=\"numbagg\",\r\n)\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/2152756418/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]