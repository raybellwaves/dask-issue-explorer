{
    "url": "https://api.github.com/repos/dask/dask/issues/3714",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/3714/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/3714/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/3714/events",
    "html_url": "https://github.com/dask/dask/issues/3714",
    "id": 338153379,
    "node_id": "MDU6SXNzdWUzMzgxNTMzNzk=",
    "number": 3714,
    "title": "repartition dask  dataframe according to frequency doesn't match pandas known frequencies",
    "user": {
        "login": "finete",
        "id": 34818222,
        "node_id": "MDQ6VXNlcjM0ODE4MjIy",
        "avatar_url": "https://avatars.githubusercontent.com/u/34818222?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/finete",
        "html_url": "https://github.com/finete",
        "followers_url": "https://api.github.com/users/finete/followers",
        "following_url": "https://api.github.com/users/finete/following{/other_user}",
        "gists_url": "https://api.github.com/users/finete/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/finete/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/finete/subscriptions",
        "organizations_url": "https://api.github.com/users/finete/orgs",
        "repos_url": "https://api.github.com/users/finete/repos",
        "events_url": "https://api.github.com/users/finete/events{/privacy}",
        "received_events_url": "https://api.github.com/users/finete/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2018-07-04T07:04:56Z",
    "updated_at": "2019-04-30T16:13:00Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "When repartitioning a dask  dataframe with a date index according to a certain frequency it does not match the partition made with a pandas Grouper object.\r\n\r\nexample: \r\n```python\r\nimport pandas as pd\r\nnums= [f'{i:02},' for i in range(9)]\r\ndates = pd.date_range('2018-07-01', periods=9, freq='1d')\r\ndf = pd.DataFrame({'dates':dates, 'nums': nums}).set_index('dates')\r\n```\r\nwhen grouping it with a weekly frequency until thursday:\r\n```python\r\ngrouper = pd.Grouper(level='dates', freq='W-THU')\r\ndf.groupby(grouper).agg({'nums':'sum'})\r\n```\r\nyou get the following result\r\n<details>\r\n\r\n\r\n|            | nums                  |\r\n|------------|-----------------------|\r\n| dates      |                       |\r\n| 2018-07-05 | 00,01,02,03,04,       |\r\n| 2018-07-12 | 05,06,07,08, |\r\n\r\n</details>\r\n\r\n\r\n\r\nhowever when you repartition a dask dataframe according to the same frequency\r\nand print them you get different partitions. \r\n```python\r\nimport dask.dataframe as dd\r\nddf = dd.from_pandas(df, npartitions=1).repartition(freq='W-THU')\r\n\r\nfor i in range(ddf.npartitions):\r\n    print(ddf.get_partition(i).compute())\r\n```\r\n<details>\r\n\r\n|            | nums |\r\n|------------|------|\r\n| dates      |      |\r\n| 2018-07-01 | 00,  |\r\n| 2018-07-02 | 01,  |\r\n| 2018-07-03 | 02,  |\r\n| 2018-07-04 | 03,  |\r\n\r\n|            | nums |\r\n|------------|------|\r\n| dates      |      |\r\n| 2018-07-05 | 04,  |\r\n| 2018-07-06 | 05,  |\r\n| 2018-07-07 | 06,  |\r\n| 2018-07-08 | 07,  |\r\n| 2018-07-09 | 08,  |\r\n\r\n</details>\r\nand thus resulting in faulty calculations if i do the following:\r\n\r\n```python \r\ngrouper = pd.Grouper(level='dates', freq='W-THU')\r\nddf.map_partitions(lambda df:df.groupby(grouper).agg({'nums':'sum'}), meta={'nums':str}).compute()\r\n``` \r\n<details>\r\n\r\n|            | nums         |\r\n|------------|--------------|\r\n| dates      |              |\r\n| 2018-07-05 | 00,01,02,03, |\r\n| 2018-07-05 | 04,          |\r\n| 2018-07-12 | 05,06,07,08, |\r\n\r\n</details>\r\nEDIT:\r\nPython 3.6.5 :: Anaconda, Inc.\r\ndask Version: 0.18.0\r\npandas Version: 0.23.0",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/3714/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/3714/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}