{
    "url": "https://api.github.com/repos/dask/dask/issues/10595",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/10595/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/10595/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/10595/events",
    "html_url": "https://github.com/dask/dask/issues/10595",
    "id": 1959752231,
    "node_id": "I_kwDOAbcwm850z3In",
    "number": 10595,
    "title": "`except Exception` in `compute_meta` makes custom functions and schedulers difficult",
    "user": {
        "login": "djhoese",
        "id": 1828519,
        "node_id": "MDQ6VXNlcjE4Mjg1MTk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1828519?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/djhoese",
        "html_url": "https://github.com/djhoese",
        "followers_url": "https://api.github.com/users/djhoese/followers",
        "following_url": "https://api.github.com/users/djhoese/following{/other_user}",
        "gists_url": "https://api.github.com/users/djhoese/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/djhoese/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/djhoese/subscriptions",
        "organizations_url": "https://api.github.com/users/djhoese/orgs",
        "repos_url": "https://api.github.com/users/djhoese/repos",
        "events_url": "https://api.github.com/users/djhoese/events{/privacy}",
        "received_events_url": "https://api.github.com/users/djhoese/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 3468123446,
            "node_id": "LA_kwDOAbcwm87Ot102",
            "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention",
            "name": "needs attention",
            "color": "6d626c",
            "default": false,
            "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."
        },
        {
            "id": 3880424463,
            "node_id": "LA_kwDOAbcwm87nSpQP",
            "url": "https://api.github.com/repos/dask/dask/labels/needs%20triage",
            "name": "needs triage",
            "color": "eeeeee",
            "default": false,
            "description": "Needs a response from a contributor"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-10-24T17:36:34Z",
    "updated_at": "2023-11-27T01:46:52Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "active_lock_reason": null,
    "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**Describe the issue**:\r\n\r\nThere is an `except Exception` block in `compute_meta` when running the function being called.\r\n\r\nhttps://github.com/dask/dask/blame/1203b1bb6d52b1fb00d54656af4af8e6e35aa615/dask/array/utils.py#L162-L163\r\n\r\nThe commit message for this change mentions avoiding numpy warnings, but those should already be ignored by the `errstate` at the top of the function.\r\n\r\nhttps://github.com/dask/dask/commit/aa5d4ac8eefa4cbcadd0ca112651d53b1403e0a8\r\n\r\nIn Satpy we use a `CustomScheduler` class in our testing and debugging to verify that we are not computing dask arrays until we expect to. We do this by raising a `RuntimeError` when the scheduler is told to compute more than N times. See:\r\n\r\nhttps://github.com/pytroll/satpy/blob/bc32c9434815365d180b1c6d38c00b2b6b4d5f7e/satpy/tests/utils.py#L275-L290\r\n\r\nHowever, it was recently discovered that this doesn't work if any of our functions require computing the meta array (ex. map_blocks, etc). Most recently it was when passing `xarray.DataArray`s to a `da.where` function by mistake (we're still not sure if this is a problem).\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport dask\r\nimport dask.array as da\r\nimport xarray as xr\r\n\r\nclass CustomScheduler(object):\r\n    \"\"\"Scheduler raising an exception if data are computed too many times.\"\"\"\r\n\r\n    def __init__(self, max_computes=1):\r\n        \"\"\"Set starting and maximum compute counts.\"\"\"\r\n        self.max_computes = max_computes\r\n        self.total_computes = 0\r\n\r\n    def __call__(self, dsk, keys, **kwargs):\r\n        \"\"\"Compute dask task and keep track of number of times we do so.\"\"\"\r\n        import dask\r\n        self.total_computes += 1\r\n        if self.total_computes > self.max_computes:\r\n            raise RuntimeError(\"Too many dask computations were scheduled: \"\r\n                               \"{}\".format(self.total_computes))\r\n        return dask.get(dsk, keys, **kwargs)\r\n\r\nwith dask.config.set(scheduler=CustomScheduler(1)):\r\n    da.where(xr.DataArray(da.zeros((5, 5))), xr.DataArray(da.zeros((5, 5))), xr.DataArray(da.ones((5, 5)))).compute()\r\n```\r\n\r\nException:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\nCell In[22], line 2\r\n      1 with dask.config.set(scheduler=CustomScheduler(1)):\r\n----> 2     da.where(xr.DataArray(da.zeros((5, 5))), xr.DataArray(da.zeros((5, 5))), xr.DataArray(da.ones((5, 5)))).compute()\r\n\r\nFile ~/miniconda3/envs/polar2grid_py310/lib/python3.10/site-packages/dask/base.py:312, in DaskMethodsMixin.compute(self, **kwargs)\r\n    288 def compute(self, **kwargs):\r\n    289     \"\"\"Compute this dask collection\r\n    290\r\n    291     This turns a lazy Dask collection into its in-memory equivalent.\r\n   (...)\r\n    310     dask.base.compute\r\n    311     \"\"\"\r\n--> 312     (result,) = compute(self, traverse=False, **kwargs)\r\n    313     return result\r\n\r\nFile ~/miniconda3/envs/polar2grid_py310/lib/python3.10/site-packages/dask/base.py:600, in compute(traverse, optimize_graph, scheduler, get, *args, **kwargs)\r\n    597     keys.append(x.__dask_keys__())\r\n    598     postcomputes.append(x.__dask_postcompute__())\r\n--> 600 results = schedule(dsk, keys, **kwargs)\r\n    601 return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\r\n\r\nCell In[13], line 14, in CustomScheduler.__call__(self, dsk, keys, **kwargs)\r\n     12 self.total_computes += 1\r\n     13 if self.total_computes > self.max_computes:\r\n---> 14     raise RuntimeError(\"Too many dask computations were scheduled: \"\r\n     15                        \"{}\".format(self.total_computes))\r\n     16 return dask.get(dsk, keys, **kwargs)\r\n\r\nRuntimeError: Too many dask computations were scheduled: 4\r\n\r\n```\r\n\r\nNote how the error message says there were 4 computations when there should have only been 2 when the `if self.total_computes > self.max_computes` check is triggered. This is due to `compute_meta` computing the DataArrays as far as I can tell and hiding the `RuntimeError` from trickling up to the user.\r\n\r\n**Anything else we need to know?**:\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2023.9.2 (above code run with a 2022.05.2 but 2023.9.2 also produces it)\r\n- Python version: 3.10 and 3.11\r\n- Operating System: Linux\r\n- Install method (conda, pip, source): conda-forge\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/10595/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/10595/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}