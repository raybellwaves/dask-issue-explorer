{
    "url": "https://api.github.com/repos/dask/dask/issues/3973",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/3973/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/3973/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/3973/events",
    "html_url": "https://github.com/dask/dask/issues/3973",
    "id": 359031507,
    "node_id": "MDU6SXNzdWUzNTkwMzE1MDc=",
    "number": 3973,
    "title": "Inconsistent behaviour when using map_partitions with DataFrames as arguments",
    "user": {
        "login": "avnovikov",
        "id": 15693459,
        "node_id": "MDQ6VXNlcjE1NjkzNDU5",
        "avatar_url": "https://avatars.githubusercontent.com/u/15693459?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/avnovikov",
        "html_url": "https://github.com/avnovikov",
        "followers_url": "https://api.github.com/users/avnovikov/followers",
        "following_url": "https://api.github.com/users/avnovikov/following{/other_user}",
        "gists_url": "https://api.github.com/users/avnovikov/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/avnovikov/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/avnovikov/subscriptions",
        "organizations_url": "https://api.github.com/users/avnovikov/orgs",
        "repos_url": "https://api.github.com/users/avnovikov/repos",
        "events_url": "https://api.github.com/users/avnovikov/events{/privacy}",
        "received_events_url": "https://api.github.com/users/avnovikov/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2018-09-11T12:47:50Z",
    "updated_at": "2021-10-12T07:00:56Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "When trying to use map_partitions and passing GeoDataFrames as an argument I run into inconsistent behaviour of DASK when the DASK DataFrame is created from delayed. When passing raw DataFrame it throws error about unknown divisions, when first scattering this DataFrame and only then passing It as an argument everything works as (un)expected. Sorry for the long description, but I spent quite a long time trying to figure out what went wrong after DASK upgrade (from 0.17)\r\n\r\n```\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\nimport geopandas as gpd\r\nfrom dask import dataframe as dd\r\nfrom distributed import Client\r\nfrom shapely.geometry import Point\r\nfrom dask import delayed\r\n\r\ndef find_fids(df, gdf_harbours):   #, gdf_anchorage, gdf_faculty, gdf_berths, gdf_buoy):\r\n    print(\"This is partition with {} points\".format(len(df.index)))\r\n    m_df = df[['lat', 'lon', 'port_id', 'anch_id', 'fac_id', 'berth_id', 'boy_id']]\r\n    m_df = m_df.reset_index()\r\n    m_df.loc[:,'port_id'] = 1\r\n    m_df = m_df.set_index('index')\r\n    print(\"Finished partition\")\r\n    return m_df[['port_id', 'anch_id', 'fac_id', 'berth_id', 'boy_id']]\r\n\r\ndef rnp(length):\r\n    data_pos = (np.random.rand(length,2)-0.5)*90\r\n    data_id = -np.ones((length,5))\r\n    data = np.concatenate((data_pos, data_id), axis=1)\r\n    return pd.DataFrame(data = data, columns=['lat', 'lon', 'port_id', 'anch_id', 'fac_id', 'berth_id', 'boy_id'])\r\n\r\ndef get_fdf():\r\n    lazy_dataframes=[]\r\n    for i in range(10000):\r\n        ndf = delayed(rnp)(1000)\r\n        lazy_dataframes.append(ndf)\r\n    ddf = dd.from_delayed(lazy_dataframes, meta=lazy_dataframes[0].compute())\r\n    ldf = ddf.copy()\r\n    ddf = ddf.append(ldf)\r\n    return ddf\r\n\r\nclient = Client('127.0.0.1:8786', processes=True)\r\n\r\nlength = 10000\r\ndata_pos = (np.random.rand(length,2)-0.5)*90\r\nz = list(map(Point, data_pos))\r\nharbours = gpd.GeoDataFrame({'116': list(np.ones((length, 1))), 'geometry': z}, crs={'init': 'epsg:4326'})\r\n\r\nsharbours = client.scatter(harbours)\r\nddf = client.persist(get_fdf())\r\nddf[['port_id', 'anch_id', 'fac_id', 'berth_id', 'boy_id']] = ddf.map_partitions(\r\n            find_fids, sharbours, meta=pd.DataFrame({'port_id':[-1], 'anch_id':[-1], 'fac_id':[-1], \r\n                                                                'berth_id':[-1], 'boy_id':[-1]}))\r\ndf = ddf.compute()\r\n```\r\nWorks fine. However if I the last part will be only  \r\n\r\n```\r\nddf = client.persist(get_fdf())\r\nddf[['port_id', 'anch_id', 'fac_id', 'berth_id', 'boy_id']] = ddf.map_partitions(\r\n            find_fids, harbours, meta=pd.DataFrame({'port_id':[-1], 'anch_id':[-1], 'fac_id':[-1], \r\n                                                                'berth_id':[-1], 'boy_id':[-1]}))\r\ndf = ddf.compute()\r\n\r\n```\r\nthen I receive the following error\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-30-5088b0035b38> in <module>()\r\n      1 ddf[['port_id', 'anch_id', 'fac_id', 'berth_id', 'boy_id']] = ddf.map_partitions(\r\n      2             find_fids, harbours, meta=pd.DataFrame({'port_id':[-1], 'anch_id':[-1], 'fac_id':[-1], \r\n----> 3                                                                 'berth_id':[-1], 'boy_id':[-1]}))\r\n      4 df = ddf.compute()\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/dask/dataframe/core.py in map_partitions(self, func, *args, **kwargs)\r\n    579         >>> ddf.map_partitions(func).clear_divisions()  # doctest: +SKIP\r\n    580         \"\"\"\r\n--> 581         return map_partitions(func, self, *args, **kwargs)\r\n    582 \r\n    583     @insert_meta_param_description(pad=12)\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/dask/dataframe/core.py in map_partitions(func, *args, **kwargs)\r\n   3614     from .multi import _maybe_align_partitions\r\n   3615     args = _maybe_from_pandas(args)\r\n-> 3616     args = _maybe_align_partitions(args)\r\n   3617 \r\n   3618     if meta is no_default:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/dask/dataframe/multi.py in _maybe_align_partitions(args)\r\n    145     divisions = dfs[0].divisions\r\n    146     if not all(df.divisions == divisions for df in dfs):\r\n--> 147         dfs2 = iter(align_partitions(*dfs)[0])\r\n    148         return [a if not isinstance(a, _Frame) else next(dfs2) for a in args]\r\n    149     return args\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/dask/dataframe/multi.py in align_partitions(*dfs)\r\n    101         raise ValueError(\"dfs contains no DataFrame and Series\")\r\n    102     if not all(df.known_divisions for df in dfs1):\r\n--> 103         raise ValueError(\"Not all divisions are known, can't align \"\r\n    104                          \"partitions. Please use `set_index` \"\r\n    105                          \"to set the index.\")\r\n\r\nValueError: Not all divisions are known, can't align partitions. Please use `set_index` to set the index.\r\n```\r\n\r\nIf I try to set index (adding) the following line\r\n\r\n`ddf = client.persist(ddf.reset_index().set_index('index'))`\r\nit takes forever and when killed gives the following trace\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nKeyboardInterrupt                         Traceback (most recent call last)\r\n<ipython-input-12-2911203558a9> in <module>()\r\n----> 1 ddf = client.persist(ddf.reset_index().set_index('index'))\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/client.py in persist(self, collections, optimize_graph, workers, allow_other_workers, resources, retries, priority, fifo_timeout, actors, **kwargs)\r\n   2469                                          user_priority=priority,\r\n   2470                                          fifo_timeout=fifo_timeout,\r\n-> 2471                                          actors=actors)\r\n   2472 \r\n   2473         postpersists = [c.__dask_postpersist__() for c in collections]\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/client.py in _graph_to_futures(self, dsk, keys, restrictions, loose_restrictions, priority, user_priority, resources, retries, fifo_timeout, actors)\r\n   2109                 dsk = dask.optimization.inline(dsk, keys=values)\r\n   2110 \r\n-> 2111             d = {k: unpack_remotedata(v, byte_keys=True) for k, v in dsk.items()}\r\n   2112             extra_futures = set.union(*[v[1] for v in d.values()]) if d else set()\r\n   2113             extra_keys = {tokey(future.key) for future in extra_futures}\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/client.py in <dictcomp>(.0)\r\n   2109                 dsk = dask.optimization.inline(dsk, keys=values)\r\n   2110 \r\n-> 2111             d = {k: unpack_remotedata(v, byte_keys=True) for k, v in dsk.items()}\r\n   2112             extra_futures = set.union(*[v[1] for v in d.values()]) if d else set()\r\n   2113             extra_keys = {tokey(future.key) for future in extra_futures}\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in unpack_remotedata(o, byte_keys, myset)\r\n    173     if myset is None:\r\n    174         myset = set()\r\n--> 175         out = unpack_remotedata(o, byte_keys, myset)\r\n    176         return out, myset\r\n    177 \r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in unpack_remotedata(o, byte_keys, myset)\r\n    181         if not o:\r\n    182             return o\r\n--> 183         outs = [unpack_remotedata(item, byte_keys, myset) for item in o]\r\n    184         return type(o)(outs)\r\n    185     elif typ is dict:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in <listcomp>(.0)\r\n    181         if not o:\r\n    182             return o\r\n--> 183         outs = [unpack_remotedata(item, byte_keys, myset) for item in o]\r\n    184         return type(o)(outs)\r\n    185     elif typ is dict:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in unpack_remotedata(o, byte_keys, myset)\r\n    181         if not o:\r\n    182             return o\r\n--> 183         outs = [unpack_remotedata(item, byte_keys, myset) for item in o]\r\n    184         return type(o)(outs)\r\n    185     elif typ is dict:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in <listcomp>(.0)\r\n    181         if not o:\r\n    182             return o\r\n--> 183         outs = [unpack_remotedata(item, byte_keys, myset) for item in o]\r\n    184         return type(o)(outs)\r\n    185     elif typ is dict:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in unpack_remotedata(o, byte_keys, myset)\r\n    181         if not o:\r\n    182             return o\r\n--> 183         outs = [unpack_remotedata(item, byte_keys, myset) for item in o]\r\n    184         return type(o)(outs)\r\n    185     elif typ is dict:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in <listcomp>(.0)\r\n    181         if not o:\r\n    182             return o\r\n--> 183         outs = [unpack_remotedata(item, byte_keys, myset) for item in o]\r\n    184         return type(o)(outs)\r\n    185     elif typ is dict:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in unpack_remotedata(o, byte_keys, myset)\r\n    181         if not o:\r\n    182             return o\r\n--> 183         outs = [unpack_remotedata(item, byte_keys, myset) for item in o]\r\n    184         return type(o)(outs)\r\n    185     elif typ is dict:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in <listcomp>(.0)\r\n    181         if not o:\r\n    182             return o\r\n--> 183         outs = [unpack_remotedata(item, byte_keys, myset) for item in o]\r\n    184         return type(o)(outs)\r\n    185     elif typ is dict:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in unpack_remotedata(o, byte_keys, myset)\r\n    181         if not o:\r\n    182             return o\r\n--> 183         outs = [unpack_remotedata(item, byte_keys, myset) for item in o]\r\n    184         return type(o)(outs)\r\n    185     elif typ is dict:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in <listcomp>(.0)\r\n    181         if not o:\r\n    182             return o\r\n--> 183         outs = [unpack_remotedata(item, byte_keys, myset) for item in o]\r\n    184         return type(o)(outs)\r\n    185     elif typ is dict:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in unpack_remotedata(o, byte_keys, myset)\r\n    176         return out, myset\r\n    177 \r\n--> 178     typ = type(o)\r\n    179 \r\n    180     if typ in collection_types:\r\n```\r\n\r\nif done without _persist_, i.e.\r\n`ddf = ddf.reset_index().set_index('index')`\r\nthen it got stack on map_partitions with **unscattered** geodataframe and when killed produce the following trace:\r\n```\r\n\r\n---------------------------------------------------------------------------\r\nKeyboardInterrupt                         Traceback (most recent call last)\r\n<ipython-input-14-5088b0035b38> in <module>()\r\n      2             find_fids, harbours, meta=pd.DataFrame({'port_id':[-1], 'anch_id':[-1], 'fac_id':[-1], \r\n      3                                                                 'berth_id':[-1], 'boy_id':[-1]}))\r\n----> 4 df = ddf.compute()\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/dask/base.py in compute(self, **kwargs)\r\n    154         dask.base.compute\r\n    155         \"\"\"\r\n--> 156         (result,) = compute(self, traverse=False, **kwargs)\r\n    157         return result\r\n    158 \r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/dask/base.py in compute(*args, **kwargs)\r\n    393     keys = [x.__dask_keys__() for x in collections]\r\n    394     postcomputes = [x.__dask_postcompute__() for x in collections]\r\n--> 395     results = schedule(dsk, keys, **kwargs)\r\n    396     return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\r\n    397 \r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/client.py in get(self, dsk, keys, restrictions, loose_restrictions, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, **kwargs)\r\n   2202                                          fifo_timeout=fifo_timeout,\r\n   2203                                          retries=retries,\r\n-> 2204                                          user_priority=priority,\r\n   2205                                          )\r\n   2206         packed = pack_data(keys, futures)\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/client.py in _graph_to_futures(self, dsk, keys, restrictions, loose_restrictions, priority, user_priority, resources, retries, fifo_timeout, actors)\r\n   2107                       and k not in keyset}\r\n   2108             if values:\r\n-> 2109                 dsk = dask.optimization.inline(dsk, keys=values)\r\n   2110 \r\n   2111             d = {k: unpack_remotedata(v, byte_keys=True) for k, v in dsk.items()}\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/dask/optimization.py in inline(dsk, keys, inline_constants, dependencies)\r\n    249     if dependencies is None:\r\n    250         dependencies = {k: get_dependencies(dsk, k)\r\n--> 251                         for k in dsk}\r\n    252 \r\n    253     if inline_constants:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/dask/optimization.py in <dictcomp>(.0)\r\n    249     if dependencies is None:\r\n    250         dependencies = {k: get_dependencies(dsk, k)\r\n--> 251                         for k in dsk}\r\n    252 \r\n    253     if inline_constants:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/dask/core.py in get_dependencies(dsk, key, task, as_list)\r\n    199         new_work = []\r\n    200         for w in work:\r\n--> 201             typ = type(w)\r\n    202             if typ is tuple and w and callable(w[0]):  # istask(w)\r\n    203                 new_work += w[1:]\r\n\r\nKeyboardInterrupt: \r\n```\r\nI run with **scattered** geodataframe, then it got stack on map_partitions, consumes all the memory (in real life example) and when killed produce the following trace:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nKeyboardInterrupt                         Traceback (most recent call last)\r\n<ipython-input-12-9df5c63458da> in <module>()\r\n      2             find_fids, sharbours, meta=pd.DataFrame({'port_id':[-1], 'anch_id':[-1], 'fac_id':[-1], \r\n      3                                                                 'berth_id':[-1], 'boy_id':[-1]}))\r\n----> 4 df = ddf.compute()\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/dask/base.py in compute(self, **kwargs)\r\n    154         dask.base.compute\r\n    155         \"\"\"\r\n--> 156         (result,) = compute(self, traverse=False, **kwargs)\r\n    157         return result\r\n    158 \r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/dask/base.py in compute(*args, **kwargs)\r\n    393     keys = [x.__dask_keys__() for x in collections]\r\n    394     postcomputes = [x.__dask_postcompute__() for x in collections]\r\n--> 395     results = schedule(dsk, keys, **kwargs)\r\n    396     return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\r\n    397 \r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/client.py in get(self, dsk, keys, restrictions, loose_restrictions, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, **kwargs)\r\n   2202                                          fifo_timeout=fifo_timeout,\r\n   2203                                          retries=retries,\r\n-> 2204                                          user_priority=priority,\r\n   2205                                          )\r\n   2206         packed = pack_data(keys, futures)\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/client.py in _graph_to_futures(self, dsk, keys, restrictions, loose_restrictions, priority, user_priority, resources, retries, fifo_timeout, actors)\r\n   2109                 dsk = dask.optimization.inline(dsk, keys=values)\r\n   2110 \r\n-> 2111             d = {k: unpack_remotedata(v, byte_keys=True) for k, v in dsk.items()}\r\n   2112             extra_futures = set.union(*[v[1] for v in d.values()]) if d else set()\r\n   2113             extra_keys = {tokey(future.key) for future in extra_futures}\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/client.py in <dictcomp>(.0)\r\n   2109                 dsk = dask.optimization.inline(dsk, keys=values)\r\n   2110 \r\n-> 2111             d = {k: unpack_remotedata(v, byte_keys=True) for k, v in dsk.items()}\r\n   2112             extra_futures = set.union(*[v[1] for v in d.values()]) if d else set()\r\n   2113             extra_keys = {tokey(future.key) for future in extra_futures}\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in unpack_remotedata(o, byte_keys, myset)\r\n    173     if myset is None:\r\n    174         myset = set()\r\n--> 175         out = unpack_remotedata(o, byte_keys, myset)\r\n    176         return out, myset\r\n    177 \r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in unpack_remotedata(o, byte_keys, myset)\r\n    181         if not o:\r\n    182             return o\r\n--> 183         outs = [unpack_remotedata(item, byte_keys, myset) for item in o]\r\n    184         return type(o)(outs)\r\n    185     elif typ is dict:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in <listcomp>(.0)\r\n    181         if not o:\r\n    182             return o\r\n--> 183         outs = [unpack_remotedata(item, byte_keys, myset) for item in o]\r\n    184         return type(o)(outs)\r\n    185     elif typ is dict:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in unpack_remotedata(o, byte_keys, myset)\r\n    181         if not o:\r\n    182             return o\r\n--> 183         outs = [unpack_remotedata(item, byte_keys, myset) for item in o]\r\n    184         return type(o)(outs)\r\n    185     elif typ is dict:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in <listcomp>(.0)\r\n    181         if not o:\r\n    182             return o\r\n--> 183         outs = [unpack_remotedata(item, byte_keys, myset) for item in o]\r\n    184         return type(o)(outs)\r\n    185     elif typ is dict:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in unpack_remotedata(o, byte_keys, myset)\r\n    181         if not o:\r\n    182             return o\r\n--> 183         outs = [unpack_remotedata(item, byte_keys, myset) for item in o]\r\n    184         return type(o)(outs)\r\n    185     elif typ is dict:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in <listcomp>(.0)\r\n    181         if not o:\r\n    182             return o\r\n--> 183         outs = [unpack_remotedata(item, byte_keys, myset) for item in o]\r\n    184         return type(o)(outs)\r\n    185     elif typ is dict:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in unpack_remotedata(o, byte_keys, myset)\r\n    181         if not o:\r\n    182             return o\r\n--> 183         outs = [unpack_remotedata(item, byte_keys, myset) for item in o]\r\n    184         return type(o)(outs)\r\n    185     elif typ is dict:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in <listcomp>(.0)\r\n    181         if not o:\r\n    182             return o\r\n--> 183         outs = [unpack_remotedata(item, byte_keys, myset) for item in o]\r\n    184         return type(o)(outs)\r\n    185     elif typ is dict:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in unpack_remotedata(o, byte_keys, myset)\r\n    181         if not o:\r\n    182             return o\r\n--> 183         outs = [unpack_remotedata(item, byte_keys, myset) for item in o]\r\n    184         return type(o)(outs)\r\n    185     elif typ is dict:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in <listcomp>(.0)\r\n    181         if not o:\r\n    182             return o\r\n--> 183         outs = [unpack_remotedata(item, byte_keys, myset) for item in o]\r\n    184         return type(o)(outs)\r\n    185     elif typ is dict:\r\n\r\n/anaconda3/envs/mariquant/lib/python3.6/site-packages/distributed/utils_comm.py in unpack_remotedata(o, byte_keys, myset)\r\n    176         return out, myset\r\n    177 \r\n--> 178     typ = type(o)\r\n    179 \r\n    180     if typ in collection_types:\r\n\r\nKeyboardInterrupt: \r\n```",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/3973/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/3973/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}