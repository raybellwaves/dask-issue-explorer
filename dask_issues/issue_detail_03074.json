{
    "url": "https://api.github.com/repos/dask/dask/issues/3074",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/3074/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/3074/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/3074/events",
    "html_url": "https://github.com/dask/dask/issues/3074",
    "id": 289109956,
    "node_id": "MDU6SXNzdWUyODkxMDk5NTY=",
    "number": 3074,
    "title": "Multiprocess writes using `to_hdf5`",
    "user": {
        "login": "jakirkham",
        "id": 3019665,
        "node_id": "MDQ6VXNlcjMwMTk2NjU=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3019665?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/jakirkham",
        "html_url": "https://github.com/jakirkham",
        "followers_url": "https://api.github.com/users/jakirkham/followers",
        "following_url": "https://api.github.com/users/jakirkham/following{/other_user}",
        "gists_url": "https://api.github.com/users/jakirkham/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/jakirkham/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/jakirkham/subscriptions",
        "organizations_url": "https://api.github.com/users/jakirkham/orgs",
        "repos_url": "https://api.github.com/users/jakirkham/repos",
        "events_url": "https://api.github.com/users/jakirkham/events{/privacy}",
        "received_events_url": "https://api.github.com/users/jakirkham/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862305,
            "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=",
            "url": "https://api.github.com/repos/dask/dask/labels/array",
            "name": "array",
            "color": "006b75",
            "default": false,
            "description": null
        },
        {
            "id": 365513534,
            "node_id": "MDU6TGFiZWwzNjU1MTM1MzQ=",
            "url": "https://api.github.com/repos/dask/dask/labels/io",
            "name": "io",
            "color": "6f871c",
            "default": false,
            "description": ""
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 21,
    "created_at": "2018-01-17T01:12:00Z",
    "updated_at": "2021-10-12T04:39:39Z",
    "closed_at": null,
    "author_association": "MEMBER",
    "active_lock_reason": null,
    "body": "After seeing @stuartarchibald's [post on gitter]( https://gitter.im/dask/dask?at=5a5cd598290a1f45618f91b3 ), I was a bit curious how `to_hdf5` actually worked and whether it would be viable to call from multiple processes.\r\n\r\nTurns out [`to_hdf5` just calls `store` underneath the hood]( https://github.com/dask/dask/blob/0.16.1/dask/array/core.py#L3390 ) while [holding the file open locally]( https://github.com/dask/dask/blob/0.16.1/dask/array/core.py#L3385 ). The biggest issue of course is that the file is held open in write mode on the scheduler (meaning nothing else can write to the HDF5 file without corrupting it). Since the type of locking was not specified and `store` uses a [`threading.Lock` by default]( https://github.com/dask/dask/blob/0.16.1/dask/array/core.py#L837-L840 ), this is also incompatible with the multiprocessing use case (i.e. `threading.Lock` cannot be serialized/locked across processes). IOW the current implementation of `to_hdf5` is not friendly even for locked parallel writes.\r\n\r\nThat said, it should be feasible to change `to_hdf5`'s behavior to be more friendly for storage from multiple processes (though it will still need to be locked). In this case, it would still create the datasets initially (as it already does), but then would close the file. Instead of passing raw HDF5 Datasets as targets, a wrapper class would need to be used (to allow for pickling). The wrapper class would need to provide a `__setitem__` method that would open the HDF5 file and write to the HDF5 Dataset at the selection specified in a process safe manner (probably with `locket.lock_file`). Ideally it would provide a `__getitem__` method as well. Doing this should allow for HDF5 file to be written to in parallel. This assumes the filesystem is very robust and syncing changes between different nodes.\r\n\r\nAn alternative to this proposal that would avoid locking would be to have data serialized back to the scheduler, which then writes each piece to the HDF5 file as it arrives. This would avoid the overhead of the previous strategy (and any potential issues locking) by guaranteeing only one process ever opens the HDF5 file and keeps open until everything is written. This strategy would continue to work well for non-parallel use cases with arguably less overhead than is present now. The only thing to do before writing out all results would be to optimize the graphs since `store` would no longer be used.",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/3074/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/3074/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}