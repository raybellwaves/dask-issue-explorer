{
    "url": "https://api.github.com/repos/dask/dask/issues/4275",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/4275/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/4275/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/4275/events",
    "html_url": "https://github.com/dask/dask/issues/4275",
    "id": 388380730,
    "node_id": "MDU6SXNzdWUzODgzODA3MzA=",
    "number": 4275,
    "title": "Better educate users when hashing/tokenizing large numpy arrays",
    "user": {
        "login": "qwitwa",
        "id": 2302478,
        "node_id": "MDQ6VXNlcjIzMDI0Nzg=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2302478?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/qwitwa",
        "html_url": "https://github.com/qwitwa",
        "followers_url": "https://api.github.com/users/qwitwa/followers",
        "following_url": "https://api.github.com/users/qwitwa/following{/other_user}",
        "gists_url": "https://api.github.com/users/qwitwa/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/qwitwa/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/qwitwa/subscriptions",
        "organizations_url": "https://api.github.com/users/qwitwa/orgs",
        "repos_url": "https://api.github.com/users/qwitwa/repos",
        "events_url": "https://api.github.com/users/qwitwa/events{/privacy}",
        "received_events_url": "https://api.github.com/users/qwitwa/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862305,
            "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=",
            "url": "https://api.github.com/repos/dask/dask/labels/array",
            "name": "array",
            "color": "006b75",
            "default": false,
            "description": null
        },
        {
            "id": 386719598,
            "node_id": "MDU6TGFiZWwzODY3MTk1OTg=",
            "url": "https://api.github.com/repos/dask/dask/labels/documentation",
            "name": "documentation",
            "color": "f9d0c4",
            "default": true,
            "description": "Improve or add to documentation"
        },
        {
            "id": 996497175,
            "node_id": "MDU6TGFiZWw5OTY0OTcxNzU=",
            "url": "https://api.github.com/repos/dask/dask/labels/good%20second%20issue",
            "name": "good second issue",
            "color": "5319e7",
            "default": false,
            "description": "Clearly described, educational, but less trivial than \"good first issue\"."
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 7,
    "created_at": "2018-12-06T20:16:38Z",
    "updated_at": "2021-10-19T01:51:19Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "At the monthly community meeting we discussed that new users of dask may be surprised by slowdowns when passing large arrays to numpy without name=False. \r\n\r\nThis has been discussed previously at #4169 where solving the issue via configuration was proposed, and there seemed to be some consensus at the meeting that this was viable. Discussion about how to implement that should probably take place on that issue.\r\n\r\nHowever, configuration options are no good if users do not know about them, and at present there is not much indication to a naive user passing large numpy arrays that they're working against the grain, other than a slowdown in code, which can be substantial (as shown by the benchmark below). \r\n\r\nAlthough adding warnings to the introductory docs was rejected (as this issue only affects a particular subset of users), we agreed that a dynamic warning message that pointed users to relevant documentation (possibly dask.array best practices?) when input arrays were expected to take a long time to hash would be very useful. \r\n\r\nIf dask/distributed#2400 is implemented, then this warning could also be shown there. \r\n\r\nThe benchmark below shows a pathological use-case which I personally encountered as a result of a bodge to force pandas to store images or image-stacks inside dataframe columns. It would be nice if the dynamic check were robust to such cases, but even a simple check that the number of elements in the input array does not exceed a threshold would be better than the current situation. \r\n\r\n```python\r\nimport numpy as np\r\nimport dask.array as da\r\nfrom dask.distributed import Client\r\n\r\nclient = Client()\r\n\r\n# normal use-case, shows some slowdown\r\ndef create_test_for_3d_array(x, y, z):\r\n    arr = np.random.rand(x, y, z)\r\n    def with_hashing():\r\n        arr_da = da.from_array(arr, chunks=(x // 100, -1, -1))\r\n    def without_hashing():\r\n        arr_da = da.from_array(arr, chunks=(x // 100, -1, -1), name=False)\r\n    return (with_hashing, without_hashing)\r\n\r\n# my unusual use-case, pathological\r\ndef create_test_for_nested_object_array(x, y, z):\r\n    # pre-allocate object array \r\n    arr = np.full(x, None)\r\n    # assign using broadcasting and list to force a 1d object array of 2d arrays\r\n    arr[:] = list(np.random.rand(x, y, z))\r\n    def with_hashing():\r\n        arr_da = da.from_array(arr, chunks=(x // 100,))\r\n    def without_hashing():\r\n        arr_da = da.from_array(arr, chunks=(x // 100,), name=False)\r\n    return (with_hashing, without_hashing)\r\n\r\n(with_hashing_3d, without_hashing_3d) = create_test_for_3d_array(100000, 28, 28)\r\n# smaller size for obj because otherwise the code does not complete in reasonable time\r\n(with_hashing_obj, without_hashing_obj) = create_test_for_nested_object_array(10000, 5, 5)\r\n\r\n# in the ipython repl\r\n# for 100_000, 28, 28\r\n%timeit with_hashing_3d()\r\n# 552 ms \u00b1 946 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\r\n%timeit without_hashing_3d()\r\n# 269 \u00b5s \u00b1 1.06 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)\r\n\r\n# for 10_000, 5, 5\r\n%timeit with_hashing_obj()\r\n# 2.05 s \u00b1 11.5 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\r\n%timeit without_hashing_obj()\r\n# 207 \u00b5s \u00b1 524 ns per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)\r\n```\r\n\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/4275/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/4275/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}