[
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/537696549",
        "html_url": "https://github.com/dask/dask/issues/5452#issuecomment-537696549",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/5452",
        "id": 537696549,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUzNzY5NjU0OQ==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-10-02T21:49:40Z",
        "updated_at": "2019-10-02T21:49:40Z",
        "author_association": "MEMBER",
        "body": "> How/when to allow the user to define their own chunk sizes? With semi-recent updates for 'auto' chunking and setting chunks based on in-memory size this is easier, but still requires asking users to understand some low-level implementation details of a package.\r\n\r\nI would say that this depends on the technical sophistication of your users.  Assuming that that sophistication is sometimes low, I would say that you should probably expose chunking optionally, and otherwise should help to provide guides to dask's auto-chunking if possible.  Assuming that you're dealing with geotiffs it would be good to use the tile size to inform automatic chunking.\r\n\r\nhttps://github.com/dask/dask/blob/4898c75908587a1c3686f9c87d7150dd9cf0d379/dask/array/core.py#L2313\r\n\r\nThis is done in an old PR to Xarray, which might be interesting.\r\n\r\nhttps://github.com/pydata/xarray/pull/2255/files#diff-6364b203943c799516f9ecba19e1b119R326\r\n\r\n> How/when should number of workers be configured by the package's user? Things like OMP_NUM_THREADS and DASK_NUM_WORKERS (or the related dask.config.set parameter).\r\n\r\nI think that downstream libraries should probably avoid setting this if possible.  Creating the scheduler/client should be orthogonal from libraries that create computations.  \r\n\r\n> If the package wants to take the advantage of a distributed client (submit, gather, etc) what should the user be required to provide? Is it bad practice to use get_client inside the package's utilities to get any configured client? Should a user be required to provide a client? If not provided can/should a package create a local client? Is that too much magic happening without the user's knowledge (creating sub-processes, etc)?\r\n\r\nIdeally, they don't have to use submit/gather, and can just use `dask.compute`/`dask.persist`.  This makes them usable by the broadest set of Dask schedulers.\r\n\r\nOf course, as your questions poses, this may not always be possible.  I think that using `get_client`, as you suggest, is probably best.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/537696549/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/537773973",
        "html_url": "https://github.com/dask/dask/issues/5452#issuecomment-537773973",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/5452",
        "id": 537773973,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUzNzc3Mzk3Mw==",
        "user": {
            "login": "djhoese",
            "id": 1828519,
            "node_id": "MDQ6VXNlcjE4Mjg1MTk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1828519?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/djhoese",
            "html_url": "https://github.com/djhoese",
            "followers_url": "https://api.github.com/users/djhoese/followers",
            "following_url": "https://api.github.com/users/djhoese/following{/other_user}",
            "gists_url": "https://api.github.com/users/djhoese/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/djhoese/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/djhoese/subscriptions",
            "organizations_url": "https://api.github.com/users/djhoese/orgs",
            "repos_url": "https://api.github.com/users/djhoese/repos",
            "events_url": "https://api.github.com/users/djhoese/events{/privacy}",
            "received_events_url": "https://api.github.com/users/djhoese/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-10-03T03:57:02Z",
        "updated_at": "2019-10-03T03:57:02Z",
        "author_association": "CONTRIBUTOR",
        "body": "So it sounds like to summarize your answers:\r\n\r\n1. It'll be a case by case decision on how/when chunking is specified by package users. In most cases and if done correctly the package should be able to auto-chunk in most cases using `normalize_chunks` with optional overrides by the user.\r\n2. Packages point to dask docs.\r\n3. I was thinking of non-array cases where we have utilities using futures and/or complex delayed functions. All or most of the dask-ness of the utility are hidden from the user except for \"you can run this on a cluster if you pass a dask client to the `client` keyword argument\".",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/537773973/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/538043488",
        "html_url": "https://github.com/dask/dask/issues/5452#issuecomment-538043488",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/5452",
        "id": 538043488,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUzODA0MzQ4OA==",
        "user": {
            "login": "pnuu",
            "id": 3170788,
            "node_id": "MDQ6VXNlcjMxNzA3ODg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3170788?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pnuu",
            "html_url": "https://github.com/pnuu",
            "followers_url": "https://api.github.com/users/pnuu/followers",
            "following_url": "https://api.github.com/users/pnuu/following{/other_user}",
            "gists_url": "https://api.github.com/users/pnuu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pnuu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pnuu/subscriptions",
            "organizations_url": "https://api.github.com/users/pnuu/orgs",
            "repos_url": "https://api.github.com/users/pnuu/repos",
            "events_url": "https://api.github.com/users/pnuu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pnuu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-10-03T17:25:43Z",
        "updated_at": "2019-10-03T17:25:43Z",
        "author_association": "NONE",
        "body": "Few more (euro) cents from another Pytroll core dev. As I'm more concentrated on the operational satellite processing chains, there are some points that I need to consider all the time, both when writing the software and when setting things up. Below are some thoughts that came to mind when I read the 3-item list @djhoese started with.\r\n\r\nThere can be several completely independent chains (we at FMI have 10+) running, and some of them need to share resources. So the chains need to be constrained in CPU and/or RAM usage. The first means setting *both* `OMP_NUM_THREADS` and `DASK_NUM_WORKERS`, and the other *both* `DASK_NUM_WORKERS` and the chunk size. The CPU limitation is exact. RAM limitation depends a lot on the implementation and use case. With \"simple\" array operations where chunks are constant, it can be controlled with some precission. With Satpy it depends if reprojection is done, which resampling method is used, if the resampling uses caching, what the output is (JPG, GeoTIFF, NetCDF, ...), what's the originating data, and so on and so on.\r\n\r\nAs Dask by default uses all the resources available, we Pytroll devs need to advice the users with things like (a _bit_ exaggerated, but not by much) \"Try if `PYTROLL_CHUNK_SIZE=1024 OMP_NUM_THREADS=1 DASK_NUM_WORKERS=4 BLAS_NUM_THREADS=1 MKL_NUM_THREADS=1 script.py` works better.\" Naturally these depend on the use case.\r\n\r\nI guess the point here is: we (the library/application devs) need a simple way to give the user control over the amount of resources the software takes.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/538043488/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/538055572",
        "html_url": "https://github.com/dask/dask/issues/5452#issuecomment-538055572",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/5452",
        "id": 538055572,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUzODA1NTU3Mg==",
        "user": {
            "login": "djhoese",
            "id": 1828519,
            "node_id": "MDQ6VXNlcjE4Mjg1MTk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1828519?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/djhoese",
            "html_url": "https://github.com/djhoese",
            "followers_url": "https://api.github.com/users/djhoese/followers",
            "following_url": "https://api.github.com/users/djhoese/following{/other_user}",
            "gists_url": "https://api.github.com/users/djhoese/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/djhoese/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/djhoese/subscriptions",
            "organizations_url": "https://api.github.com/users/djhoese/orgs",
            "repos_url": "https://api.github.com/users/djhoese/repos",
            "events_url": "https://api.github.com/users/djhoese/events{/privacy}",
            "received_events_url": "https://api.github.com/users/djhoese/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-10-03T17:55:29Z",
        "updated_at": "2019-10-03T17:55:59Z",
        "author_association": "CONTRIBUTOR",
        "body": "> I guess the point here is: we (the library/application devs) need a simple way to give the user control over the amount of resources the software takes.\r\n\r\nAnd any package using dask would need to come up with some sort of best practices for their use cases. So maybe it isn't something that dask can do to help any more than it already is, but that dask's best practices for downstream packages would need to discuss this as something people should be concerned about.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/538055572/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/538088606",
        "html_url": "https://github.com/dask/dask/issues/5452#issuecomment-538088606",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/5452",
        "id": 538088606,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUzODA4ODYwNg==",
        "user": {
            "login": "mraspaud",
            "id": 167802,
            "node_id": "MDQ6VXNlcjE2NzgwMg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/167802?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mraspaud",
            "html_url": "https://github.com/mraspaud",
            "followers_url": "https://api.github.com/users/mraspaud/followers",
            "following_url": "https://api.github.com/users/mraspaud/following{/other_user}",
            "gists_url": "https://api.github.com/users/mraspaud/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mraspaud/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mraspaud/subscriptions",
            "organizations_url": "https://api.github.com/users/mraspaud/orgs",
            "repos_url": "https://api.github.com/users/mraspaud/repos",
            "events_url": "https://api.github.com/users/mraspaud/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mraspaud/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-10-03T19:23:26Z",
        "updated_at": "2019-10-03T19:23:26Z",
        "author_association": "NONE",
        "body": "Great stuff in here, thanks for starting this issue!\r\n\r\nI have one thing I would like to bring up, it's related to IO. In our application (satpy), we do read a lot of data from disk and write at least as much to disk when we're done. However, it's not really practical for us (at my work place) to have these data on shared storage as the data volume is too big and would slow down the entire network, so we have the data locally on the servers. On the other hand, we need to balance the load of our servers, so dask.distributed would be very handy, but I'm not sure how to handle the reading and writing parts as they can only be done on one of the machines. I know that workers can be assigned some flags to represent the resources they have access to, but how do we set this up transparently in a library (satpy) that have to be runable both with and without dask.distributed ? And more generally how can we activate distributed be added transparently to the library ? (I think that last question was also raised indirectly by @djhoese)",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/538088606/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/538097271",
        "html_url": "https://github.com/dask/dask/issues/5452#issuecomment-538097271",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/5452",
        "id": 538097271,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUzODA5NzI3MQ==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-10-03T19:41:04Z",
        "updated_at": "2019-10-03T19:41:04Z",
        "author_association": "MEMBER",
        "body": "I would encourage satpy to not make constraints about setting up Dask workers.  I think that this is handled best on an application by application basis. \r\n\r\n> There can be several completely independent chains (we at FMI have 10+) running, and some of them need to share resources. So the chains need to be constrained in CPU and/or RAM usage\r\n\r\nCan they all use the same dask cluster?  If so, that would load balance for you.\r\n\r\n> but I'm not sure how to handle the reading and writing parts as they can only be done on one of the machines\r\n\r\nTypically people use a network file system for this sort of thing.  If I/O is a bottleneck then you might consider compression, nicer file formats, doing more computation per run, or something similar.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/538097271/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/539027568",
        "html_url": "https://github.com/dask/dask/issues/5452#issuecomment-539027568",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/5452",
        "id": 539027568,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUzOTAyNzU2OA==",
        "user": {
            "login": "djhoese",
            "id": 1828519,
            "node_id": "MDQ6VXNlcjE4Mjg1MTk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1828519?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/djhoese",
            "html_url": "https://github.com/djhoese",
            "followers_url": "https://api.github.com/users/djhoese/followers",
            "following_url": "https://api.github.com/users/djhoese/following{/other_user}",
            "gists_url": "https://api.github.com/users/djhoese/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/djhoese/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/djhoese/subscriptions",
            "organizations_url": "https://api.github.com/users/djhoese/orgs",
            "repos_url": "https://api.github.com/users/djhoese/repos",
            "events_url": "https://api.github.com/users/djhoese/events{/privacy}",
            "received_events_url": "https://api.github.com/users/djhoese/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-10-07T14:04:12Z",
        "updated_at": "2019-10-07T14:04:12Z",
        "author_association": "CONTRIBUTOR",
        "body": "I thought of some new ones this weekend and an update on another:\r\n\r\n2a. A lot of scientific libraries that can benefit from dask are usually wrapping old fortran or C code that is fast because of how it is implemented. Some also use OpenMP, but they are part of the existing users' workflow. Blindly setting things like OpenMP or BLAS number of threads could have major performance penalties on these libraries. Perhaps suggesting sub-library developers to take advantage of projects like https://github.com/joblib/threadpoolctl may be a good suggestion. I've never used it myself, but discovered it when worrying about how Satpy uses the pykdtree library (OpenMP-based). If we access pykdtree from dask workers there isn't a real need for OpenMP...but what if it is faster (leading to profiling, benchmarks, etc only to find it doesn't make a big difference)?\r\n\r\n4. How to make a sub-library work for both numpy users, dask users, and xarray users. In most cases numpy and dask arrays should work pretty well together with `__array_function__`.  things like blockwise operations or having to do delayed functions as workarounds for non-vectorized operations can make interfaces complicated. Similarly, having the same interface work with xarray objects can be difficult when you want to maintain `.attrs` (which get lost on most operations), `.dims`, etc. This could result in 3 separate implementations of the same functionality or even 4 if you want to throw a numba jit'd version in the mix. I'm not saying that this is necessarily something dask/xarray devs should be concerned about but it can hinder libraries migrating code to be dask/xarray friendly. Side question: Can blockwise be used as a decorator?\r\n\r\n5. Some low level C/fortran libraries are used for reading/writing files and may not be multi-process or multi-thread safe. This makes the sub-library developer have to worry about what dask scheduler the user is using and to choose the most performant method of using these libraries. In Satpy's case we got around some of this by using a thread lock on `da.store` with rasterio. I think xarray has come up with fancier ways of handling this, but I haven't had time to investigate. Best practices could either help or layout issues like this. Or if there is an easy way to check the scheduler being used or if there is an easy way to tell users \"you *must* create your X library jobs like this so that this entire dask task graph gets run on one threaded worker on a single node\" then that could work too. It is something I've wanted to play with more in Satpy but haven't had time.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/539027568/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/541708415",
        "html_url": "https://github.com/dask/dask/issues/5452#issuecomment-541708415",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/5452",
        "id": 541708415,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU0MTcwODQxNQ==",
        "user": {
            "login": "djhoese",
            "id": 1828519,
            "node_id": "MDQ6VXNlcjE4Mjg1MTk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1828519?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/djhoese",
            "html_url": "https://github.com/djhoese",
            "followers_url": "https://api.github.com/users/djhoese/followers",
            "following_url": "https://api.github.com/users/djhoese/following{/other_user}",
            "gists_url": "https://api.github.com/users/djhoese/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/djhoese/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/djhoese/subscriptions",
            "organizations_url": "https://api.github.com/users/djhoese/orgs",
            "repos_url": "https://api.github.com/users/djhoese/repos",
            "events_url": "https://api.github.com/users/djhoese/events{/privacy}",
            "received_events_url": "https://api.github.com/users/djhoese/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-10-14T14:22:32Z",
        "updated_at": "2019-10-14T14:22:32Z",
        "author_association": "CONTRIBUTOR",
        "body": "6. Another one based on https://github.com/dask/distributed/pull/2671. How to write tests (pytest or unittest only) that need to use a distributed Client. When trying to do it in Satpy tests I run in to issues with ports remaining open and not being able to reopen them.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/541708415/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/541821786",
        "html_url": "https://github.com/dask/dask/issues/5452#issuecomment-541821786",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/5452",
        "id": 541821786,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU0MTgyMTc4Ng==",
        "user": {
            "login": "TomAugspurger",
            "id": 1312546,
            "node_id": "MDQ6VXNlcjEzMTI1NDY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1312546?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/TomAugspurger",
            "html_url": "https://github.com/TomAugspurger",
            "followers_url": "https://api.github.com/users/TomAugspurger/followers",
            "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
            "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
            "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
            "repos_url": "https://api.github.com/users/TomAugspurger/repos",
            "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
            "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-10-14T17:49:25Z",
        "updated_at": "2019-10-14T17:49:25Z",
        "author_association": "MEMBER",
        "body": "> When trying to do it in Satpy tests I run in to issues with ports remaining open and not being able to reopen them.\r\n\r\nWere you doing anything fancy, like trying to reuse an event loop or state between tests? Or were you just using the public API? I would think that things would be fine as long as you're closing the cluster down between tests. Reports otherwise would be welcome.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/541821786/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/541839321",
        "html_url": "https://github.com/dask/dask/issues/5452#issuecomment-541839321",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/5452",
        "id": 541839321,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU0MTgzOTMyMQ==",
        "user": {
            "login": "djhoese",
            "id": 1828519,
            "node_id": "MDQ6VXNlcjE4Mjg1MTk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1828519?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/djhoese",
            "html_url": "https://github.com/djhoese",
            "followers_url": "https://api.github.com/users/djhoese/followers",
            "following_url": "https://api.github.com/users/djhoese/following{/other_user}",
            "gists_url": "https://api.github.com/users/djhoese/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/djhoese/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/djhoese/subscriptions",
            "organizations_url": "https://api.github.com/users/djhoese/orgs",
            "repos_url": "https://api.github.com/users/djhoese/repos",
            "events_url": "https://api.github.com/users/djhoese/events{/privacy}",
            "received_events_url": "https://api.github.com/users/djhoese/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-10-14T18:22:23Z",
        "updated_at": "2019-10-14T18:22:23Z",
        "author_association": "CONTRIBUTOR",
        "body": "No, nothing too fancy. When I originally wrote the tests I noticed that dask's own tests had some pytest fixtures for handling things so I assumed that might be necessary and just mocked the Client in my tests. I was creating a LocalCluster with 1 worker, creating a Client with that cluster, then after using them I would run `.close()` on both.\r\n\r\nI should note, it passed locally just fine but on Travis it would fail.\r\n\r\nHere's the error:\r\n\r\n<details>\r\n\r\n```\r\nBUG:asyncio:Using selector: EpollSelector\r\n\r\nDEBUG:asyncio:Using selector: EpollSelector\r\n\r\n/home/travis/miniconda/envs/test/lib/python3.6/site-packages/distributed/dashboard/core.py:72: UserWarning: \r\n\r\nPort 8787 is already in use. \r\n\r\nPerhaps you already have a cluster running?\r\n\r\nHosting the diagnostics dashboard on a random port instead.\r\n\r\n  warnings.warn(\"\\n\" + msg)\r\n\r\n/home/travis/miniconda/envs/test/lib/python3.6/site-packages/distributed/dashboard/core.py:75: ResourceWarning: unclosed <socket.socket fd=30, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('0.0.0.0', 0)>\r\n\r\n  raise\r\n\r\nERROR:asyncio:Task exception was never retrieved\r\n\r\nfuture: <Task finished coro=<_wrap_awaitable() done, defined at /home/travis/miniconda/envs/test/lib/python3.6/asyncio/tasks.py:530> exception=RuntimeError('\\n        An attempt has been made to start a new process before the\\n        current process has finished its bootstrapping phase.\\n\\n        This probably means that you are not using fork to start your\\n        child processes and you have forgotten to use the proper idiom\\n        in the main module:\\n\\n            if __name__ == \\'__main__\\':\\n                freeze_support()\\n                ...\\n\\n        The \"freeze_support()\" line can be omitted if the program\\n        is not going to be frozen to produce an executable.',)>\r\n\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/travis/miniconda/envs/test/lib/python3.6/asyncio/tasks.py\", line 537, in _wrap_awaitable\r\n\r\n    return (yield from awaitable.__await__())\r\n\r\n  File \"/home/travis/miniconda/envs/test/lib/python3.6/site-packages/distributed/nanny.py\", line 243, in start\r\n\r\n    response = await self.instantiate()\r\n\r\n  File \"/home/travis/miniconda/envs/test/lib/python3.6/site-packages/distributed/nanny.py\", line 325, in instantiate\r\n\r\n    result = await self.process.start()\r\n\r\n  File \"/home/travis/miniconda/envs/test/lib/python3.6/site-packages/distributed/nanny.py\", line 490, in start\r\n\r\n    await self.process.start()\r\n\r\n  File \"/home/travis/miniconda/envs/test/lib/python3.6/site-packages/distributed/process.py\", line 33, in _call_and_set_future\r\n\r\n    res = func(*args, **kwargs)\r\n\r\n  File \"/home/travis/miniconda/envs/test/lib/python3.6/site-packages/distributed/process.py\", line 190, in _start\r\n\r\n    process.start()\r\n\r\n  File \"/home/travis/miniconda/envs/test/lib/python3.6/multiprocessing/process.py\", line 105, in start\r\n\r\n    self._popen = self._Popen(self)\r\n\r\n  File \"/home/travis/miniconda/envs/test/lib/python3.6/multiprocessing/context.py\", line 291, in _Popen\r\n\r\n    return Popen(process_obj)\r\n\r\n  File \"/home/travis/miniconda/envs/test/lib/python3.6/multiprocessing/popen_forkserver.py\", line 35, in __init__\r\n\r\n    super().__init__(process_obj)\r\n\r\n  File \"/home/travis/miniconda/envs/test/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\r\n\r\n    self._launch(process_obj)\r\n\r\n  File \"/home/travis/miniconda/envs/test/lib/python3.6/multiprocessing/popen_forkserver.py\", line 42, in _launch\r\n\r\n    prep_data = spawn.get_preparation_data(process_obj._name)\r\n\r\n  File \"/home/travis/miniconda/envs/test/lib/python3.6/multiprocessing/spawn.py\", line 143, in get_preparation_data\r\n\r\n    _check_not_importing_main()\r\n\r\n  File \"/home/travis/miniconda/envs/test/lib/python3.6/multiprocessing/spawn.py\", line 136, in _check_not_importing_main\r\n\r\n    is not going to be frozen to produce an executable.''')\r\n\r\nRuntimeError: \r\n\r\n        An attempt has been made to start a new process before the\r\n\r\n        current process has finished its bootstrapping phase.\r\n\r\n        This probably means that you are not using fork to start your\r\n\r\n        child processes and you have forgotten to use the proper idiom\r\n\r\n        in the main module:\r\n\r\n            if __name__ == '__main__':\r\n\r\n                freeze_support()\r\n\r\n                ...\r\n\r\n        The \"freeze_support()\" line can be omitted if the program\r\n\r\n        is not going to be frozen to produce an executable.\r\n\r\nNo output has been received in the last 10m0s, this potentially indicates a stalled build or something wrong with the build itself.\r\n\r\nCheck the details on how to adjust your build configuration on: https://docs.travis-ci.com/user/common-build-problems/#build-times-out-because-no-output-was-received\r\n```\r\n\r\n</details>\r\n\r\nSo it is likely in the way we are starting our tests (using `python setup.py test` to run a unittest suite) that is causing the error. If I have time to get back to it I'll file a separate github issue.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/541839321/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/541866689",
        "html_url": "https://github.com/dask/dask/issues/5452#issuecomment-541866689",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/5452",
        "id": 541866689,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU0MTg2NjY4OQ==",
        "user": {
            "login": "TomAugspurger",
            "id": 1312546,
            "node_id": "MDQ6VXNlcjEzMTI1NDY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1312546?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/TomAugspurger",
            "html_url": "https://github.com/TomAugspurger",
            "followers_url": "https://api.github.com/users/TomAugspurger/followers",
            "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
            "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
            "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
            "repos_url": "https://api.github.com/users/TomAugspurger/repos",
            "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
            "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-10-14T19:14:46Z",
        "updated_at": "2019-10-14T19:14:46Z",
        "author_association": "MEMBER",
        "body": "> When I originally wrote the tests I noticed that dask's own tests had some pytest fixtures for handling things so I assumed that might be necessary and just mocked the Client in my tests.\r\n\r\nThose are documented at https://distributed.dask.org/en/latest/develop.html#writing-tests. If you're making assertions about the cluster, it may be helpful to use those helpers, but otherwise they may be too tricky to use.\r\n\r\n> If I have time to get back to it I'll file a separate github issue.\r\n\r\nWe have one similar to this already. It's about creating a `LocalCluster` at the top-level of a python script. I'm not familiar with what `setup.py test` does unfortunately.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/541866689/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/541867547",
        "html_url": "https://github.com/dask/dask/issues/5452#issuecomment-541867547",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/5452",
        "id": 541867547,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU0MTg2NzU0Nw==",
        "user": {
            "login": "djhoese",
            "id": 1828519,
            "node_id": "MDQ6VXNlcjE4Mjg1MTk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1828519?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/djhoese",
            "html_url": "https://github.com/djhoese",
            "followers_url": "https://api.github.com/users/djhoese/followers",
            "following_url": "https://api.github.com/users/djhoese/following{/other_user}",
            "gists_url": "https://api.github.com/users/djhoese/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/djhoese/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/djhoese/subscriptions",
            "organizations_url": "https://api.github.com/users/djhoese/orgs",
            "repos_url": "https://api.github.com/users/djhoese/repos",
            "events_url": "https://api.github.com/users/djhoese/events{/privacy}",
            "received_events_url": "https://api.github.com/users/djhoese/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-10-14T19:16:25Z",
        "updated_at": "2019-10-14T19:16:25Z",
        "author_association": "CONTRIBUTOR",
        "body": "> I'm not familiar with what setup.py test does unfortunately.\r\n\r\nIt's deprecated (as far as I understand), but essentially calls unittest with the test suite specified in setup.py.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/541867547/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/542265020",
        "html_url": "https://github.com/dask/dask/issues/5452#issuecomment-542265020",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/5452",
        "id": 542265020,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU0MjI2NTAyMA==",
        "user": {
            "login": "TomAugspurger",
            "id": 1312546,
            "node_id": "MDQ6VXNlcjEzMTI1NDY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1312546?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/TomAugspurger",
            "html_url": "https://github.com/TomAugspurger",
            "followers_url": "https://api.github.com/users/TomAugspurger/followers",
            "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
            "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
            "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
            "repos_url": "https://api.github.com/users/TomAugspurger/repos",
            "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
            "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-10-15T15:17:41Z",
        "updated_at": "2019-10-15T15:17:41Z",
        "author_association": "MEMBER",
        "body": "> Perhaps suggesting sub-library developers to take advantage of projects like https://github.com/joblib/threadpoolctl may be a good suggestion. I've never used it myself, but discovered it when worrying about how Satpy uses the pykdtree library (OpenMP-based).\r\n\r\nJust an FYI, scikit-learn is dealing with similar issues: https://github.com/scikit-learn/scikit-learn/issues/14979.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/542265020/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]