[
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/358191102",
        "html_url": "https://github.com/dask/dask/issues/3074#issuecomment-358191102",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/3074",
        "id": 358191102,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODE5MTEwMg==",
        "user": {
            "login": "rzu512",
            "id": 32720823,
            "node_id": "MDQ6VXNlcjMyNzIwODIz",
            "avatar_url": "https://avatars.githubusercontent.com/u/32720823?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rzu512",
            "html_url": "https://github.com/rzu512",
            "followers_url": "https://api.github.com/users/rzu512/followers",
            "following_url": "https://api.github.com/users/rzu512/following{/other_user}",
            "gists_url": "https://api.github.com/users/rzu512/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rzu512/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rzu512/subscriptions",
            "organizations_url": "https://api.github.com/users/rzu512/orgs",
            "repos_url": "https://api.github.com/users/rzu512/repos",
            "events_url": "https://api.github.com/users/rzu512/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rzu512/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-01-17T04:03:58Z",
        "updated_at": "2018-01-17T04:03:58Z",
        "author_association": "NONE",
        "body": "Can I avoid this problem if I use the MPI scheduler?\r\nh5py [says](http://docs.h5py.org/en/latest/mpi.html) it supports parallel hdf5.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/358191102/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/358202223",
        "html_url": "https://github.com/dask/dask/issues/3074#issuecomment-358202223",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/3074",
        "id": 358202223,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODIwMjIyMw==",
        "user": {
            "login": "jakirkham",
            "id": 3019665,
            "node_id": "MDQ6VXNlcjMwMTk2NjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3019665?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jakirkham",
            "html_url": "https://github.com/jakirkham",
            "followers_url": "https://api.github.com/users/jakirkham/followers",
            "following_url": "https://api.github.com/users/jakirkham/following{/other_user}",
            "gists_url": "https://api.github.com/users/jakirkham/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jakirkham/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jakirkham/subscriptions",
            "organizations_url": "https://api.github.com/users/jakirkham/orgs",
            "repos_url": "https://api.github.com/users/jakirkham/repos",
            "events_url": "https://api.github.com/users/jakirkham/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jakirkham/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-01-17T05:34:13Z",
        "updated_at": "2018-01-17T05:34:13Z",
        "author_association": "MEMBER",
        "body": "I don't really have much experience with Parallel HDF5. However, from what I have read, it should be possible to use MPI to write in parallel. It would probably be too difficult to enforce collectivity, but that doesn't seem to be required for a basic write. That said, we would still need to fix the lock issue.\r\n\r\nWe probably cannot generally assume that most people wanting to use `to_hdf5` are using MPI (there are a few hoops for the average user). That said, I agree there would be a lot of value in making sure that the solution to this problem remains MPI friendly. We could add a flag to disable locking (with locking enabled by default). Alternatively we can try to detect whether the user is running with MPI. I have a slight preference for the former (flag-based) solution, but could be convinced otherwise.\r\n\r\nAny other suggestions about improving the MPI friendliness of `to_hdf5`?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/358202223/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/358305888",
        "html_url": "https://github.com/dask/dask/issues/3074#issuecomment-358305888",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/3074",
        "id": 358305888,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODMwNTg4OA==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-01-17T13:35:11Z",
        "updated_at": "2018-01-17T13:35:11Z",
        "author_association": "MEMBER",
        "body": "> That said, it should be feasible to change to_hdf5's behavior to be more friendly for storage from multiple processes (though it will still need to be locked). In this case, it would still create the datasets initially (as it already does), but then would close the file. Instead of passing raw HDF5 Datasets as targets, a wrapper class would need to be used (to allow for pickling). The wrapper class would need to provide a __setitem__ method that would open the HDF5 file and write to the HDF5 Dataset at the selection specified in a process safe manner (probably with locket.lock_file). Ideally it would provide a __getitem__ method as well. Doing this should allow for HDF5 file to be written to in parallel. This assumes the filesystem is very robust and syncing changes between different nodes.\r\n\r\nThis is a decent option.  We could also pass the path and datapath as part of the task.  We might also want to cache the h5py file objects in some sort of LRU cache.\r\n\r\nIt's worth noting that XArray has solved this problem.  Honestly the fact that XArray exists is probably why no one has spent much time on this topic historically.  We should still have a pure-dask.array solution though.  We might want to look at what they do.\r\n\r\n> An alternative to this proposal that would avoid locking would be to have data serialized back to the scheduler, which then writes each piece to the HDF5 file as it arrives. \r\n\r\nI'm -1 on this.  It doesn't scale well and the scheduler shouldn't get bogged down.\r\n\r\n> Can I avoid this problem if I use the MPI scheduler?  h5py says it supports parallel hdf5.\r\n\r\nNo.  There is no MPI scheduler.  As stated in [the docs](http://dask.pydata.org/en/latest/setup/hpc.html#using-mpi) dask-mpi only uses MPI to set up dask workers, and not for inter-worker communication.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/358305888/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/358306233",
        "html_url": "https://github.com/dask/dask/issues/3074#issuecomment-358306233",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/3074",
        "id": 358306233,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODMwNjIzMw==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-01-17T13:36:34Z",
        "updated_at": "2018-01-17T14:29:51Z",
        "author_association": "MEMBER",
        "body": "Generally it would be great to improve `to_hdf5`.  There is some good discussion on this topic on this XArray issue.  https://github.com/pydata/xarray/issues/798#issuecomment-199545836",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/358306233/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/358455007",
        "html_url": "https://github.com/dask/dask/issues/3074#issuecomment-358455007",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/3074",
        "id": 358455007,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODQ1NTAwNw==",
        "user": {
            "login": "jakirkham",
            "id": 3019665,
            "node_id": "MDQ6VXNlcjMwMTk2NjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3019665?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jakirkham",
            "html_url": "https://github.com/jakirkham",
            "followers_url": "https://api.github.com/users/jakirkham/followers",
            "following_url": "https://api.github.com/users/jakirkham/following{/other_user}",
            "gists_url": "https://api.github.com/users/jakirkham/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jakirkham/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jakirkham/subscriptions",
            "organizations_url": "https://api.github.com/users/jakirkham/orgs",
            "repos_url": "https://api.github.com/users/jakirkham/repos",
            "events_url": "https://api.github.com/users/jakirkham/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jakirkham/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-01-17T21:36:47Z",
        "updated_at": "2018-01-17T21:36:47Z",
        "author_association": "MEMBER",
        "body": "Thanks for the thoughts.\r\n\r\nAn LRU cache definitely makes sense for reading. I think that is what the `h5pickle` project did. Believe the author was interested in contributing that back to Dask. So we definitely can follow-up on that.\r\n\r\nAm a little nervous using an LRU cache for writing though. Have corrupted an HDF5 file before during testing by merely opening the file in append mode and reading from it in multiple processes. So would certainly appreciate any elucidation you might have on this point (assuming I'm understanding the implication correctly).\r\n\r\nWould be remiss if I didn't mention @martindurant's comment about `dask.dataframe` writing from multiple workers behaving correctly. Perhaps we don't need `lockfile` and can just [copy that strategy]( https://github.com/dask/dask/blob/0.16.1/dask/dataframe/io/hdf.py#L163-L180 ) over as he suggested.\r\n\r\nAgree that writing from the scheduler is suboptimal. However it can be handy if the underlying file system is a bit unreliable. Though I agree it is not the best direction.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/358455007/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/358521913",
        "html_url": "https://github.com/dask/dask/issues/3074#issuecomment-358521913",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/3074",
        "id": 358521913,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODUyMTkxMw==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-01-18T02:55:32Z",
        "updated_at": "2018-01-18T02:55:32Z",
        "author_association": "MEMBER",
        "body": "If we wanted to write from a single process sequentially then I would\nvolunteer one of the workers rather than the scheduler.\n\nI wonder if we can guarantee good behavior if we chunk the dask.array along\nthe hdf5 dataset chunks.  Perhaps that avoids the need for an inter-process\nlock and we can just get away with intra-process locks?\n\nOn Wed, Jan 17, 2018 at 4:36 PM, jakirkham <notifications@github.com> wrote:\n\n> Thanks for the thoughts.\n>\n> An LRU cache definitely makes sense for reading. I think that is what the\n> h5pickle project did. Believe the author was interested in contributing\n> that back to Dask. So we definitely can follow-up on that.\n>\n> Am a little nervous using an LRU cache for writing though. Have corrupted\n> an HDF5 file before during testing by merely opening the file in append\n> mode and reading from it in multiple processes. So would certainly\n> appreciate any elucidation you might have on this point (assuming I'm\n> understanding the implication correctly).\n>\n> Would be remiss if I didn't mention @martindurant\n> <https://github.com/martindurant>'s comment about dask.dataframe writing\n> from multiple workers behaving correctly. Perhaps we don't need lockfile\n> and can just copy that strategy\n> <https://github.com/dask/dask/blob/0.16.1/dask/dataframe/io/hdf.py#L163-L180>\n> over as he suggested.\n>\n> Agree that writing from the scheduler is suboptimal. However it can be\n> handy if the underlying file system is a bit unreliable. Though I agree it\n> is not the best direction.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/dask/dask/issues/3074#issuecomment-358455007>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/AASszKv1y-w3lh9rDy8qprvPYJ_pR04Fks5tLmfwgaJpZM4Rgqby>\n> .\n>\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/358521913/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/358676972",
        "html_url": "https://github.com/dask/dask/issues/3074#issuecomment-358676972",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/3074",
        "id": 358676972,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODY3Njk3Mg==",
        "user": {
            "login": "jakirkham",
            "id": 3019665,
            "node_id": "MDQ6VXNlcjMwMTk2NjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3019665?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jakirkham",
            "html_url": "https://github.com/jakirkham",
            "followers_url": "https://api.github.com/users/jakirkham/followers",
            "following_url": "https://api.github.com/users/jakirkham/following{/other_user}",
            "gists_url": "https://api.github.com/users/jakirkham/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jakirkham/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jakirkham/subscriptions",
            "organizations_url": "https://api.github.com/users/jakirkham/orgs",
            "repos_url": "https://api.github.com/users/jakirkham/repos",
            "events_url": "https://api.github.com/users/jakirkham/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jakirkham/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-01-18T15:14:40Z",
        "updated_at": "2018-01-18T15:14:40Z",
        "author_association": "MEMBER",
        "body": "Good point. Agreed. Am now wondering if we should persist the data and then have one worker write things out as soon as they complete.\r\n\r\nDon't think I'm following this second proposal. How are we handling the file handle constraints?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/358676972/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/358707717",
        "html_url": "https://github.com/dask/dask/issues/3074#issuecomment-358707717",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/3074",
        "id": 358707717,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODcwNzcxNw==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-01-18T16:49:13Z",
        "updated_at": "2018-01-18T16:49:13Z",
        "author_association": "MEMBER",
        "body": "My hope is that if we only write cleanly across blocks (no two processes\nwill write to the same block) then maybe we can avoid locking between\nprocesses and allow multi-process writes.  I don't know though.\n\nOn Thu, Jan 18, 2018 at 10:14 AM, jakirkham <notifications@github.com>\nwrote:\n\n> Good point. Agreed. Am now wondering if we should persist the data and\n> then have one worker write things out as soon as they complete.\n>\n> Don't think I'm following this second proposal. How are we handling the\n> file handle constraints?\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/dask/dask/issues/3074#issuecomment-358676972>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/AASszPmOzsCfTkYmw_0EcLWh0PMHt9Xyks5tL1_hgaJpZM4Rgqby>\n> .\n>\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/358707717/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/359030028",
        "html_url": "https://github.com/dask/dask/issues/3074#issuecomment-359030028",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/3074",
        "id": 359030028,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM1OTAzMDAyOA==",
        "user": {
            "login": "stuartarchibald",
            "id": 907717,
            "node_id": "MDQ6VXNlcjkwNzcxNw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/907717?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stuartarchibald",
            "html_url": "https://github.com/stuartarchibald",
            "followers_url": "https://api.github.com/users/stuartarchibald/followers",
            "following_url": "https://api.github.com/users/stuartarchibald/following{/other_user}",
            "gists_url": "https://api.github.com/users/stuartarchibald/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stuartarchibald/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stuartarchibald/subscriptions",
            "organizations_url": "https://api.github.com/users/stuartarchibald/orgs",
            "repos_url": "https://api.github.com/users/stuartarchibald/repos",
            "events_url": "https://api.github.com/users/stuartarchibald/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stuartarchibald/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-01-19T17:11:02Z",
        "updated_at": "2018-01-19T17:11:02Z",
        "author_association": "CONTRIBUTOR",
        "body": "I've just caught up with this, thanks @jakirkham for opening the ticket. Indeed, `to_hdf5()` just calls `store()` and does not work in the distributed context due to the use of threadlocals for the lock, I tried a `SerializableLock` and then IIRC the hdf5 object won't serialize instead. I guess I anticipated that there would be some coordinated write taking place whereby either a lock was passed around between processes and then file opening/closing plus the actual write happening from those processes. In practice I resorted to just materialising the `dask.array` data chunk-wise on a single process and writing those chunks to file as they appeared (I'd love a chunks API, but that's another story!).\r\n\r\nThe following is based on in part memory and in part a bit of looking through docs...\r\n\r\nThe hdf5 FAQ (https://support.hdfgroup.org/HDF5/hdf5-quest.html) mentions a few useful things:\r\n1. Concurrent access from multiple processes is fine if reading, if writing SWMR (single-write-multiple-read, pronounced \"swimmer\" apparently) can be used, but note the \"single-write\". https://support.hdfgroup.org/HDF5/hdf5-quest.html#gconc1 (http://docs.h5py.org/en/latest/swmr.html, www.hdfgroup.org/HDF5/docNewFeatures/NewFeaturesSwmrDocs.html).\r\n2. That MPI with MPI-I/O is needed for Parallel HDF5. https://support.hdfgroup.org/HDF5/hdf5-quest.html#pneed\r\n\r\nSo in terms of parallel writes to hdf5, I don't think this is possible without the use of `MPI` as it is `MPI-I/O` that coordinates this ability. Further, concurrent writes from multiple processes are not supported, but single writer multiple reader (SWMR) is. I think therefore locked and serialised write coordination would be needed across processes and but reads could be done simultaneously.\r\n\r\nWith a bit more thought, in terms of write from multiple processes, I guess one (somewhat complicated) way to achieve a faked-up MPI-I/O like parallel write would be for each process to open a hdf5 file for its chunk of data and write to it lock free. Then use that the hdf5 spec supports references to external data or Virtual Datasets (VDS) to assemble an agglomerating hdf5 file on the scheduler thread that references the per-process written data, this acting as a transparent entry point for future reads. There are however some restrictions on the types of data that can be used for VDS/external, some more info is here https://support.hdfgroup.org/HDF5/Tutor/vds.html and here https://support.hdfgroup.org/HDF5/Tutor/property.html#storage\r\n\r\nAs to the noted corruption from read whilst in append mode, the SWMR  interface may help http://docs.h5py.org/en/latest/swmr.html.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/359030028/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/359031283",
        "html_url": "https://github.com/dask/dask/issues/3074#issuecomment-359031283",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/3074",
        "id": 359031283,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM1OTAzMTI4Mw==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-01-19T17:15:29Z",
        "updated_at": "2018-01-19T17:15:29Z",
        "author_association": "MEMBER",
        "body": "Note that dask.distributed also has a distributed lock:\nhttp://distributed.readthedocs.io/en/latest/api.html#distributed.Lock\n\nOn Fri, Jan 19, 2018 at 11:11 AM, stuartarchibald <notifications@github.com>\nwrote:\n\n> I've just caught up with this, thanks @jakirkham\n> <https://github.com/jakirkham> for opening the ticket. Indeed, to_hdf5()\n> just calls store() and does not work in the distributed context due to\n> the use of threadlocals for the lock, I tried a SerializableLock and then\n> IIRC the hdf5 object won't serialize instead. I guess I anticipated that\n> there would be some coordinated write taking place whereby either a lock\n> was passed around between processes and then file opening/closing plus the\n> actual write happening from those processes. In practice I resorted to just\n> materialising the dask.array data chunk-wise on a single process and\n> writing those chunks to file as they appeared (I'd love a chunks API, but\n> that's another story!).\n>\n> The following is based on in part memory and in part a bit of looking\n> through docs...\n>\n> The hdf5 FAQ (https://support.hdfgroup.org/HDF5/hdf5-quest.html) mentions\n> a few useful things:\n>\n>    1. Concurrent access from multiple processes is fine if reading, if\n>    writing SWMR (single-write-multiple-read, pronounced \"swimmer\" apparently)\n>    can be used, but note the \"single-write\". https://support.hdfgroup.org/\n>    HDF5/hdf5-quest.html#gconc1 (http://docs.h5py.org/en/latest/swmr.html,\n>    www.hdfgroup.org/HDF5/docNewFeatures/NewFeaturesSwmrDocs.html\n>    <http://www.hdfgroup.org/HDF5/docNewFeatures/NewFeaturesSwmrDocs.html>\n>    ).\n>    2. That MPI with MPI-I/O is needed for Parallel HDF5.\n>    https://support.hdfgroup.org/HDF5/hdf5-quest.html#pneed\n>    <https://support.hdfgroup.org/HDF5/hdf5-quest.html#pneed>\n>\n> So in terms of parallel writes to hdf5, I don't think this is possible\n> without the use of MPI as it is MPI-I/O that coordinates this ability.\n> Further, concurrent writes from multiple processes are not supported, but\n> single writer multiple reader (SWMR) is. I think therefore locked and\n> serialised write coordination would be needed across processes and but\n> reads could be done simultaneously.\n>\n> With a bit more thought, in terms of write from multiple processes, I\n> guess one (somewhat complicated) way to achieve a faked-up MPI-I/O like\n> parallel write would be for each process to open a hdf5 file for its chunk\n> of data and write to it lock free. Then use that the hdf5 spec supports\n> references to external data or Virtual Datasets (VDS) to assemble an\n> agglomerating hdf5 file on the scheduler thread that references the\n> per-process written data, this acting as a transparent entry point for\n> future reads. There are however some restrictions on the types of data that\n> can be used for VDS/external, some more info is here\n> https://support.hdfgroup.org/HDF5/Tutor/vds.html and here\n> https://support.hdfgroup.org/HDF5/Tutor/property.html#storage\n>\n> As to the noted corruption from read whilst in append mode, the SWMR\n> interface may help http://docs.h5py.org/en/latest/swmr.html.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/dask/dask/issues/3074#issuecomment-359030028>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/AASszAvslwiGwn0PE_TEH_DKL9_RstZbks5tMMymgaJpZM4Rgqby>\n> .\n>\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/359031283/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/359031862",
        "html_url": "https://github.com/dask/dask/issues/3074#issuecomment-359031862",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/3074",
        "id": 359031862,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM1OTAzMTg2Mg==",
        "user": {
            "login": "stuartarchibald",
            "id": 907717,
            "node_id": "MDQ6VXNlcjkwNzcxNw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/907717?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stuartarchibald",
            "html_url": "https://github.com/stuartarchibald",
            "followers_url": "https://api.github.com/users/stuartarchibald/followers",
            "following_url": "https://api.github.com/users/stuartarchibald/following{/other_user}",
            "gists_url": "https://api.github.com/users/stuartarchibald/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stuartarchibald/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stuartarchibald/subscriptions",
            "organizations_url": "https://api.github.com/users/stuartarchibald/orgs",
            "repos_url": "https://api.github.com/users/stuartarchibald/repos",
            "events_url": "https://api.github.com/users/stuartarchibald/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stuartarchibald/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-01-19T17:17:31Z",
        "updated_at": "2018-01-19T17:17:31Z",
        "author_association": "CONTRIBUTOR",
        "body": "Thanks @mrocklin for https://github.com/dask/dask/issues/3074#issuecomment-359031283, perhaps I ought to try `store()` with that too. I'd still really like lock free parallel writes though!",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/359031862/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/359039123",
        "html_url": "https://github.com/dask/dask/issues/3074#issuecomment-359039123",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/3074",
        "id": 359039123,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM1OTAzOTEyMw==",
        "user": {
            "login": "jakirkham",
            "id": 3019665,
            "node_id": "MDQ6VXNlcjMwMTk2NjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3019665?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jakirkham",
            "html_url": "https://github.com/jakirkham",
            "followers_url": "https://api.github.com/users/jakirkham/followers",
            "following_url": "https://api.github.com/users/jakirkham/following{/other_user}",
            "gists_url": "https://api.github.com/users/jakirkham/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jakirkham/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jakirkham/subscriptions",
            "organizations_url": "https://api.github.com/users/jakirkham/orgs",
            "repos_url": "https://api.github.com/users/jakirkham/repos",
            "events_url": "https://api.github.com/users/jakirkham/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jakirkham/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-01-19T17:45:11Z",
        "updated_at": "2018-01-19T17:45:11Z",
        "author_association": "MEMBER",
        "body": "> I tried a `SerializableLock` and then IIRC the hdf5 object won't serialize instead.\r\n\r\nRight. So my thinking here is that we wrap up the opening and closing of the HDF5 File such that it only occurs when storing happens. This way we are only pickling the filename, datasetname, and some slice info about where to store each chunk.\r\n\r\n> In practice I resorted to just materialising the `dask.array` data chunk-wise on a single process and writing those chunks to file as they appeared\r\n\r\nThat was something Matt and I were talking about earlier in this thread. We could also submit this as a job, which would free you up to do other things while the result is serialized.\r\n\r\n> (I'd love a chunks API, but that's another story!).\r\n\r\nThere are a few tricks of the trade for this sort of stuff. Maybe we could do with some internal developer docs about how to work with chunks.\r\n\r\n> ...one (somewhat complicated) way to achieve a faked-up MPI-I/O like parallel write would be for each process to open a hdf5 file for its chunk of data and write to it lock free.\r\n\r\nHad also given this some thought more recently. We might be able to employ some tricks copying these chunks back into one HDF5 file also. Maybe a little less tricky than VDS.\r\n\r\n> I'd still really like lock free parallel writes though!\r\n\r\nPersonally have not found HDF5 satisfying in this regard. Would make another mention for Zarr here as that seems like a better fit. It was designed with Dask usage in mind. So avoids these pickling and locking issues that HDF5 bumps into.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/359039123/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/359045114",
        "html_url": "https://github.com/dask/dask/issues/3074#issuecomment-359045114",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/3074",
        "id": 359045114,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM1OTA0NTExNA==",
        "user": {
            "login": "stuartarchibald",
            "id": 907717,
            "node_id": "MDQ6VXNlcjkwNzcxNw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/907717?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stuartarchibald",
            "html_url": "https://github.com/stuartarchibald",
            "followers_url": "https://api.github.com/users/stuartarchibald/followers",
            "following_url": "https://api.github.com/users/stuartarchibald/following{/other_user}",
            "gists_url": "https://api.github.com/users/stuartarchibald/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stuartarchibald/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stuartarchibald/subscriptions",
            "organizations_url": "https://api.github.com/users/stuartarchibald/orgs",
            "repos_url": "https://api.github.com/users/stuartarchibald/repos",
            "events_url": "https://api.github.com/users/stuartarchibald/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stuartarchibald/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-01-19T18:08:12Z",
        "updated_at": "2018-01-19T18:08:12Z",
        "author_association": "CONTRIBUTOR",
        "body": "I've found `MPI-I/O` fine for parallel read/write but this is indeed an entirely different system. I appreciate that `Zarr` is almost certainly a better fit, but sometimes `HDF5` is a constraint applied by external factors. I'm of the view that if something can be done to make `to_hdf5` work better with distributed in the short term, even if that's just making it so that the writes work out of the box albeit in practice they are serial, then that is a good intermediate step. Long term I'd be interested in hearing about ideas of copying chunks into a single hdf5 file and how that compares to VDS.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/359045114/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/359128306",
        "html_url": "https://github.com/dask/dask/issues/3074#issuecomment-359128306",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/3074",
        "id": 359128306,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM1OTEyODMwNg==",
        "user": {
            "login": "jakirkham",
            "id": 3019665,
            "node_id": "MDQ6VXNlcjMwMTk2NjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3019665?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jakirkham",
            "html_url": "https://github.com/jakirkham",
            "followers_url": "https://api.github.com/users/jakirkham/followers",
            "following_url": "https://api.github.com/users/jakirkham/following{/other_user}",
            "gists_url": "https://api.github.com/users/jakirkham/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jakirkham/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jakirkham/subscriptions",
            "organizations_url": "https://api.github.com/users/jakirkham/orgs",
            "repos_url": "https://api.github.com/users/jakirkham/repos",
            "events_url": "https://api.github.com/users/jakirkham/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jakirkham/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-01-20T00:40:40Z",
        "updated_at": "2018-01-20T00:40:40Z",
        "author_association": "MEMBER",
        "body": "> I've found `MPI-I/O` fine for parallel read/write but this is indeed an entirely different system.\r\n\r\nI'm sure my experience would be different if I were using MPI-I/O.\r\n\r\n> I appreciate that `Zarr` is almost certainly a better fit, but sometimes `HDF5` is a constraint applied by external factors.\r\n\r\nI can definitely appreciate that. We still use HDF5 as a storage format. It remains a nice format that lots of people in different languages can read and write easily and there are some standards in my research community that have been built around it. So this is unlikely to change for me either.\r\n\r\nHowever when it comes to computing things with Dask, we convert everything into Zarr and only use Zarr until we are done. At which point it goes back into some HDF5 file that we share and/or store longer term. IOW Zarr is internal to our computational pipelines with the option to export to HDF5 wherever needed (typically the end).\r\n\r\nThere has been a lot of work in Zarr `master` (soon to be 2.2.0) to make sure that conversion between Zarr and HDF5 is pretty painless. Not really knowing your constraints, I don't know if this strategy would be a good fit for your use case. That said, if you think it might, would certainly encourage you to explore it further and ask questions as they arise.\r\n\r\n> I'm of the view that if something can be done to make `to_hdf5` work better with distributed in the short term, even if that's just making it so that the writes work out of the box albeit in practice they are serial, then that is a good intermediate step.\r\n\r\nGenerally I agree. Unfortunately, for me, short term would probably be in a month. Though I would be supportive of you or anyone pushing ahead on one of the ideas we have discussed.\r\n\r\n> Long term I'd be interested in hearing about ideas of copying chunks into a single hdf5 file and how that compares to VDS.\r\n\r\nSure. I guess let's wait and see how the short term solution goes.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/359128306/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/362812984",
        "html_url": "https://github.com/dask/dask/issues/3074#issuecomment-362812984",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/3074",
        "id": 362812984,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM2MjgxMjk4NA==",
        "user": {
            "login": "rzu512",
            "id": 32720823,
            "node_id": "MDQ6VXNlcjMyNzIwODIz",
            "avatar_url": "https://avatars.githubusercontent.com/u/32720823?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rzu512",
            "html_url": "https://github.com/rzu512",
            "followers_url": "https://api.github.com/users/rzu512/followers",
            "following_url": "https://api.github.com/users/rzu512/following{/other_user}",
            "gists_url": "https://api.github.com/users/rzu512/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rzu512/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rzu512/subscriptions",
            "organizations_url": "https://api.github.com/users/rzu512/orgs",
            "repos_url": "https://api.github.com/users/rzu512/repos",
            "events_url": "https://api.github.com/users/rzu512/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rzu512/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-02-03T14:24:10Z",
        "updated_at": "2018-02-03T14:24:10Z",
        "author_association": "NONE",
        "body": "Can this approach handle a Dask array that has `np.nan` in chunks?\r\nThe method mentioned [here](https://clouds.eos.ubc.ca/~phil/courses/parallel_python/03_dask_and_zarr.html) seems to not work for this case.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/362812984/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/366576952",
        "html_url": "https://github.com/dask/dask/issues/3074#issuecomment-366576952",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/3074",
        "id": 366576952,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM2NjU3Njk1Mg==",
        "user": {
            "login": "jakirkham",
            "id": 3019665,
            "node_id": "MDQ6VXNlcjMwMTk2NjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3019665?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jakirkham",
            "html_url": "https://github.com/jakirkham",
            "followers_url": "https://api.github.com/users/jakirkham/followers",
            "following_url": "https://api.github.com/users/jakirkham/following{/other_user}",
            "gists_url": "https://api.github.com/users/jakirkham/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jakirkham/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jakirkham/subscriptions",
            "organizations_url": "https://api.github.com/users/jakirkham/orgs",
            "repos_url": "https://api.github.com/users/jakirkham/repos",
            "events_url": "https://api.github.com/users/jakirkham/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jakirkham/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-02-19T02:51:51Z",
        "updated_at": "2018-02-19T02:51:51Z",
        "author_association": "MEMBER",
        "body": "Ultimately working with Arrays of unknown shape would be difficult. How would you propose allocating an adequately sized HDF5 Dataset?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/366576952/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/366580037",
        "html_url": "https://github.com/dask/dask/issues/3074#issuecomment-366580037",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/3074",
        "id": 366580037,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM2NjU4MDAzNw==",
        "user": {
            "login": "jakirkham",
            "id": 3019665,
            "node_id": "MDQ6VXNlcjMwMTk2NjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3019665?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jakirkham",
            "html_url": "https://github.com/jakirkham",
            "followers_url": "https://api.github.com/users/jakirkham/followers",
            "following_url": "https://api.github.com/users/jakirkham/following{/other_user}",
            "gists_url": "https://api.github.com/users/jakirkham/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jakirkham/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jakirkham/subscriptions",
            "organizations_url": "https://api.github.com/users/jakirkham/orgs",
            "repos_url": "https://api.github.com/users/jakirkham/repos",
            "events_url": "https://api.github.com/users/jakirkham/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jakirkham/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-02-19T03:20:53Z",
        "updated_at": "2018-02-19T03:20:53Z",
        "author_association": "MEMBER",
        "body": "Thought about writing an idea down and decided it was easier to write code. Put an RFC of how we might tackle this problem in PR ( https://github.com/dask/dask/pull/3179 ). Would be great to hear some feedback on it.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/366580037/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/372213197",
        "html_url": "https://github.com/dask/dask/issues/3074#issuecomment-372213197",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/3074",
        "id": 372213197,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM3MjIxMzE5Nw==",
        "user": {
            "login": "jakirkham",
            "id": 3019665,
            "node_id": "MDQ6VXNlcjMwMTk2NjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3019665?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jakirkham",
            "html_url": "https://github.com/jakirkham",
            "followers_url": "https://api.github.com/users/jakirkham/followers",
            "following_url": "https://api.github.com/users/jakirkham/following{/other_user}",
            "gists_url": "https://api.github.com/users/jakirkham/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jakirkham/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jakirkham/subscriptions",
            "organizations_url": "https://api.github.com/users/jakirkham/orgs",
            "repos_url": "https://api.github.com/users/jakirkham/repos",
            "events_url": "https://api.github.com/users/jakirkham/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jakirkham/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-03-12T07:15:53Z",
        "updated_at": "2018-03-12T07:15:53Z",
        "author_association": "MEMBER",
        "body": "We could also consider an entirely different approach if we could guarantee there is a `Client`. Might provide some impetus to think about issue ( https://github.com/dask/dask/issues/3237 ). ;) Namely we could `persist` the Dask Array and then pass all the Futures to one Dask job, which could then write them out as they arrive. This would avoid having a file lock and would allow the HDF5 file to only be opened once by one worker. Other safety measures could be added here like writing to a temp file that gets moved to the right location only when it is done. Of course this wouldn't allow parallel writes; though, neither does the strategy in PR ( https://github.com/dask/dask/pull/3179 ).\r\n\r\ncc @shoyer @jhamman",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/372213197/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/372218212",
        "html_url": "https://github.com/dask/dask/issues/3074#issuecomment-372218212",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/3074",
        "id": 372218212,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM3MjIxODIxMg==",
        "user": {
            "login": "jakirkham",
            "id": 3019665,
            "node_id": "MDQ6VXNlcjMwMTk2NjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3019665?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jakirkham",
            "html_url": "https://github.com/jakirkham",
            "followers_url": "https://api.github.com/users/jakirkham/followers",
            "following_url": "https://api.github.com/users/jakirkham/following{/other_user}",
            "gists_url": "https://api.github.com/users/jakirkham/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jakirkham/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jakirkham/subscriptions",
            "organizations_url": "https://api.github.com/users/jakirkham/orgs",
            "repos_url": "https://api.github.com/users/jakirkham/repos",
            "events_url": "https://api.github.com/users/jakirkham/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jakirkham/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-03-12T07:42:14Z",
        "updated_at": "2018-03-12T07:42:14Z",
        "author_association": "MEMBER",
        "body": "On a different note, took a look at what support for VDS was in h5py and it seems there has been an attempt to add Python support for this, but it is incomplete. That said, we could certainly explore a simple solution along these lines (an HDF5 file per chunk) as Dask can already help do the legwork for this sort of thing without too much trouble. This would allow parallel reading and writing as a direct consequence of using multiple files. Though keeping track of these files would come with some overhead.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/372218212/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/372454727",
        "html_url": "https://github.com/dask/dask/issues/3074#issuecomment-372454727",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/3074",
        "id": 372454727,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM3MjQ1NDcyNw==",
        "user": {
            "login": "jhamman",
            "id": 2443309,
            "node_id": "MDQ6VXNlcjI0NDMzMDk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2443309?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jhamman",
            "html_url": "https://github.com/jhamman",
            "followers_url": "https://api.github.com/users/jhamman/followers",
            "following_url": "https://api.github.com/users/jhamman/following{/other_user}",
            "gists_url": "https://api.github.com/users/jhamman/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jhamman/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jhamman/subscriptions",
            "organizations_url": "https://api.github.com/users/jhamman/orgs",
            "repos_url": "https://api.github.com/users/jhamman/repos",
            "events_url": "https://api.github.com/users/jhamman/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jhamman/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-03-12T20:39:37Z",
        "updated_at": "2018-03-12T20:39:37Z",
        "author_association": "MEMBER",
        "body": "From, my perspective, streaming computed arrays when using `distributed` to a single writer would be a nice compromise here. I'm not sure what machinery would be needed to make that happen but I can vouch for its potential application. \r\n\r\nIn terms of virtual datasets, I'm headed this way with xarray as well. In our case we can use `save_mfdataset(datasets, paths)` to enable parallel writing to separate files. `datasets` would be some partitioned version of a single `xarray.Dataset` made up of dask arrays. ",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/372454727/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/377661634",
        "html_url": "https://github.com/dask/dask/issues/3074#issuecomment-377661634",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/3074",
        "id": 377661634,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM3NzY2MTYzNA==",
        "user": {
            "login": "jakirkham",
            "id": 3019665,
            "node_id": "MDQ6VXNlcjMwMTk2NjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3019665?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jakirkham",
            "html_url": "https://github.com/jakirkham",
            "followers_url": "https://api.github.com/users/jakirkham/followers",
            "following_url": "https://api.github.com/users/jakirkham/following{/other_user}",
            "gists_url": "https://api.github.com/users/jakirkham/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jakirkham/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jakirkham/subscriptions",
            "organizations_url": "https://api.github.com/users/jakirkham/orgs",
            "repos_url": "https://api.github.com/users/jakirkham/repos",
            "events_url": "https://api.github.com/users/jakirkham/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jakirkham/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-03-31T03:12:39Z",
        "updated_at": "2018-03-31T03:12:39Z",
        "author_association": "MEMBER",
        "body": "It\u2019s worth noting that Zarr has support for copying data into HDF5 files.\n\nref: http://zarr.readthedocs.io/en/stable/api/convenience.html#zarr.convenience.copy",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/377661634/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 1,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]