{
    "url": "https://api.github.com/repos/dask/dask/issues/8829",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/8829/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/8829/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/8829/events",
    "html_url": "https://github.com/dask/dask/issues/8829",
    "id": 1174841234,
    "node_id": "I_kwDOAbcwm85GBqeS",
    "number": 8829,
    "title": "dask DataFrame.read_parquet doesn't preserve the paths order",
    "user": {
        "login": "rajeee",
        "id": 12487392,
        "node_id": "MDQ6VXNlcjEyNDg3Mzky",
        "avatar_url": "https://avatars.githubusercontent.com/u/12487392?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/rajeee",
        "html_url": "https://github.com/rajeee",
        "followers_url": "https://api.github.com/users/rajeee/followers",
        "following_url": "https://api.github.com/users/rajeee/following{/other_user}",
        "gists_url": "https://api.github.com/users/rajeee/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/rajeee/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/rajeee/subscriptions",
        "organizations_url": "https://api.github.com/users/rajeee/orgs",
        "repos_url": "https://api.github.com/users/rajeee/repos",
        "events_url": "https://api.github.com/users/rajeee/events{/privacy}",
        "received_events_url": "https://api.github.com/users/rajeee/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        },
        {
            "id": 2949099791,
            "node_id": "MDU6TGFiZWwyOTQ5MDk5Nzkx",
            "url": "https://api.github.com/repos/dask/dask/labels/parquet",
            "name": "parquet",
            "color": "77A66C",
            "default": false,
            "description": ""
        },
        {
            "id": 3798450420,
            "node_id": "LA_kwDOAbcwm87iZ8D0",
            "url": "https://api.github.com/repos/dask/dask/labels/feature",
            "name": "feature",
            "color": "b0f0fa",
            "default": false,
            "description": "Something is missing"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 13,
    "created_at": "2022-03-21T03:31:49Z",
    "updated_at": "2022-03-25T21:28:28Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**What happened**:\r\nDask doesn't honor the order of files listed in the path\r\n\r\n**What you expected to happen**:\r\nI would have expected the partition ordering to be consistent with list of paths in read_parquet. Seems like the input path is automatically sorted internally without choice. \r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport dask.dataframe as dd\r\nimport pandas as pd\r\ndf1=pd.DataFrame({'i': [1, 1], 'A': [1.0, 2.0], 'B': [11.0, 12.0]})\r\ndf1.to_parquet(\"df1.parquet\")\r\ndf2=pd.DataFrame({'i': [0, 0], 'A':  [3.0, 4.0], 'B': [13.0, 14.0]})\r\ndf2.to_parquet(\"df2.parquet\")\r\nforward_df = dd.read_parquet([\"df1.parquet\", \"df2.parquet\"], engine='pyarrow')\r\nreverse_df = dd.read_parquet([\"df2.parquet\", \"df1.parquet\"], engine='pyarrow')\r\nforward_df.npartitions  # 2\r\nreverse_df.npartitions  # 2\r\n\r\nforward_df.get_partition(0).compute() # returns df1\r\nreverse_df.get_partition(0).compute() # Also returns df1. Expected to return df2\r\n\r\n\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\n**Environment**:\r\n\r\n- Dask version:\r\n- Python version:\r\n- Operating System:\r\n- Install method (conda, pip, source):\r\n\r\n<!-- If you are reporting an issue such as scale stability, cluster deadlock.\r\nPlease provide a cluster dump state with this issue, by running client.dump_cluster_state()\r\n\r\nhttps://distributed.dask.org/en/stable/api.html?highlight=dump_cluster_state#distributed.Client.dump_cluster_state\r\n\r\n-->\r\n\r\n<details>\r\n<summary>Cluster Dump State:</summary>\r\n\r\n</details>",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/8829/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/8829/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}