{
    "url": "https://api.github.com/repos/dask/dask/issues/10237",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/10237/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/10237/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/10237/events",
    "html_url": "https://github.com/dask/dask/pull/10237",
    "id": 1688616850,
    "node_id": "PR_kwDOAbcwm85PY8Rs",
    "number": 10237,
    "title": "Array.vindex performance improvements",
    "user": {
        "login": "greg9q",
        "id": 9966211,
        "node_id": "MDQ6VXNlcjk5NjYyMTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/9966211?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/greg9q",
        "html_url": "https://github.com/greg9q",
        "followers_url": "https://api.github.com/users/greg9q/followers",
        "following_url": "https://api.github.com/users/greg9q/following{/other_user}",
        "gists_url": "https://api.github.com/users/greg9q/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/greg9q/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/greg9q/subscriptions",
        "organizations_url": "https://api.github.com/users/greg9q/orgs",
        "repos_url": "https://api.github.com/users/greg9q/repos",
        "events_url": "https://api.github.com/users/greg9q/events{/privacy}",
        "received_events_url": "https://api.github.com/users/greg9q/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862305,
            "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=",
            "url": "https://api.github.com/repos/dask/dask/labels/array",
            "name": "array",
            "color": "006b75",
            "default": false,
            "description": null
        },
        {
            "id": 3468123446,
            "node_id": "LA_kwDOAbcwm87Ot102",
            "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention",
            "name": "needs attention",
            "color": "6d626c",
            "default": false,
            "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-04-28T14:01:17Z",
    "updated_at": "2023-05-29T01:58:03Z",
    "closed_at": null,
    "author_association": "FIRST_TIME_CONTRIBUTOR",
    "active_lock_reason": null,
    "draft": false,
    "pull_request": {
        "url": "https://api.github.com/repos/dask/dask/pulls/10237",
        "html_url": "https://github.com/dask/dask/pull/10237",
        "diff_url": "https://github.com/dask/dask/pull/10237.diff",
        "patch_url": "https://github.com/dask/dask/pull/10237.patch",
        "merged_at": null
    },
    "body": "This is a patch to `Array.vindex` that aims to:\r\n1. Cut down on how long it takes to build the task graph\r\n2. Reduce memory usage in some cases by avoiding copies of the index arrays\r\n\r\nFor execute time, I used the following code as a simple benchmark:\r\n```python\r\nimport dask.array as da\r\nimport numpy as np\r\narr_1 = da.ones([6000, 6000], chunks=[3000, 3000])  # 36M elements in 4 chunks\r\nidx = np.repeat(np.arange(0, 6000, 6), 1000)  # 1M index points\r\narr_2 = arr_1.vindex[idx, idx[::-1]]\r\n```\r\n\r\nBefore this change the last line took 2.47s of wall clock time to execute. With this change it takes 22.1ms.\r\n\r\nRegarding memory usage, I was motivated by my use case which involves accessing NetCDF files via Xarray and using `xarray.Dataset.isel`, which under the hood calls `da.Array.vindex` on many arrays using the same index values. The current `vindex` implementation always stores copies of the index arrays in the task graph, so an `isel` call could cause many index array copies to accumulate. This change stores the passed-in index arrays directly in the task graph, if possible.\r\n\r\nThis implementation essentially works the same way as the existing one, it just handles the bookkeeping data structures a bit differently. One consequence is that some of the index processing that used to happen when building the graph now happens at graph execution time. Nonetheless, in my testing graph execution performance also seems to have improved a bit: wall time for `arr_2.compute()` from the snippet above dropped from 632ms to 118ms.\r\n\r\nI don't have much experience with Dask internals, but I hope this is a workable solution. Also, a couple questions:\r\n1. Is it ok to store the passed-in index arrays directly in the task graph like this? If the caller goes on to mutate these arrays, this could cause surprising results. If it's not ok it'd be easy to change the code to make a copy and still benefit from the speedup. But I suspect it is ok, since a similar situation results just from calling `da.from_array` on a NumPy array.\r\n2. From profing `vindex` I can see that more than half its time is now being spent hashing the index arrays in order to assign key names to graph nodes. Are there any alternatives for generating keys in this type of situation?",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/10237/reactions",
        "total_count": 3,
        "+1": 3,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/10237/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}