[
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/163385370",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-163385370",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 163385370,
        "node_id": "MDEyOklzc3VlQ29tbWVudDE2MzM4NTM3MA==",
        "user": {
            "login": "jcrist",
            "id": 2783717,
            "node_id": "MDQ6VXNlcjI3ODM3MTc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2783717?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jcrist",
            "html_url": "https://github.com/jcrist",
            "followers_url": "https://api.github.com/users/jcrist/followers",
            "following_url": "https://api.github.com/users/jcrist/following{/other_user}",
            "gists_url": "https://api.github.com/users/jcrist/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jcrist/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jcrist/subscriptions",
            "organizations_url": "https://api.github.com/users/jcrist/orgs",
            "repos_url": "https://api.github.com/users/jcrist/repos",
            "events_url": "https://api.github.com/users/jcrist/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jcrist/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2015-12-09T20:39:20Z",
        "updated_at": "2015-12-09T20:44:33Z",
        "author_association": "MEMBER",
        "body": "If `np.ones` is added to the set of `fast_functions`, then the graph looks like:\n\n![mydask](https://cloud.githubusercontent.com/assets/2783717/11698046/65e3a0d6-9e82-11e5-99c1-b6b9264e7c1c.png)\n\nThis results in the desired scheduler behavior. In general, we can't assume that recomputing the initial chunks is fast, but for things like `getarray`, this should be fine. We should also somehow forward kwargs to optimize. `dask.array.optimization.optimize` accepts `fast_functions` as a keyword, but the scheduler `get` doesn't forward it.\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/163385370/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/163389748",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-163389748",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 163389748,
        "node_id": "MDEyOklzc3VlQ29tbWVudDE2MzM4OTc0OA==",
        "user": {
            "login": "jcrist",
            "id": 2783717,
            "node_id": "MDQ6VXNlcjI3ODM3MTc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2783717?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jcrist",
            "html_url": "https://github.com/jcrist",
            "followers_url": "https://api.github.com/users/jcrist/followers",
            "following_url": "https://api.github.com/users/jcrist/following{/other_user}",
            "gists_url": "https://api.github.com/users/jcrist/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jcrist/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jcrist/subscriptions",
            "organizations_url": "https://api.github.com/users/jcrist/orgs",
            "repos_url": "https://api.github.com/users/jcrist/repos",
            "events_url": "https://api.github.com/users/jcrist/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jcrist/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2015-12-09T20:57:54Z",
        "updated_at": "2015-12-09T20:57:54Z",
        "author_association": "MEMBER",
        "body": "Currently `threaded.get`, `multiprocessing.get` share some keywords, and have some other keywords that are specific to each scheduler. `array.optimize` takes a few keywords, while `dataframe.optimize` takes none. However, all of them have spots for `**kwargs`, which means that excess keywords are simply ignored. Thus, we could forward all keywords from `expr.get(...)` to both the call to `optimize` and `get`, and everything would be fine. Not sure if this is the best way, but it would work.\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/163389748/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/163389814",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-163389814",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 163389814,
        "node_id": "MDEyOklzc3VlQ29tbWVudDE2MzM4OTgxNA==",
        "user": {
            "login": "shoyer",
            "id": 1217238,
            "node_id": "MDQ6VXNlcjEyMTcyMzg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1217238?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/shoyer",
            "html_url": "https://github.com/shoyer",
            "followers_url": "https://api.github.com/users/shoyer/followers",
            "following_url": "https://api.github.com/users/shoyer/following{/other_user}",
            "gists_url": "https://api.github.com/users/shoyer/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/shoyer/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/shoyer/subscriptions",
            "organizations_url": "https://api.github.com/users/shoyer/orgs",
            "repos_url": "https://api.github.com/users/shoyer/repos",
            "events_url": "https://api.github.com/users/shoyer/events{/privacy}",
            "received_events_url": "https://api.github.com/users/shoyer/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2015-12-09T20:58:11Z",
        "updated_at": "2015-12-09T20:58:11Z",
        "author_association": "MEMBER",
        "body": "In general, it's probably not a good idea to assume that loading data from disk is \"fast\", although it's certainly a preferable alternative to exhausting memory.\n\nIt would be nice if we could setup dask to recompute chunks once they start to overflow some memory threshold, which might default to some fraction of the available system memory. The challenge then is figuring out which chunks to throw away. Cachey might have most of the appropriate logic for this.\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/163389814/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/163390034",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-163390034",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 163390034,
        "node_id": "MDEyOklzc3VlQ29tbWVudDE2MzM5MDAzNA==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2015-12-09T20:59:08Z",
        "updated_at": "2015-12-09T20:59:08Z",
        "author_association": "MEMBER",
        "body": "It would be an interesting intellectual exercise on how to do this generally.  \n\nAny thoughts on how we could solve this problem if we tracked number of bytes of each output and computation times?\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/163390034/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/163391593",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-163391593",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 163391593,
        "node_id": "MDEyOklzc3VlQ29tbWVudDE2MzM5MTU5Mw==",
        "user": {
            "login": "jcrist",
            "id": 2783717,
            "node_id": "MDQ6VXNlcjI3ODM3MTc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2783717?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jcrist",
            "html_url": "https://github.com/jcrist",
            "followers_url": "https://api.github.com/users/jcrist/followers",
            "following_url": "https://api.github.com/users/jcrist/following{/other_user}",
            "gists_url": "https://api.github.com/users/jcrist/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jcrist/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jcrist/subscriptions",
            "organizations_url": "https://api.github.com/users/jcrist/orgs",
            "repos_url": "https://api.github.com/users/jcrist/repos",
            "events_url": "https://api.github.com/users/jcrist/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jcrist/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2015-12-09T21:05:53Z",
        "updated_at": "2015-12-09T21:07:33Z",
        "author_association": "MEMBER",
        "body": "One thought would be to pass in a `cache` object to replace the dictionary that is used by default. Upon overflow, a decision could be made to drop a cheap result, with a callback on `getitem` setup  to recompute it (based on the graph). A good metric might be dumping large things that would be quick to recompute from things currently in the cache (possibly `min(C1*compute_time + C2/memory_used)`). Could be done with a mix of callbacks, and a `MutableMapping` object.\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/163391593/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/163392877",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-163392877",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 163392877,
        "node_id": "MDEyOklzc3VlQ29tbWVudDE2MzM5Mjg3Nw==",
        "user": {
            "login": "shoyer",
            "id": 1217238,
            "node_id": "MDQ6VXNlcjEyMTcyMzg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1217238?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/shoyer",
            "html_url": "https://github.com/shoyer",
            "followers_url": "https://api.github.com/users/shoyer/followers",
            "following_url": "https://api.github.com/users/shoyer/following{/other_user}",
            "gists_url": "https://api.github.com/users/shoyer/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/shoyer/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/shoyer/subscriptions",
            "organizations_url": "https://api.github.com/users/shoyer/orgs",
            "repos_url": "https://api.github.com/users/shoyer/repos",
            "events_url": "https://api.github.com/users/shoyer/events{/privacy}",
            "received_events_url": "https://api.github.com/users/shoyer/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2015-12-09T21:11:09Z",
        "updated_at": "2015-12-09T21:11:09Z",
        "author_association": "MEMBER",
        "body": "Yes, I think dask.cache/cachey already uses a roughly appropriate metric.\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/163392877/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292553242",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292553242",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292553242,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU1MzI0Mg==",
        "user": {
            "login": "pwolfram",
            "id": 4295853,
            "node_id": "MDQ6VXNlcjQyOTU4NTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4295853?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pwolfram",
            "html_url": "https://github.com/pwolfram",
            "followers_url": "https://api.github.com/users/pwolfram/followers",
            "following_url": "https://api.github.com/users/pwolfram/following{/other_user}",
            "gists_url": "https://api.github.com/users/pwolfram/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pwolfram/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pwolfram/subscriptions",
            "organizations_url": "https://api.github.com/users/pwolfram/orgs",
            "repos_url": "https://api.github.com/users/pwolfram/repos",
            "events_url": "https://api.github.com/users/pwolfram/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pwolfram/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T14:33:41Z",
        "updated_at": "2017-04-07T14:33:41Z",
        "author_association": "CONTRIBUTOR",
        "body": "From http://xarray.pydata.org/en/stable/dask.html\r\n\r\n> in practice this is a fail case for the dask scheduler, because it tries to keep every chunk of an array that it computes in memory\r\n\r\n@shoyer, does this imply that memory usage for computation of the mean is linearly dependent upon number of the unlimited dimension?  We are having challenging memory issues with computing the mean for large spatial resolution datasets for short and long time record datasets.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292553242/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292555895",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292555895",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292555895,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU1NTg5NQ==",
        "user": {
            "login": "pwolfram",
            "id": 4295853,
            "node_id": "MDQ6VXNlcjQyOTU4NTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4295853?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pwolfram",
            "html_url": "https://github.com/pwolfram",
            "followers_url": "https://api.github.com/users/pwolfram/followers",
            "following_url": "https://api.github.com/users/pwolfram/following{/other_user}",
            "gists_url": "https://api.github.com/users/pwolfram/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pwolfram/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pwolfram/subscriptions",
            "organizations_url": "https://api.github.com/users/pwolfram/orgs",
            "repos_url": "https://api.github.com/users/pwolfram/repos",
            "events_url": "https://api.github.com/users/pwolfram/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pwolfram/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T14:43:01Z",
        "updated_at": "2017-04-07T14:43:01Z",
        "author_association": "CONTRIBUTOR",
        "body": "In xarray-space is there a way I can get the same behavior as a \r\n`ds = xr.open_dataset(ds.to_netcdf(tmpfile))`\r\nwithout actually resorting to this type of trick, e.g., can we just explicitly force dask to flush its memory cache or something?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292555895/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292557236",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292557236",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292557236,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU1NzIzNg==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T14:47:51Z",
        "updated_at": "2017-04-07T14:47:51Z",
        "author_association": "MEMBER",
        "body": "Computing the mean shouldn't be hard.  The problem arises when you have a large array interact with the mean, like the following:\r\n\r\n    (x - x.mean()).sum().compute()\r\n\r\nThe current workaround is to explicitly compute the mean beforehand\r\n\r\n    (x - x.mean().compute()).sum().compute()\r\n\r\nThis will require two passes over the data\r\n\r\nNote that this problem should only be an issue if you don't have enough memory.  If you were on a distributed system this might not be an issue.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292557236/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292559014",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292559014",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292559014,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU1OTAxNA==",
        "user": {
            "login": "pwolfram",
            "id": 4295853,
            "node_id": "MDQ6VXNlcjQyOTU4NTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4295853?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pwolfram",
            "html_url": "https://github.com/pwolfram",
            "followers_url": "https://api.github.com/users/pwolfram/followers",
            "following_url": "https://api.github.com/users/pwolfram/following{/other_user}",
            "gists_url": "https://api.github.com/users/pwolfram/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pwolfram/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pwolfram/subscriptions",
            "organizations_url": "https://api.github.com/users/pwolfram/orgs",
            "repos_url": "https://api.github.com/users/pwolfram/repos",
            "events_url": "https://api.github.com/users/pwolfram/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pwolfram/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T14:54:25Z",
        "updated_at": "2017-04-07T14:54:25Z",
        "author_association": "CONTRIBUTOR",
        "body": "@mrocklin, the problem is exactly as you imply but we have the limitation that we are trying really hard to keep compute cost down so `dask.distributed` isn't ideal in this application.  It certainly is ideal and arguably *necessary* for analysis with particles and not Eulerian means, although I'm not quite there yet but should be working on that in the next several months (likely June or July).  \r\n\r\nFor `(x - x.mean().compute()).sum().compute()` above what this means is that we would have to have enough memory to store `x.mean()` twice plus say 2-3X a chunk size, correct?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292559014/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292560898",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292560898",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292560898,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU2MDg5OA==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T15:01:06Z",
        "updated_at": "2017-04-07T15:01:06Z",
        "author_association": "MEMBER",
        "body": "Storing `x.mean()` twice is 16 bytes.  Given your question I'm guessing that you're storing `x.mean(axis=...)`.  Are you having trouble computing just that value or are you having trouble computing just the reduction or are you having trouble computing a compound expression like `(x - x.mean().compute()).sum().compute()`?\r\n\r\nYou should always have significantly more memory than your chunk size.  How much RAM do you have?  What are your chunk sizes?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292560898/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292561090",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292561090",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292561090,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU2MTA5MA==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T15:01:41Z",
        "updated_at": "2017-04-07T15:01:41Z",
        "author_association": "MEMBER",
        "body": "For reference.  My notebook has 16GB of memory and I probably shoot for chunk sizes in the 100 MB range.  There is about a 100x gap there.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292561090/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292565097",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292565097",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292565097,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU2NTA5Nw==",
        "user": {
            "login": "pwolfram",
            "id": 4295853,
            "node_id": "MDQ6VXNlcjQyOTU4NTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4295853?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pwolfram",
            "html_url": "https://github.com/pwolfram",
            "followers_url": "https://api.github.com/users/pwolfram/followers",
            "following_url": "https://api.github.com/users/pwolfram/following{/other_user}",
            "gists_url": "https://api.github.com/users/pwolfram/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pwolfram/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pwolfram/subscriptions",
            "organizations_url": "https://api.github.com/users/pwolfram/orgs",
            "repos_url": "https://api.github.com/users/pwolfram/repos",
            "events_url": "https://api.github.com/users/pwolfram/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pwolfram/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T15:16:09Z",
        "updated_at": "2017-04-07T15:16:09Z",
        "author_association": "CONTRIBUTOR",
        "body": "Thanks @mrocklin for the quick reply.  We are storing `x.mean(axis=...)` along the time axis, which has large variability from O(10) to O(1000).  Other dimensions are spatial and fixed.  \r\n\r\nWe have had both problems but in its simplest form we are having challenges computing just the mean and not having it exceed memory.  Fundamentally, I think I'm confused about the rules related to chunk size and total memory available.  Does the computation performed indicate the ratio of chunk size to total memory required?  It seems like this is the case but this is not obvious how to estimate this ratio.  Ultimately, it would be good to have a rule of thumb that we can add to http://xarray.pydata.org/en/stable/dask.html.\r\n\r\nTo clarify, how many chunks get loaded into memory for computation of (mixed xarray and dask-esq pseudo code):\r\n```\r\nx.shape = (Nx, Ny, Nt)\r\nx.chunks = {'Nx': Nx, 'Ny': Ny, 'Nt' : Nt/10}\r\nx.mean('Nt')\r\n```\r\nDoes this mean that 10 chunks are loaded into memory to compute the mean because chunk size on `Nt` is `Nt/10`?  So, if `Nx*Ny*Nt/10 = O(RAM)` this likely causes a memory error, correct?  The metric you give above would imply this is the case but that we really need `Nt/(10*100)` to be the chunk size for this case.  Obviously the scaling here is non-optimal because as Nt grows, we need to make smaller and smaller chunk sizes and we pay more and more for chunking overhead.\r\n\r\nI suspect I'm wrong many please here and please set me on the right conceptual path.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292565097/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292565319",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292565319",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292565319,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU2NTMxOQ==",
        "user": {
            "login": "pwolfram",
            "id": 4295853,
            "node_id": "MDQ6VXNlcjQyOTU4NTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4295853?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pwolfram",
            "html_url": "https://github.com/pwolfram",
            "followers_url": "https://api.github.com/users/pwolfram/followers",
            "following_url": "https://api.github.com/users/pwolfram/following{/other_user}",
            "gists_url": "https://api.github.com/users/pwolfram/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pwolfram/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pwolfram/subscriptions",
            "organizations_url": "https://api.github.com/users/pwolfram/orgs",
            "repos_url": "https://api.github.com/users/pwolfram/repos",
            "events_url": "https://api.github.com/users/pwolfram/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pwolfram/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T15:16:56Z",
        "updated_at": "2017-04-07T15:16:56Z",
        "author_association": "CONTRIBUTOR",
        "body": "> For reference. My notebook has 16GB of memory and I probably shoot for chunk sizes in the 100 MB range. There is about a 100x gap there.\r\n\r\n@mrocklin, this is just a good general heuristic, right?   Or is this specific to the `(x - x.mean().compute()).sum().compute()` case?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292565319/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292567281",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292567281",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292567281,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU2NzI4MQ==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T15:24:00Z",
        "updated_at": "2017-04-07T15:24:00Z",
        "author_association": "MEMBER",
        "body": "Pessimistically dask will use something like `ncores * chunksize` + `reduced chunksize * nchunks`  where in your case reduced chunksize is probably `Nx * Ny`.  Dask *should* do better than this, and should reduce the intermediates as they arrive.  You might play with the `split_every=` keyword here.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292567281/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292567783",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292567783",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292567783,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU2Nzc4Mw==",
        "user": {
            "login": "pwolfram",
            "id": 4295853,
            "node_id": "MDQ6VXNlcjQyOTU4NTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4295853?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pwolfram",
            "html_url": "https://github.com/pwolfram",
            "followers_url": "https://api.github.com/users/pwolfram/followers",
            "following_url": "https://api.github.com/users/pwolfram/following{/other_user}",
            "gists_url": "https://api.github.com/users/pwolfram/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pwolfram/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pwolfram/subscriptions",
            "organizations_url": "https://api.github.com/users/pwolfram/orgs",
            "repos_url": "https://api.github.com/users/pwolfram/repos",
            "events_url": "https://api.github.com/users/pwolfram/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pwolfram/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T15:25:50Z",
        "updated_at": "2017-04-07T15:25:50Z",
        "author_association": "CONTRIBUTOR",
        "body": "What I'm getting at is that there are two ways to compute the mean that I can forsee: \r\n1. Compute it with a self-reducing tree: average pairs, averaged produced pairs, etc\r\n2. Compute it incrementally (like the naive formula): \r\n```\r\nsum_{i=1}^n xtot = x_i\r\nxtot /= n\r\n```\r\n\r\nDoes dask do 1 or 2 or some combination or alternative strategy?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292567783/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292567969",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292567969",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292567969,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU2Nzk2OQ==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T15:26:32Z",
        "updated_at": "2017-04-07T15:26:32Z",
        "author_association": "MEMBER",
        "body": "Strategy 1.  However it tries to walk that tree in a depth-first way, rather than producing all of the leaves first.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292567969/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292569787",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292569787",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292569787,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU2OTc4Nw==",
        "user": {
            "login": "pwolfram",
            "id": 4295853,
            "node_id": "MDQ6VXNlcjQyOTU4NTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4295853?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pwolfram",
            "html_url": "https://github.com/pwolfram",
            "followers_url": "https://api.github.com/users/pwolfram/followers",
            "following_url": "https://api.github.com/users/pwolfram/following{/other_user}",
            "gists_url": "https://api.github.com/users/pwolfram/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pwolfram/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pwolfram/subscriptions",
            "organizations_url": "https://api.github.com/users/pwolfram/orgs",
            "repos_url": "https://api.github.com/users/pwolfram/repos",
            "events_url": "https://api.github.com/users/pwolfram/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pwolfram/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T15:33:13Z",
        "updated_at": "2017-04-07T15:33:13Z",
        "author_association": "CONTRIBUTOR",
        "body": "> Strategy 1. However it tries to walk that tree in a depth-first way, rather than producing all of the leaves first.\r\n\r\nThat is just for performance because it is the optimal way to compute on the tree, right?  That way some leaves are effectively never needed and we can average a leaf into some averaged-average, correct?\r\n\r\nOk, this is starting to make sense now.  nco probably does 2, which is why it sometimes seems to work better because if file access is really expensive to access at a particular point, e.g., get the data chunk from a file, approach 2 will actually make more sense because there will be fewer cache misses overall and the primary cost is getting data from disk into memory.\r\n\r\nDo we have freedom or recourse to force dask to minimize the data accesses somehow (optimally force strategy 2 so that adjacent times are computed first)?  The issue is that we never get close to using all the cores because we are so disk / memory limited.  Maybe this is a set up problem on our end.\r\n\r\nI fully recognize I'm asking *a lot* that is probably not in the dask design here because there is probably a latent assumption that most of the data is already in memory because dask is supposed to be more of a threaded/distributed numpy, where it would be unwise to do all the loading and unloading of data in and out of the data structures anyway.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292569787/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292571088",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292571088",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292571088,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU3MTA4OA==",
        "user": {
            "login": "pwolfram",
            "id": 4295853,
            "node_id": "MDQ6VXNlcjQyOTU4NTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4295853?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pwolfram",
            "html_url": "https://github.com/pwolfram",
            "followers_url": "https://api.github.com/users/pwolfram/followers",
            "following_url": "https://api.github.com/users/pwolfram/following{/other_user}",
            "gists_url": "https://api.github.com/users/pwolfram/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pwolfram/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pwolfram/subscriptions",
            "organizations_url": "https://api.github.com/users/pwolfram/orgs",
            "repos_url": "https://api.github.com/users/pwolfram/repos",
            "events_url": "https://api.github.com/users/pwolfram/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pwolfram/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T15:37:53Z",
        "updated_at": "2017-04-07T15:37:53Z",
        "author_association": "CONTRIBUTOR",
        "body": "Is a performance solution to artificially limit `ncores` and force the mean computation to span `Nx` and `Ny` *before* spanning `Nt`?  I think this access pattern will yield better performance to help reduce cache misses on file reads but I don't know if this is a practical solution.  ",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292571088/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292571242",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292571242",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292571242,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU3MTI0Mg==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T15:38:29Z",
        "updated_at": "2017-04-07T15:38:29Z",
        "author_association": "MEMBER",
        "body": "If you were to set `split_every=2` and use the synchronous scheduler then it would probably mimic option 1",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292571242/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292572278",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292572278",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292572278,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU3MjI3OA==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T15:42:16Z",
        "updated_at": "2017-04-07T15:42:16Z",
        "author_association": "MEMBER",
        "body": "If you're also computing the mean across Nx and Ny then I wouldn't anticipate a problem.  The intermediates would be very small.  I don't think that this is what you're asking though.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292572278/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292573283",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292573283",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292573283,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU3MzI4Mw==",
        "user": {
            "login": "pwolfram",
            "id": 4295853,
            "node_id": "MDQ6VXNlcjQyOTU4NTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4295853?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pwolfram",
            "html_url": "https://github.com/pwolfram",
            "followers_url": "https://api.github.com/users/pwolfram/followers",
            "following_url": "https://api.github.com/users/pwolfram/following{/other_user}",
            "gists_url": "https://api.github.com/users/pwolfram/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pwolfram/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pwolfram/subscriptions",
            "organizations_url": "https://api.github.com/users/pwolfram/orgs",
            "repos_url": "https://api.github.com/users/pwolfram/repos",
            "events_url": "https://api.github.com/users/pwolfram/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pwolfram/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T15:45:52Z",
        "updated_at": "2017-04-07T15:45:52Z",
        "author_association": "CONTRIBUTOR",
        "body": "No, the problem is we just need a time mean.  If data access were free we could do this with some type of SIMD kernel, e.g. at a point just average the time dimension.  We just have slow drives on HPC.  If we had more compute time dask.distributed would make sense and we could effectively get this to scale like on a laptop, but it doesn't we can't afford the cycles for the analysis so this obvious solution is inapplicable for our case.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292573283/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292574119",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292574119",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292574119,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU3NDExOQ==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T15:49:01Z",
        "updated_at": "2017-04-07T15:49:01Z",
        "author_association": "MEMBER",
        "body": "Does this work for you?\r\n\r\n> If you were to set split_every=2 and use the synchronous scheduler then it would probably mimic option 1\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292574119/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292575335",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292575335",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292575335,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU3NTMzNQ==",
        "user": {
            "login": "pwolfram",
            "id": 4295853,
            "node_id": "MDQ6VXNlcjQyOTU4NTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4295853?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pwolfram",
            "html_url": "https://github.com/pwolfram",
            "followers_url": "https://api.github.com/users/pwolfram/followers",
            "following_url": "https://api.github.com/users/pwolfram/following{/other_user}",
            "gists_url": "https://api.github.com/users/pwolfram/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pwolfram/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pwolfram/subscriptions",
            "organizations_url": "https://api.github.com/users/pwolfram/orgs",
            "repos_url": "https://api.github.com/users/pwolfram/repos",
            "events_url": "https://api.github.com/users/pwolfram/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pwolfram/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T15:53:34Z",
        "updated_at": "2017-04-07T15:53:34Z",
        "author_association": "CONTRIBUTOR",
        "body": "I haven't tried it yet.  I'm not sure I understand how to set this option in xarray for the computation to be 100% honest.  Advice on this would greatly be appreciated.  Is this one of those times I need to convert to dask from xarray first?\r\n\r\nAlso, is the split going to be over the non-reduced direction first?  If so, this is the best solution but I can hack it by setting chunk size to be over the entire spatial dimension.  The problem is that we could have more performance hurdles at larger scales if we don't compute over Nx and Ny first, and then over adjacent time steps.  So, this fixes today's problem but we could still have a latent issue.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292575335/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292575774",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292575774",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292575774,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU3NTc3NA==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T15:55:05Z",
        "updated_at": "2017-04-07T15:55:05Z",
        "author_association": "MEMBER",
        "body": "It looks like the tree reduction functions checks with globals, so `dask.set_options(split_every=2)` should work.\r\n\r\nGenerally in the future it would be useful for xarray reductions to pass through keyword arguments to dask.array functions.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292575774/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292577050",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292577050",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292577050,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU3NzA1MA==",
        "user": {
            "login": "pwolfram",
            "id": 4295853,
            "node_id": "MDQ6VXNlcjQyOTU4NTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4295853?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pwolfram",
            "html_url": "https://github.com/pwolfram",
            "followers_url": "https://api.github.com/users/pwolfram/followers",
            "following_url": "https://api.github.com/users/pwolfram/following{/other_user}",
            "gists_url": "https://api.github.com/users/pwolfram/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pwolfram/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pwolfram/subscriptions",
            "organizations_url": "https://api.github.com/users/pwolfram/orgs",
            "repos_url": "https://api.github.com/users/pwolfram/repos",
            "events_url": "https://api.github.com/users/pwolfram/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pwolfram/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T16:00:00Z",
        "updated_at": "2017-04-07T16:00:00Z",
        "author_association": "CONTRIBUTOR",
        "body": "> `dask.set_options(split_every=2)` \r\n\r\nThanks @mrocklin!\r\n\r\n> Generally in the future it would be useful for xarray reductions to pass through keyword arguments to dask.array functions.\r\n\r\n@mrocklin I agree.  For this type of solution to be generally useful we would need to have this fine-tuning control because a global reduction, e.g., heat capacity of the ocean, would not have this problem and we wouldn't want `split_every=2` for that case to avoid throttling performance.\r\n\r\n(cc @shoyer to highlight this particular discussion)",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292577050/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292595174",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292595174",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292595174,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU5NTE3NA==",
        "user": {
            "login": "pwolfram",
            "id": 4295853,
            "node_id": "MDQ6VXNlcjQyOTU4NTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4295853?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pwolfram",
            "html_url": "https://github.com/pwolfram",
            "followers_url": "https://api.github.com/users/pwolfram/followers",
            "following_url": "https://api.github.com/users/pwolfram/following{/other_user}",
            "gists_url": "https://api.github.com/users/pwolfram/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pwolfram/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pwolfram/subscriptions",
            "organizations_url": "https://api.github.com/users/pwolfram/orgs",
            "repos_url": "https://api.github.com/users/pwolfram/repos",
            "events_url": "https://api.github.com/users/pwolfram/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pwolfram/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T17:08:37Z",
        "updated_at": "2017-04-07T17:08:37Z",
        "author_association": "CONTRIBUTOR",
        "body": "@mrocklin, does this choice of `dask.set_options(split_every=2)` produce a global option?  If so, is it easy to set this back to a default value? ",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292595174/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292596862",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292596862",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292596862,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU5Njg2Mg==",
        "user": {
            "login": "pwolfram",
            "id": 4295853,
            "node_id": "MDQ6VXNlcjQyOTU4NTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4295853?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pwolfram",
            "html_url": "https://github.com/pwolfram",
            "followers_url": "https://api.github.com/users/pwolfram/followers",
            "following_url": "https://api.github.com/users/pwolfram/following{/other_user}",
            "gists_url": "https://api.github.com/users/pwolfram/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pwolfram/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pwolfram/subscriptions",
            "organizations_url": "https://api.github.com/users/pwolfram/orgs",
            "repos_url": "https://api.github.com/users/pwolfram/repos",
            "events_url": "https://api.github.com/users/pwolfram/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pwolfram/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T17:15:18Z",
        "updated_at": "2017-04-07T17:15:18Z",
        "author_association": "CONTRIBUTOR",
        "body": "One more question-- how do I set the synchronous scheduler?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292596862/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292597078",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292597078",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292597078,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU5NzA3OA==",
        "user": {
            "login": "shoyer",
            "id": 1217238,
            "node_id": "MDQ6VXNlcjEyMTcyMzg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1217238?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/shoyer",
            "html_url": "https://github.com/shoyer",
            "followers_url": "https://api.github.com/users/shoyer/followers",
            "following_url": "https://api.github.com/users/shoyer/following{/other_user}",
            "gists_url": "https://api.github.com/users/shoyer/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/shoyer/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/shoyer/subscriptions",
            "organizations_url": "https://api.github.com/users/shoyer/orgs",
            "repos_url": "https://api.github.com/users/shoyer/repos",
            "events_url": "https://api.github.com/users/shoyer/events{/privacy}",
            "received_events_url": "https://api.github.com/users/shoyer/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T17:16:01Z",
        "updated_at": "2017-04-07T17:16:01Z",
        "author_association": "MEMBER",
        "body": "You can use a context manager:\r\n```python\r\nwith dask.set_options(split_every=2):\r\n    result = ds.mean()\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292597078/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/292597973",
        "html_url": "https://github.com/dask/dask/issues/874#issuecomment-292597973",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/874",
        "id": 292597973,
        "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjU5Nzk3Mw==",
        "user": {
            "login": "shoyer",
            "id": 1217238,
            "node_id": "MDQ6VXNlcjEyMTcyMzg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1217238?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/shoyer",
            "html_url": "https://github.com/shoyer",
            "followers_url": "https://api.github.com/users/shoyer/followers",
            "following_url": "https://api.github.com/users/shoyer/following{/other_user}",
            "gists_url": "https://api.github.com/users/shoyer/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/shoyer/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/shoyer/subscriptions",
            "organizations_url": "https://api.github.com/users/shoyer/orgs",
            "repos_url": "https://api.github.com/users/shoyer/repos",
            "events_url": "https://api.github.com/users/shoyer/events{/privacy}",
            "received_events_url": "https://api.github.com/users/shoyer/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-04-07T17:19:24Z",
        "updated_at": "2017-04-07T17:19:24Z",
        "author_association": "MEMBER",
        "body": "Xarray actually passes `**kwargs` on to the dask function from aggregations like method `mean()`, though it isn't documented. So `ds.mean(split_every=2)` should work.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/292597973/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]