{
    "url": "https://api.github.com/repos/dask/dask/issues/5915",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/5915/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/5915/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/5915/events",
    "html_url": "https://github.com/dask/dask/issues/5915",
    "id": 566823517,
    "node_id": "MDU6SXNzdWU1NjY4MjM1MTc=",
    "number": 5915,
    "title": "MemoryError with `dask.array.from_tiledb`",
    "user": {
        "login": "DPeterK",
        "id": 3473068,
        "node_id": "MDQ6VXNlcjM0NzMwNjg=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3473068?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DPeterK",
        "html_url": "https://github.com/DPeterK",
        "followers_url": "https://api.github.com/users/DPeterK/followers",
        "following_url": "https://api.github.com/users/DPeterK/following{/other_user}",
        "gists_url": "https://api.github.com/users/DPeterK/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/DPeterK/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/DPeterK/subscriptions",
        "organizations_url": "https://api.github.com/users/DPeterK/orgs",
        "repos_url": "https://api.github.com/users/DPeterK/repos",
        "events_url": "https://api.github.com/users/DPeterK/events{/privacy}",
        "received_events_url": "https://api.github.com/users/DPeterK/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862305,
            "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=",
            "url": "https://api.github.com/repos/dask/dask/labels/array",
            "name": "array",
            "color": "006b75",
            "default": false,
            "description": null
        },
        {
            "id": 365513534,
            "node_id": "MDU6TGFiZWwzNjU1MTM1MzQ=",
            "url": "https://api.github.com/repos/dask/dask/labels/io",
            "name": "io",
            "color": "6f871c",
            "default": false,
            "description": ""
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 11,
    "created_at": "2020-02-18T11:18:16Z",
    "updated_at": "2021-03-12T14:51:35Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "TileDB allows you to create arrays with an effectively unlimited domain. If you try to create a dask array from such a TileDB array, however, you unsurprisingly hit issues. For example, if you run the code below you get a Segmentation Fault, which I think is hiding a `MemoryError` (I've seen this error before with similar code to this, but unfortunately can't reproduce it here).\r\n\r\nHere's some code to demonstrate the problem:\r\n```python\r\nimport dask.array as da\r\nimport numpy as np\r\nimport tiledb\r\n\r\narray_name = './tdb/example'\r\nattr_name = 'test'\r\n\r\nx_dim = tiledb.Dim(name=\"x\", domain=(0, np.iinfo(np.uint64).max-1), tile=1, dtype=np.uint64)\r\ny_dim = tiledb.Dim(name=\"y\", domain=(0, 100), tile=10, dtype=np.uint64)\r\ndomain = tiledb.Domain(x_dim, y_dim)\r\n\r\nattr = tiledb.Attr(name=attr_name, dtype=np.int64)\r\nschema = tiledb.ArraySchema(domain=domain, sparse=False, attrs=[attr])\r\ntiledb.Array.create(array_name, schema)\r\n\r\ndata = np.arange(100).reshape(10, 10)\r\nwith tiledb.open(array_name, 'w') as A:\r\n    A[0:10, 0:10] = data\r\n    \r\nwith tiledb.open(array_name, 'r') as A:\r\n    print(f'Nonempty domain: {A.nonempty_domain()}')\r\n    \r\narray = da.from_tiledb(array_name, attribute=attr_name)\r\n```\r\nAnd here's an example of running the code:\r\n```bash\r\n$ python dask_memerror_code.py \r\nNonempty domain: ((0, 9), (0, 9))\r\nSegmentation fault (core dumped)\r\n```\r\n\r\nI think dask is unable to create a Python array large enough for the size of the TileDB array, regardless of the TileDB array's nonempty domain.\r\n\r\nA possible solution for this would be to add functionality to `da.from_tiledb` to allow the TileDB array to be subset when it's read into a dask array, such as:\r\n```\r\ninds = (slice(0, 10, None), slice(0, 10, None))\r\narray = da.from_tiledb(array_name, attribute='attr', inds=inds)\r\n```\r\nwhich could then be used [when creating the dask array](https://github.com/dask/dask/blob/master/dask/array/tiledb_io.py#L72) to subset the TileDB array:\r\n```python\r\n    return core.from_array(tdb[inds], chunks, name=\"tiledb-%s\" % uri)\r\n```\r\nI'm not sure, however, whether this would cause the data from the TileDB array to be loaded into local memory and potentially cause a different problem with memory being flooded if the indexed array were itself large.\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/5915/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/5915/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}