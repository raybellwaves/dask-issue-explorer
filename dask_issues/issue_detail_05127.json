{
    "url": "https://api.github.com/repos/dask/dask/issues/5127",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/5127/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/5127/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/5127/events",
    "html_url": "https://github.com/dask/dask/issues/5127",
    "id": 470929526,
    "node_id": "MDU6SXNzdWU0NzA5Mjk1MjY=",
    "number": 5127,
    "title": "Custom defined Aggregations faile with empty partitiions",
    "user": {
        "login": "avlahop",
        "id": 3893010,
        "node_id": "MDQ6VXNlcjM4OTMwMTA=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3893010?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/avlahop",
        "html_url": "https://github.com/avlahop",
        "followers_url": "https://api.github.com/users/avlahop/followers",
        "following_url": "https://api.github.com/users/avlahop/following{/other_user}",
        "gists_url": "https://api.github.com/users/avlahop/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/avlahop/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/avlahop/subscriptions",
        "organizations_url": "https://api.github.com/users/avlahop/orgs",
        "repos_url": "https://api.github.com/users/avlahop/repos",
        "events_url": "https://api.github.com/users/avlahop/events{/privacy}",
        "received_events_url": "https://api.github.com/users/avlahop/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2019-07-22T07:08:38Z",
    "updated_at": "2021-10-13T00:41:13Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "active_lock_reason": null,
    "body": "I was trying to apply a custom aggregation on data that were read from a csv. The csvs contained data per day. After that I wanted to apply a filter (`loc`) on the data on a column. The result was that one of my partitions was left empty. So when trying to execute my defined Aggregation I got the following error message:\r\n\r\n```python\r\nValueError: multiple levels only valid with MultiIndex\r\n```\r\nsince I was grouping by with more than one keys. Grouping  with on field, succeeds. You can see that on the following example:\r\n\r\n```python\r\ndf_empty = pd.DataFrame(columns=['col1', 'col2', 'col3', 'col4'])\r\nddf_empty = dd.from_pandas(df_empty, npartitions=4)\r\nddf_empty.groupby(['col1', 'col2', 'col3']).col4.agg(a_in_data).compute()\r\n\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-54-eb3f6087572d> in <module>\r\n----> 1 ddf_empty.groupby(['col1', 'col2', 'col3']).col4.agg(a_in_data).compute()\r\n\r\n~/virtualenvs/statistics3/lib/python3.6/site-packages/dask/base.py in compute(self, **kwargs)\r\n    173         dask.base.compute\r\n    174         \"\"\"\r\n--> 175         (result,) = compute(self, traverse=False, **kwargs)\r\n    176         return result\r\n    177 \r\n\r\n~/virtualenvs/statistics3/lib/python3.6/site-packages/dask/base.py in compute(*args, **kwargs)\r\n    444     keys = [x.__dask_keys__() for x in collections]\r\n    445     postcomputes = [x.__dask_postcompute__() for x in collections]\r\n--> 446     results = schedule(dsk, keys, **kwargs)\r\n    447     return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\r\n    448 \r\n\r\n~/virtualenvs/statistics3/lib/python3.6/site-packages/dask/threaded.py in get(dsk, result, cache, num_workers, pool, **kwargs)\r\n     80         get_id=_thread_get_id,\r\n     81         pack_exception=pack_exception,\r\n---> 82         **kwargs\r\n     83     )\r\n     84 \r\n\r\n~/virtualenvs/statistics3/lib/python3.6/site-packages/dask/local.py in get_async(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\r\n    489                         _execute_task(task, data)  # Re-execute locally\r\n    490                     else:\r\n--> 491                         raise_exception(exc, tb)\r\n    492                 res, worker_id = loads(res_info)\r\n    493                 state[\"cache\"][key] = res\r\n\r\n~/virtualenvs/statistics3/lib/python3.6/site-packages/dask/compatibility.py in reraise(exc, tb)\r\n    128         if exc.__traceback__ is not tb:\r\n    129             raise exc.with_traceback(tb)\r\n--> 130         raise exc\r\n    131 \r\n    132     import pickle as cPickle\r\n\r\n~/virtualenvs/statistics3/lib/python3.6/site-packages/dask/local.py in execute_task(key, task_info, dumps, loads, get_id, pack_exception)\r\n    231     try:\r\n    232         task, data = loads(task_info)\r\n--> 233         result = _execute_task(task, data)\r\n    234         id = get_id()\r\n    235         result = dumps((result, id))\r\n\r\n~/virtualenvs/statistics3/lib/python3.6/site-packages/dask/core.py in _execute_task(arg, cache, dsk)\r\n    116     elif istask(arg):\r\n    117         func, args = arg[0], arg[1:]\r\n--> 118         args2 = [_execute_task(a, cache) for a in args]\r\n    119         return func(*args2)\r\n    120     elif not ishashable(arg):\r\n\r\n~/virtualenvs/statistics3/lib/python3.6/site-packages/dask/core.py in <listcomp>(.0)\r\n    116     elif istask(arg):\r\n    117         func, args = arg[0], arg[1:]\r\n--> 118         args2 = [_execute_task(a, cache) for a in args]\r\n    119         return func(*args2)\r\n    120     elif not ishashable(arg):\r\n\r\n~/virtualenvs/statistics3/lib/python3.6/site-packages/dask/core.py in _execute_task(arg, cache, dsk)\r\n    117         func, args = arg[0], arg[1:]\r\n    118         args2 = [_execute_task(a, cache) for a in args]\r\n--> 119         return func(*args2)\r\n    120     elif not ishashable(arg):\r\n    121         return arg\r\n\r\n~/virtualenvs/statistics3/lib/python3.6/site-packages/dask/compatibility.py in apply(func, args, kwargs)\r\n    105     def apply(func, args, kwargs=None):\r\n    106         if kwargs:\r\n--> 107             return func(*args, **kwargs)\r\n    108         else:\r\n    109             return func(*args)\r\n\r\n~/virtualenvs/statistics3/lib/python3.6/site-packages/dask/dataframe/groupby.py in _agg_finalize(df, aggregate_funcs, finalize_funcs, level)\r\n    860 def _agg_finalize(df, aggregate_funcs, finalize_funcs, level):\r\n    861     # finish the final aggregation level\r\n--> 862     df = _groupby_apply_funcs(df, funcs=aggregate_funcs, level=level)\r\n    863 \r\n    864     # and finalize the result\r\n\r\n~/virtualenvs/statistics3/lib/python3.6/site-packages/dask/dataframe/groupby.py in _groupby_apply_funcs(df, *index, **kwargs)\r\n    833 \r\n    834     funcs = kwargs.pop(\"funcs\")\r\n--> 835     grouped = _groupby_raise_unaligned(df, **kwargs)\r\n    836 \r\n    837     result = collections.OrderedDict()\r\n\r\n~/virtualenvs/statistics3/lib/python3.6/site-packages/dask/dataframe/groupby.py in _groupby_raise_unaligned(df, **kwargs)\r\n    161         # We want multiple keys\r\n    162         kwargs.update(by=list(by))\r\n--> 163     return df.groupby(**kwargs)\r\n    164 \r\n    165 \r\n\r\n~/virtualenvs/statistics3/lib/python3.6/site-packages/pandas/core/generic.py in groupby(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, **kwargs)\r\n   7630         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\r\n   7631                        sort=sort, group_keys=group_keys, squeeze=squeeze,\r\n-> 7632                        observed=observed, **kwargs)\r\n   7633 \r\n   7634     def asfreq(self, freq, method=None, how=None, normalize=False,\r\n\r\n~/virtualenvs/statistics3/lib/python3.6/site-packages/pandas/core/groupby/groupby.py in groupby(obj, by, **kwds)\r\n   2108         raise TypeError('invalid type: {}'.format(obj))\r\n   2109 \r\n-> 2110     return klass(obj, by, **kwds)\r\n\r\n~/virtualenvs/statistics3/lib/python3.6/site-packages/pandas/core/groupby/groupby.py in __init__(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, **kwargs)\r\n    358                                                     sort=sort,\r\n    359                                                     observed=observed,\r\n--> 360                                                     mutated=self.mutated)\r\n    361 \r\n    362         self.obj = obj\r\n\r\n~/virtualenvs/statistics3/lib/python3.6/site-packages/pandas/core/groupby/grouper.py in _get_grouper(obj, key, axis, level, sort, observed, mutated, validate)\r\n    458                     raise ValueError('No group keys passed!')\r\n    459                 else:\r\n--> 460                     raise ValueError('multiple levels only valid with '\r\n    461                                      'MultiIndex')\r\n    462 \r\n\r\nValueError: multiple levels only valid with MultiIndex\r\n```\r\n\r\nGrouping by on a single column works correclty.\r\n\r\n```python\r\nddf_empty.groupby('col1').col4.agg(a_in_data).compute()\r\nSeries([], Name: col4, dtype: bool)\r\n```\r\nUsing the same dask dataframe on the `custom_sum` Aggregation described on the dask documentation gives me the same result:\r\n\r\n```python\r\ncustom_sum = dd.Aggregation('custom_sum', lambda s: s.sum(), lambda s0: s0.sum())\r\nddf_empty.groupby(['col1', 'col2', 'col3']).col4.agg(custom_sum).compute() # raises the Exception above\r\n```\r\n\r\nDask version: 2.1.0\r\ndistributed version: 2.0.1\r\nPython version: 3.6.8\r\npandas version: 0.24.2",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/5127/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/5127/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}