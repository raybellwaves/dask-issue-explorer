{
    "url": "https://api.github.com/repos/dask/dask/issues/4001",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/4001/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/4001/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/4001/events",
    "html_url": "https://github.com/dask/dask/issues/4001",
    "id": 362468408,
    "node_id": "MDU6SXNzdWUzNjI0Njg0MDg=",
    "number": 4001,
    "title": "groupby aggregation does not scale well with amount of groups",
    "user": {
        "login": "jangorecki",
        "id": 3627377,
        "node_id": "MDQ6VXNlcjM2MjczNzc=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3627377?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/jangorecki",
        "html_url": "https://github.com/jangorecki",
        "followers_url": "https://api.github.com/users/jangorecki/followers",
        "following_url": "https://api.github.com/users/jangorecki/following{/other_user}",
        "gists_url": "https://api.github.com/users/jangorecki/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/jangorecki/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/jangorecki/subscriptions",
        "organizations_url": "https://api.github.com/users/jangorecki/orgs",
        "repos_url": "https://api.github.com/users/jangorecki/repos",
        "events_url": "https://api.github.com/users/jangorecki/events{/privacy}",
        "received_events_url": "https://api.github.com/users/jangorecki/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 15,
    "created_at": "2018-09-21T06:13:47Z",
    "updated_at": "2020-06-22T12:29:46Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "It seems that there is performance bug when doing grouping. Time and memory consumed by dask does not seems to scale well with number of output rows.\r\nPlease find below script to produce example data, replace `N` to produce bigger input data.\r\n```py\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\ndef randChar(f, numGrp, N) :\r\n   things = [f%x for x in range(numGrp)]\r\n   return [things[x] for x in np.random.choice(numGrp, N)]\r\n\r\ndef randFloat(numGrp, N) :\r\n   things = [round(100*np.random.random(),4) for x in range(numGrp)]\r\n   return [things[x] for x in np.random.choice(numGrp, N)]\r\n\r\nN = int(1e7)\r\nK = 100\r\nx = pd.DataFrame({\r\n  'id1' : randChar(\"id%03d\", K, N),       # large groups (char)\r\n  'id2' : randChar(\"id%03d\", K, N),       # large groups (char)\r\n  'id3' : randChar(\"id%010d\", N//K, N),   # small groups (char)\r\n  'id4' : np.random.choice(K, N),         # large groups (int)\r\n  'id5' : np.random.choice(K, N),         # large groups (int)\r\n  'id6' : np.random.choice(N//K, N),      # small groups (int)\r\n  'v1' :  np.random.choice(5, N),         # int in range [1,5]\r\n  'v2' :  np.random.choice(5, N),         # int in range [1,5]\r\n  'v3' :  randFloat(100,N)                # numeric e.g. 23.5749\r\n})\r\nx.to_csv(\"example.csv\", encoding='utf-8', index=False)\r\n```\r\nAnd following code to perform grouping.\r\n```py\r\nimport os\r\nimport gc\r\nimport timeit\r\nimport pandas as pd\r\nimport dask as dk\r\nimport dask.dataframe as dd\r\n\r\nprint(pd.__version__)\r\nprint(dk.__version__)\r\n\r\nx = dd.read_csv(\"example.csv\", na_filter=False).persist()\r\nprint(len(x))\r\n\r\ngc.collect()\r\nt_start = timeit.default_timer()\r\nans = x.groupby(['id1']).agg({'v1':'sum'}).compute()\r\nt = timeit.default_timer() - t_start\r\nprint(len(ans))\r\nprint(t)\r\ndel ans\r\n\r\ngc.collect()\r\nt_start = timeit.default_timer()\r\nans = x.groupby(['id3']).agg({'v1':'sum', 'v3':'mean'}).compute()\r\nt = timeit.default_timer() - t_start\r\nprint(len(ans))\r\nprint(t)\r\ndel ans\r\n```\r\n\r\nRunning on python 3.6.5, pandas 0.23.4, dask 0.19.2.\r\nSingle machine 20 CPU, 125 GB memory.\r\n\r\nFor input 1e7 rows\r\noutput 100 rows, timing: 0.4032 s\r\noutput 1e5 rows, timing: 2.1272 s\r\n\r\nFor input 1e8 rows\r\noutput 100 rows, timing: 3.2559 s\r\noutput 1e6 rows, timing: 149.8847 s\r\n\r\nAdditionally I checked alternative approach, instead of `.compute` to use `Client` and `.persist`(adding `print(len(.))` to ensure persist has kicked in). In both cases time was not acceptable (see table below, units are seconds).\r\n\r\n| in_rows|groups | compute()|  persist()|\r\n|-------:|:------|---------:|----------:|\r\n|   1e+07|fewer  |     0.395|      0.425|\r\n|   1e+07|more   |     2.124|      2.145|\r\n|   1e+08|fewer  |     3.239|      3.420|\r\n|   1e+08|more   |   148.211|    148.043|\r\n|   1e+09|fewer  |        NA|    848.911|\r\n|   1e+09|more   |        NA|   5364.569|\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/4001/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/4001/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}