{
    "url": "https://api.github.com/repos/dask/dask/issues/9509",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/9509/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/9509/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/9509/events",
    "html_url": "https://github.com/dask/dask/issues/9509",
    "id": 1379801108,
    "node_id": "I_kwDOAbcwm85SPhgU",
    "number": 9509,
    "title": "`DataFrame.groupby().cov()` fails with `split_out>1`",
    "user": {
        "login": "ian-r-rose",
        "id": 5728311,
        "node_id": "MDQ6VXNlcjU3MjgzMTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ian-r-rose",
        "html_url": "https://github.com/ian-r-rose",
        "followers_url": "https://api.github.com/users/ian-r-rose/followers",
        "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}",
        "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions",
        "organizations_url": "https://api.github.com/users/ian-r-rose/orgs",
        "repos_url": "https://api.github.com/users/ian-r-rose/repos",
        "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}",
        "received_events_url": "https://api.github.com/users/ian-r-rose/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        },
        {
            "id": 3468123446,
            "node_id": "LA_kwDOAbcwm87Ot102",
            "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention",
            "name": "needs attention",
            "color": "6d626c",
            "default": false,
            "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."
        },
        {
            "id": 3798450413,
            "node_id": "LA_kwDOAbcwm87iZ8Dt",
            "url": "https://api.github.com/repos/dask/dask/labels/bug",
            "name": "bug",
            "color": "faadaf",
            "default": true,
            "description": "Something is broken"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2022-09-20T18:05:09Z",
    "updated_at": "2022-10-31T02:14:33Z",
    "closed_at": null,
    "author_association": "MEMBER",
    "active_lock_reason": null,
    "body": "The following fails for both `cov` and `corr` when `split_out>1`:\r\n\r\n```python\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\n\r\npdf = pd.DataFrame(\r\n  {\r\n      \"a\": [1, 2, 6, 4, 4, 6, 4, 3, 7] * 10,\r\n      \"b\": [4, 2, 7, 3, 3, 1, 1, 1, 2] * 10,\r\n      \"d\": [0, 1, 2, 3, 4, 5, 6, 7, 8] * 10,\r\n      \"c\": [0, 1, 2, 3, 4, 5, 6, 7, 8] * 10,\r\n  },\r\n  columns=[\"c\", \"b\", \"a\", \"d\"],\r\n)\r\n\r\nddf = dd.from_pandas(pdf, 2)\r\n\r\nddf.groupby(\"a\").cov(split_out=1).compute()  # Succeeds\r\nddf.groupby(\"a\").cov(split_out=2).compute()  # Fails\r\n```\r\n\r\n<details>\r\n\r\n```python-traceback\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\nInput In [21], in <cell line: 17>()\r\n     14 ddf = dd.from_pandas(pdf, 2)\r\n     16 ddf.groupby(\"a\").cov(split_out=1).compute()  # Succeeds\r\n---> 17 ddf.groupby(\"a\").cov(split_out=2).compute()\r\n\r\nFile ~/dask/dask/dask/base.py:315, in DaskMethodsMixin.compute(self, **kwargs)\r\n    291 def compute(self, **kwargs):\r\n    292     \"\"\"Compute this dask collection\r\n    293 \r\n    294     This turns a lazy Dask collection into its in-memory equivalent.\r\n   (...)\r\n    313     dask.base.compute\r\n    314     \"\"\"\r\n--> 315     (result,) = compute(self, traverse=False, **kwargs)\r\n    316     return result\r\n\r\nFile ~/dask/dask/dask/base.py:600, in compute(traverse, optimize_graph, scheduler, get, *args, **kwargs)\r\n    597     keys.append(x.__dask_keys__())\r\n    598     postcomputes.append(x.__dask_postcompute__())\r\n--> 600 results = schedule(dsk, keys, **kwargs)\r\n    601 return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\r\n\r\nFile ~/dask/dask/dask/threaded.py:89, in get(dsk, keys, cache, num_workers, pool, **kwargs)\r\n     86     elif isinstance(pool, multiprocessing.pool.Pool):\r\n     87         pool = MultiprocessingPoolExecutor(pool)\r\n---> 89 results = get_async(\r\n     90     pool.submit,\r\n     91     pool._max_workers,\r\n     92     dsk,\r\n     93     keys,\r\n     94     cache=cache,\r\n     95     get_id=_thread_get_id,\r\n     96     pack_exception=pack_exception,\r\n     97     **kwargs,\r\n     98 )\r\n    100 # Cleanup pools associated to dead threads\r\n    101 with pools_lock:\r\n\r\nFile ~/dask/dask/dask/local.py:511, in get_async(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\r\n    509         _execute_task(task, data)  # Re-execute locally\r\n    510     else:\r\n--> 511         raise_exception(exc, tb)\r\n    512 res, worker_id = loads(res_info)\r\n    513 state[\"cache\"][key] = res\r\n\r\nFile ~/dask/dask/dask/local.py:319, in reraise(exc, tb)\r\n    317 if exc.__traceback__ is not tb:\r\n    318     raise exc.with_traceback(tb)\r\n--> 319 raise exc\r\n\r\nFile ~/dask/dask/dask/local.py:224, in execute_task(key, task_info, dumps, loads, get_id, pack_exception)\r\n    222 try:\r\n    223     task, data = loads(task_info)\r\n--> 224     result = _execute_task(task, data)\r\n    225     id = get_id()\r\n    226     result = dumps((result, id))\r\n\r\nFile ~/dask/dask/dask/core.py:119, in _execute_task(arg, cache, dsk)\r\n    115     func, args = arg[0], arg[1:]\r\n    116     # Note: Don't assign the subtask results to a variable. numpy detects\r\n    117     # temporaries by their reference count and can execute certain\r\n    118     # operations in-place.\r\n--> 119     return func(*(_execute_task(a, cache) for a in args))\r\n    120 elif not ishashable(arg):\r\n    121     return arg\r\n\r\nFile ~/dask/dask/dask/optimization.py:990, in SubgraphCallable.__call__(self, *args)\r\n    988 if not len(args) == len(self.inkeys):\r\n    989     raise ValueError(\"Expected %d args, got %d\" % (len(self.inkeys), len(args)))\r\n--> 990 return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\r\n\r\nFile ~/dask/dask/dask/core.py:149, in get(dsk, out, cache)\r\n    147 for key in toposort(dsk):\r\n    148     task = dsk[key]\r\n--> 149     result = _execute_task(task, cache)\r\n    150     cache[key] = result\r\n    151 result = _execute_task(out, cache)\r\n\r\nFile ~/dask/dask/dask/core.py:119, in _execute_task(arg, cache, dsk)\r\n    115     func, args = arg[0], arg[1:]\r\n    116     # Note: Don't assign the subtask results to a variable. numpy detects\r\n    117     # temporaries by their reference count and can execute certain\r\n    118     # operations in-place.\r\n--> 119     return func(*(_execute_task(a, cache) for a in args))\r\n    120 elif not ishashable(arg):\r\n    121     return arg\r\n\r\nFile ~/dask/dask/dask/dataframe/core.py:6335, in hash_shard(df, nparts, split_out_setup, split_out_setup_kwargs, ignore_index)\r\n   6332 else:\r\n   6333     h = df\r\n-> 6335 h = hash_object_dispatch(h, index=False)\r\n   6336 return group_split_dispatch(df, h % nparts, nparts, ignore_index=ignore_index)\r\n\r\nFile ~/dask/dask/dask/utils.py:638, in Dispatch.__call__(self, arg, *args, **kwargs)\r\n    634 def __call__(self, arg, *args, **kwargs):\r\n    635     \"\"\"\r\n    636     Call the corresponding method based on type of argument.\r\n    637     \"\"\"\r\n--> 638     meth = self.dispatch(type(arg))\r\n    639     return meth(arg, *args, **kwargs)\r\n\r\nFile ~/dask/dask/dask/utils.py:632, in Dispatch.dispatch(self, cls)\r\n    630         register()\r\n    631         return self.dispatch(cls)  # recurse\r\n--> 632 raise TypeError(f\"No dispatch for {cls}\")\r\n\r\nTypeError: No dispatch for <class 'builtin_function_or_method'>\r\n```\r\n\r\n</details>",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/9509/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/9509/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}