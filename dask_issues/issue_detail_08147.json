{
    "url": "https://api.github.com/repos/dask/dask/issues/8147",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/8147/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/8147/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/8147/events",
    "html_url": "https://github.com/dask/dask/issues/8147",
    "id": 996597901,
    "node_id": "I_kwDOAbcwm847ZuCN",
    "number": 8147,
    "title": "Unified data reader / writer interfaces",
    "user": {
        "login": "MrPowers",
        "id": 2722395,
        "node_id": "MDQ6VXNlcjI3MjIzOTU=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2722395?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/MrPowers",
        "html_url": "https://github.com/MrPowers",
        "followers_url": "https://api.github.com/users/MrPowers/followers",
        "following_url": "https://api.github.com/users/MrPowers/following{/other_user}",
        "gists_url": "https://api.github.com/users/MrPowers/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/MrPowers/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/MrPowers/subscriptions",
        "organizations_url": "https://api.github.com/users/MrPowers/orgs",
        "repos_url": "https://api.github.com/users/MrPowers/repos",
        "events_url": "https://api.github.com/users/MrPowers/events{/privacy}",
        "received_events_url": "https://api.github.com/users/MrPowers/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 365513534,
            "node_id": "MDU6TGFiZWwzNjU1MTM1MzQ=",
            "url": "https://api.github.com/repos/dask/dask/labels/io",
            "name": "io",
            "color": "6f871c",
            "default": false,
            "description": ""
        },
        {
            "id": 2949099791,
            "node_id": "MDU6TGFiZWwyOTQ5MDk5Nzkx",
            "url": "https://api.github.com/repos/dask/dask/labels/parquet",
            "name": "parquet",
            "color": "77A66C",
            "default": false,
            "description": ""
        },
        {
            "id": 3468123446,
            "node_id": "LA_kwDOAbcwm87Ot102",
            "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention",
            "name": "needs attention",
            "color": "6d626c",
            "default": false,
            "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2021-09-15T02:39:57Z",
    "updated_at": "2022-03-24T21:18:41Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "active_lock_reason": null,
    "body": "This post summarizes some of the inconsistencies in the reader / writer APIs.\r\n\r\nInconsistencies naturally arise as open source projects develop.  I think the project is now in a place where we can think about the readers / writers holistically and design an interface that'll be internally consistent.  This'll also be a great opportunity to revisit assumptions and defaults (e.g. default append behavior, default compression algo for CSVs, and filenaming conventions that'll be less error prone).\r\n\r\nI expect a lot more readers / writers will be added in the future and would like to avoid even more ways of doing things.\r\n\r\nI think we can get the best of all worlds with some well thought out work:\r\n\r\n* give users a better interface\r\n* eliminate some tech debt\r\n* keep code backwards compatible\r\n\r\n**Writer inconsistencies**\r\n\r\n* Here\u2019s how to append with `to_parquet`: `ddf.to_parquet(\u201csome_folder\u201d, append=True)`\r\n* Here\u2019s how to append with `to_csv`: `ddf.to_csv(\u201csome_folder\u201d, mode=\u201da\u201d)`\r\n\r\nThere are also functionality differences.  `to_csv` allows for filename customization with `name_function` but `to_parquet` doesn't allow for customization.\r\n\r\nThere are some behavior/convention inconsistencies:\r\n\r\n_to_parquet_\r\n\r\n```python\r\ndf = pd.DataFrame(\r\n    {\"nums\": [1, 2, 3, 4, 5, 6], \"letters\": [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"]}\r\n)\r\nddf = dd.from_pandas(df, npartitions=2)\r\n\r\nddf.to_parquet(\"some_parquet_folder\") # nothing is returned\r\n```\r\n\r\nHere are the files that are outputted:\r\n\r\n```\r\nsome_parquet_folder/\r\n  _common_metadata\r\n  _metadata\r\n  part.0.parquet\r\n  part.1.parquet\r\n```\r\n\r\n_to_csv_\r\n\r\n```python\r\nddf.to_csv(\"some_csv_folder\") # this returns a list of filenames that are outputted, which is bad for huge writes\r\n```\r\n\r\nHere are the files that are outputted:\r\n\r\n```\r\nsome_csv_folder/\r\n  0.part\r\n  1.part\r\n```\r\n\r\nIt'd be better for these files to be named `part.0.csv` and `part.1.csv` to be consistent with the Parquet filenames.  The Spark convention of `part-00000-78f9c583-ea60-4962-af99-895f453dce23-c000.snappy.csv` would be even better to allow identification of files written per batch and lessen the probability of filename collisions.\r\n\r\n**Reader inconsistencies**\r\n\r\nThere are also lots of subtle inconsistencies with the data readers (CSV wants glob notation and Parquet does not).\r\n\r\n* `dd.read_csv( \"s3://coiled-datasets/timeseries/7d/csv/2000/*.csv\")`\r\n* `dd.read_parquet(\"s3://coiled-datasets/timeseries/7d\u201d)`\r\n\r\n**Recommended next steps**\r\n\r\n* Get thoughts from the core team if this project sounds interesting\r\n* I can provide suggested next steps is the team would find them useful",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/8147/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/8147/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}