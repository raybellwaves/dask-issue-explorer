{
    "url": "https://api.github.com/repos/dask/dask/issues/10270",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/10270/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/10270/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/10270/events",
    "html_url": "https://github.com/dask/dask/issues/10270",
    "id": 1699217517,
    "node_id": "I_kwDOAbcwm85lSABt",
    "number": 10270,
    "title": "Poor performance with `read_csv` and many thousands of s3 files",
    "user": {
        "login": "shughes-uk",
        "id": 546891,
        "node_id": "MDQ6VXNlcjU0Njg5MQ==",
        "avatar_url": "https://avatars.githubusercontent.com/u/546891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/shughes-uk",
        "html_url": "https://github.com/shughes-uk",
        "followers_url": "https://api.github.com/users/shughes-uk/followers",
        "following_url": "https://api.github.com/users/shughes-uk/following{/other_user}",
        "gists_url": "https://api.github.com/users/shughes-uk/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/shughes-uk/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/shughes-uk/subscriptions",
        "organizations_url": "https://api.github.com/users/shughes-uk/orgs",
        "repos_url": "https://api.github.com/users/shughes-uk/repos",
        "events_url": "https://api.github.com/users/shughes-uk/events{/privacy}",
        "received_events_url": "https://api.github.com/users/shughes-uk/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 3468123446,
            "node_id": "LA_kwDOAbcwm87Ot102",
            "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention",
            "name": "needs attention",
            "color": "6d626c",
            "default": false,
            "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."
        },
        {
            "id": 3880424463,
            "node_id": "LA_kwDOAbcwm87nSpQP",
            "url": "https://api.github.com/repos/dask/dask/labels/needs%20triage",
            "name": "needs triage",
            "color": "eeeeee",
            "default": false,
            "description": "Needs a response from a contributor"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": {
        "login": "milesgranger",
        "id": 13764397,
        "node_id": "MDQ6VXNlcjEzNzY0Mzk3",
        "avatar_url": "https://avatars.githubusercontent.com/u/13764397?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/milesgranger",
        "html_url": "https://github.com/milesgranger",
        "followers_url": "https://api.github.com/users/milesgranger/followers",
        "following_url": "https://api.github.com/users/milesgranger/following{/other_user}",
        "gists_url": "https://api.github.com/users/milesgranger/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/milesgranger/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/milesgranger/subscriptions",
        "organizations_url": "https://api.github.com/users/milesgranger/orgs",
        "repos_url": "https://api.github.com/users/milesgranger/repos",
        "events_url": "https://api.github.com/users/milesgranger/events{/privacy}",
        "received_events_url": "https://api.github.com/users/milesgranger/received_events",
        "type": "User",
        "site_admin": false
    },
    "assignees": [
        {
            "login": "milesgranger",
            "id": 13764397,
            "node_id": "MDQ6VXNlcjEzNzY0Mzk3",
            "avatar_url": "https://avatars.githubusercontent.com/u/13764397?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/milesgranger",
            "html_url": "https://github.com/milesgranger",
            "followers_url": "https://api.github.com/users/milesgranger/followers",
            "following_url": "https://api.github.com/users/milesgranger/following{/other_user}",
            "gists_url": "https://api.github.com/users/milesgranger/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/milesgranger/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/milesgranger/subscriptions",
            "organizations_url": "https://api.github.com/users/milesgranger/orgs",
            "repos_url": "https://api.github.com/users/milesgranger/repos",
            "events_url": "https://api.github.com/users/milesgranger/events{/privacy}",
            "received_events_url": "https://api.github.com/users/milesgranger/received_events",
            "type": "User",
            "site_admin": false
        }
    ],
    "milestone": null,
    "comments": 4,
    "created_at": "2023-05-07T20:08:31Z",
    "updated_at": "2023-06-12T02:04:39Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "active_lock_reason": null,
    "body": "## Use case\r\nI'm trying to produce some rollups of cloudfront access log data. Cloudfront produces many thousands of csv files, usually very small (kilobytes). An example month of a relatively low usage cloudfront distribution is 30k files. It can be 100k+.\r\n\r\nRolling these up into parquet on a monthly basis is nice as it will make downstream operations much more efficient (interacting with thousands upon thousands of files on s3 adds a lot of overhead).\r\n\r\nIf listing millions of s3 objects didn't take forever I'd probably just create one giant parquet\r\n\r\n## Issue\r\n\r\nSomething takes 15 minutes after calling `to_parquet` before a task graph appears on the scheduler.\r\n\r\nI initially started with using `df.repartition(partition_size=\"50mb\")`, I dropped it as I thought it might be the issue but it's not.\r\n\r\nI did notice that `s3fs` had some poor performance when using a glob to get the monthly files (https://github.com/fsspec/s3fs/issues/733) . However fixing that it now takes just a few seconds to generate a list of 30k files to pass to `read_csv`. Then nothing happens. CPU/Network/Disk all remain low on my laptop, and on the remote scheduler.\r\n\r\nWhen things finally start moving the resulting task graph is only about 20k tasks, nothing fancy. \r\n\r\nMy intuition here is there's some very slow s3 api operation happening involving every file. I did some surface level poking into the `read_csv` code and did not get deep enough to find out what.  I suspect enabling logging for `aiohttp` might reveal a lot of http calls to s3 if that is the case.\r\n\r\nCode here\r\n\r\n```python\r\ndf = dd.read_csv(\r\n                    files,\r\n                    sep=\"\\t\",\r\n                    names=list(dtypes.keys()),\r\n                    dtype=dtypes,\r\n                    comment=\"#\",\r\n                    on_bad_lines=\"skip\",\r\n                    compression=\"gzip\",\r\n                    sample=False,\r\n                    blocksize=None,\r\n                )\r\ndf.to_parquet(output_prefix, compression=\"gzip\")\r\n```\r\n\r\nGiven that I need to have a cluster up, whatever is happening is quite painful. The actual processing is done in seconds, but the cluster is up for the full 15 minutes burning $$ while the client seems to do something very mysterious to me as an average user.\r\n\r\nExample cluster here https://cloud.coiled.io/clusters/210090/overview?account=shughes-uk . Only 4% of the uptime was actually spent doing anything relevant.",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/10270/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/10270/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}