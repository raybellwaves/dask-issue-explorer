{
    "url": "https://api.github.com/repos/dask/dask/issues/8581",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/8581/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/8581/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/8581/events",
    "html_url": "https://github.com/dask/dask/issues/8581",
    "id": 1107043820,
    "node_id": "I_kwDOAbcwm85B_CXs",
    "number": 8581,
    "title": "Blockwise serialization can fail with LocalCluster(processes=False)",
    "user": {
        "login": "rjzamora",
        "id": 20461013,
        "node_id": "MDQ6VXNlcjIwNDYxMDEz",
        "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/rjzamora",
        "html_url": "https://github.com/rjzamora",
        "followers_url": "https://api.github.com/users/rjzamora/followers",
        "following_url": "https://api.github.com/users/rjzamora/following{/other_user}",
        "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions",
        "organizations_url": "https://api.github.com/users/rjzamora/orgs",
        "repos_url": "https://api.github.com/users/rjzamora/repos",
        "events_url": "https://api.github.com/users/rjzamora/events{/privacy}",
        "received_events_url": "https://api.github.com/users/rjzamora/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 1342304743,
            "node_id": "MDU6TGFiZWwxMzQyMzA0NzQz",
            "url": "https://api.github.com/repos/dask/dask/labels/core",
            "name": "core",
            "color": "000000",
            "default": false,
            "description": ""
        },
        {
            "id": 2156573524,
            "node_id": "MDU6TGFiZWwyMTU2NTczNTI0",
            "url": "https://api.github.com/repos/dask/dask/labels/highlevelgraph",
            "name": "highlevelgraph",
            "color": "8c24d6",
            "default": false,
            "description": "Issues relating to HighLevelGraphs."
        },
        {
            "id": 3468123446,
            "node_id": "LA_kwDOAbcwm87Ot102",
            "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention",
            "name": "needs attention",
            "color": "6d626c",
            "default": false,
            "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2022-01-18T15:28:28Z",
    "updated_at": "2022-05-13T20:02:53Z",
    "closed_at": null,
    "author_association": "MEMBER",
    "active_lock_reason": null,
    "body": "This issue is an attempt to clearly highlight an existing bug in Dask that has been (less-clearly) reported in a number of places (e.g. #7449 and #7777): The current serialization machinery used in Dask and Distributed does not work when `LocalCluster` is used with `processes=False`.\r\n\r\nThis bug shows up any time a `Blockwise`-based `HighevelGraph` (HLG) layer contains a local graph with nested tasks.  In cases like this, Dask will mark the sub-task as `Serialize`, but since `processes=False` skips the Distributed-comms interface, the `Serialize` object is never serialized/deserialized before making its way to the worker.\r\n\r\nAs correctly suggested by @snowoody [here](https://github.com/dask/dask/issues/7777#issuecomment-994509162), the short term workaround for this bug is either of the following:\r\n\r\n1. Avoid using `processes=False`.  If the distributed-communication layer is actually used, the `Serialize` objects will be properly serialized and deserialized.\r\n2. Ensure the HLG is materialized into a dict-based task graph before it is sent to the scheduler. This can be done by executing your code in a `dask.config.set({\"optimization.fuse.active\": True})` context.\u2028\r\n\r\nThe best long term solution to this problem is probably the serialization generalization/overhaul described in [distributed#5581](https://github.com/dask/distributed/issues/5581).  The current Distributed serialization design requires an ill-defined (and clumsy) partial-serialization procedure for HLG-communication to the scheduler.  That is, the definition of each HLG Layer is required to mark objects that it will include in the materialized task graph as `to_serialize` (alias for `Serialize`) when said objects cannot be serialized with msgpack. This is the only way to ensure that objects requiring pickling will (1) be passed from the client to the scheduler, (2) be injected into the graph by the scheduler, and then (3) be interpreted correctly by the worker.  If we moved to distributed#5581, the HLG-Layer code could avoid marking anything as `to_serialize`, because the comm layers would automatically use pickle when necessary.\r\n\r\n**Reproducers**:\r\n\r\n- [read_csv](https://github.com/dask/dask/issues/7777#issue-916010856)\r\n- array + [blockwise](https://github.com/dask/dask/issues/7449#issue-838479072)",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/8581/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/8581/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}