[
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/308703768",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-308703768",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 308703768,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMwODcwMzc2OA==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-06-15T11:25:39Z",
        "updated_at": "2017-06-15T11:25:39Z",
        "author_association": "MEMBER",
        "body": "First, thank you for the detailed writeup.\r\n\r\nAs for the core cause, my first guess is that this is due to inaccurate accounting between estimating the size of the pandas dataframes and determining their true cost in memory.  This often happens when we have custom objects that are large but don't implement the `__sizeof__` protocol.  Currently `--memory-limit` works on the sum of the estimated sizes of data elements we have in memory, and not on what the process reports as memory usage.  There are various reasons for this, but we could consider looking at both in the future.\r\n\r\n>  Plotting mem usage over time shows a tight distribution around --memory-limit for the first ~1/2 of the job and then large variance for the second ~1/2 of the job, during which time OOMs start happening (plots below).\r\n\r\nThis provides a different possible answer.  The second half of the job tends to be communication heavy, so maybe most of our data use isn't in storing data, but rather in bytes that are in flight.  Dask doesn't account for bytes in active use by user code or the network layer.  These bytes are much harder for us to control.\r\n\r\n### Questions\r\n\r\n1.  What is the nature of the data that you're moving around?  Largely numbers? Largely text? JSON-like data?  Custom Python objects?\r\n2.  Can you take a look at one of the diagnostic servers for one of the workers?  This is typically served at port 8789 on any of the worker machines.  You might find the bottom plot on the `/main` page of interest during communication heavy work.\r\n3.  Why are you using zlib?  Have you considered lz4?  I ask only because it might be contributing to bottlenecks during data communication.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/308703768/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/309657133",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-309657133",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 309657133,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMwOTY1NzEzMw==",
        "user": {
            "login": "jdanbrown",
            "id": 627486,
            "node_id": "MDQ6VXNlcjYyNzQ4Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/627486?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jdanbrown",
            "html_url": "https://github.com/jdanbrown",
            "followers_url": "https://api.github.com/users/jdanbrown/followers",
            "following_url": "https://api.github.com/users/jdanbrown/following{/other_user}",
            "gists_url": "https://api.github.com/users/jdanbrown/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jdanbrown/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jdanbrown/subscriptions",
            "organizations_url": "https://api.github.com/users/jdanbrown/orgs",
            "repos_url": "https://api.github.com/users/jdanbrown/repos",
            "events_url": "https://api.github.com/users/jdanbrown/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jdanbrown/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-06-20T06:27:13Z",
        "updated_at": "2017-06-20T22:05:17Z",
        "author_association": "NONE",
        "body": "### Answer 3\r\n> 3. Why are you using zlib? Have you considered lz4? I ask only because it might be contributing to bottlenecks during data communication.\r\n\r\nHmm, no good reason\u2014thanks for the heads up! I've switched `DASK_COMPRESSION` from zlib to lz4 (and I also found this [useful reference on compression tradeoffs](https://www.percona.com/blog/2016/04/13/evaluating-database-compression-methods-update/)). Updated worker run command:\r\n```sh\r\nDASK_COMPRESSION=lz4 dask-worker --nprocs 1 --nthreads 1 --memory-limit=4e9 --no-nanny <scheduler-url>\r\n```\r\n\r\nI also went ahead and upgraded dask/distributed/fastparquet to the latest masters, at the risk of changing my repros in subtle ways. Still seeing OOMs, but fwiw the job seems to be failing faster than before (based just on the 2 trials below).\r\n\r\n```sh\r\n$ python --version\r\nPython 3.6.0\r\n\r\n$ cat requirements.txt | egrep 'dask|distributed|fastparquet'\r\ngit+https://github.com/dask/dask.git@d0aa50a\r\ngit+https://github.com/dask/distributed.git@312a41a\r\ngit+https://github.com/dask/fastparquet.git@0.1.0\r\n```\r\n\r\n### Answer 1\r\n> 1. What is the nature of the data that you're moving around? Largely numbers? Largely text? JSON-like data? Custom Python objects?\r\n\r\nAll text, numbers, and timestamps, and no custom python objects. Here's the distribution of types per column (206 columns total), in terms of the count of columns that are comprised of a given set of types, which there are only 8 of:\r\n- (From https://gist.github.com/jdanbrown/a012927eb0d286ced308912370c0fc37)\r\n```py\r\n>>> df['types'].value_counts()\r\n\r\nNoneType, str                  100\r\nfloat                           67\r\nNoneType, list[], list[str]     16\r\nstr                              9\r\nNaTType, Timestamp               9\r\nTimestamp                        3\r\nlist[], list[str]                2\r\nint                              1\r\nName: types, dtype: int64\r\n```\r\n\r\nAnd here's a more detailed unpacking of each column with its mean size per value:\r\n- (From https://gist.github.com/jdanbrown/a012927eb0d286ced308912370c0fc37)\r\n```py\r\n>>> df.sort_values('mean_size', ascending=False)\r\n\r\n         mean_size                        types\r\ncol_130    500.707                NoneType, str\r\ncol_129    161.355                NoneType, str\r\ncol_45     149.221                NoneType, str\r\ncol_27     104.002           NaTType, Timestamp\r\ncol_102    104.002                    Timestamp\r\ncol_122    104.002           NaTType, Timestamp\r\ncol_54     104.002           NaTType, Timestamp\r\ncol_120    104.002           NaTType, Timestamp\r\ncol_53     104.002           NaTType, Timestamp\r\ncol_127    104.002           NaTType, Timestamp\r\ncol_88     104.002                    Timestamp\r\ncol_173    104.002           NaTType, Timestamp\r\ncol_110    104.002           NaTType, Timestamp\r\ncol_109    104.002                    Timestamp\r\ncol_32     104.002           NaTType, Timestamp\r\ncol_82      98.263  NoneType, list[], list[str]\r\ncol_111     93.002                          str\r\ncol_2       93.002                          str\r\ncol_157     82.367                NoneType, str\r\ncol_144     78.460            list[], list[str]\r\n...\r\ncol_66      32.002                        float\r\ncol_163     32.002                        float\r\ncol_160     32.002                        float\r\ncol_158     32.002                        float\r\ncol_63      32.002                        float\r\ncol_75      32.002                        float\r\ncol_65      32.002                        float\r\ncol_103     32.002                        float\r\ncol_152     32.002                        float\r\ncol_150     32.002                        float\r\ncol_68      32.002                        float\r\ncol_69      32.002                        float\r\ncol_159     30.155                NoneType, str\r\ncol_162     29.534                NoneType, str\r\ncol_200     28.546                NoneType, str\r\ncol_161     28.368                NoneType, str\r\ncol_164     27.727                NoneType, str\r\ncol_180     27.037                NoneType, str\r\ncol_183     24.971                NoneType, str\r\ncol_175     24.002                NoneType, str\r\n```\r\n\r\n### Answer 2\r\n> 2. Can you take a look at one of the diagnostic servers for one of the workers? This is typically served at port 8789 on any of the worker machines. You might find the bottom plot on the /main page of interest during communication heavy work.\r\n\r\nHmm, I ran two more trials and collected some (partial) data from some of the worker `/main` pages, but nothing jumps out at me as fishy.\r\n- Lots of peer communication, but that's expected.\r\n- Both failed faster than above with `KilledWorker`, perhaps because I upgraded to the latest master commits for these trials.\r\n\r\n| params | outcome | task counts | task aftermath | sys metrics | worker 1/16 | worker 2/16 | worker 3/16 | worker 4/16 | worker 5/16 | worker 6/16 | worker 7/16 | worker 8/16 | worker 9/16 | worker 10/16 | worker 11/16 | worker 12/16 | worker 13/16 | worker 14/16 |\r\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\r\n| 238&nbsp;parts&nbsp;in <br> 128&nbsp;parts&nbsp;out <br> 4g&nbsp;mem&nbsp;limit <br> 8g&nbsp;mem<br> 16 workers | 12&nbsp;OOMs <br> ~25m <br> `KilledWorker` || ![tasks 4g 128 z](https://user-images.githubusercontent.com/627486/27318738-f08b323a-5542-11e7-832a-d94333f40aba.png) | ![datadog 4g 128 z](https://user-images.githubusercontent.com/627486/27318739-f08b6660-5542-11e7-8ce5-5c988e9916d1.png) | ![worker 1 z](https://user-images.githubusercontent.com/627486/27318745-f0aaafa2-5542-11e7-81c2-6b4da1b917c4.png) | ![worker 2 z](https://user-images.githubusercontent.com/627486/27318743-f0a4eb9e-5542-11e7-920c-552fe4998c19.png) | ![worker 4 z](https://user-images.githubusercontent.com/627486/27318741-f09e97ee-5542-11e7-9301-6431b2404c58.png) | ![worker 3 z](https://user-images.githubusercontent.com/627486/27318742-f0a057f0-5542-11e7-9e02-e3fad20a498d.png) |\r\n| 238&nbsp;parts&nbsp;in <br> 128&nbsp;parts&nbsp;out <br> 4g&nbsp;mem&nbsp;limit <br> 8g&nbsp;mem<br> 16 workers | 18&nbsp;OOMs <br> ~25m <br> `KilledWorker` | ![dask 4g 128 y](https://user-images.githubusercontent.com/627486/27318765-f6ef913e-5542-11e7-91c0-e96cdb37d092.png) | ![tasks 4g 128 y](https://user-images.githubusercontent.com/627486/27318766-f6f32a60-5542-11e7-9d5c-ba45eea8fcdc.png) | ![datadog 4g 128 y](https://user-images.githubusercontent.com/627486/27318750-f6a84d24-5542-11e7-9d6a-54cba2d615e7.png) | ![worker 1 y](https://user-images.githubusercontent.com/627486/27318751-f6bc8122-5542-11e7-9e16-ac864a989259.png) | ![worker 2 y](https://user-images.githubusercontent.com/627486/27318752-f6c58664-5542-11e7-83bc-8df47bd1e775.png) | ![worker 3 y](https://user-images.githubusercontent.com/627486/27318754-f6c7a494-5542-11e7-921d-67c25e37c9c0.png) | ![worker 4 y](https://user-images.githubusercontent.com/627486/27318753-f6c622fe-5542-11e7-8012-84427a4f99d0.png) | ![worker 5 y](https://user-images.githubusercontent.com/627486/27318755-f6c82086-5542-11e7-9a22-2bd4ac40682f.png) | ![worker 6 y](https://user-images.githubusercontent.com/627486/27318756-f6cbcad8-5542-11e7-94c9-ec91fa33936c.png) | ![worker 7 y](https://user-images.githubusercontent.com/627486/27318757-f6cf4a46-5542-11e7-8025-d4326585c3c5.png) | ![worker 8 y](https://user-images.githubusercontent.com/627486/27318758-f6d9d6b4-5542-11e7-8f80-ffb1574dbfae.png) | ![worker 9 y](https://user-images.githubusercontent.com/627486/27318760-f6dc5236-5542-11e7-91cb-0f4afdcb2a10.png) | ![worker 10 y](https://user-images.githubusercontent.com/627486/27318759-f6dacefc-5542-11e7-9b46-fd758b14e37f.png) | ![worker 11 y](https://user-images.githubusercontent.com/627486/27318762-f6e179d2-5542-11e7-8474-e4fd833870f3.png) | ![worker 12 y](https://user-images.githubusercontent.com/627486/27318761-f6dea036-5542-11e7-8bec-2d5c0dc7991e.png) | ![worker 13 y](https://user-images.githubusercontent.com/627486/27318763-f6e7ce86-5542-11e7-9740-ac80cb50628f.png) | ![worker 14 y](https://user-images.githubusercontent.com/627486/27318764-f6ed70ac-5542-11e7-9b9b-cd6a87ad260d.png) |\r\n\r\n### Questions\r\n- Do you see anything informative in those worker `/main` pages?\r\n- What else should I try to diagnose this further?\r\n- What should I try to workaround the issue in the short term, in parallel with diagnosing? (Like, just throw more ram at it?)",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/309657133/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/309667474",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-309667474",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 309667474,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMwOTY2NzQ3NA==",
        "user": {
            "login": "jdanbrown",
            "id": 627486,
            "node_id": "MDQ6VXNlcjYyNzQ4Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/627486?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jdanbrown",
            "html_url": "https://github.com/jdanbrown",
            "followers_url": "https://api.github.com/users/jdanbrown/followers",
            "following_url": "https://api.github.com/users/jdanbrown/following{/other_user}",
            "gists_url": "https://api.github.com/users/jdanbrown/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jdanbrown/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jdanbrown/subscriptions",
            "organizations_url": "https://api.github.com/users/jdanbrown/orgs",
            "repos_url": "https://api.github.com/users/jdanbrown/repos",
            "events_url": "https://api.github.com/users/jdanbrown/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jdanbrown/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-06-20T07:22:59Z",
        "updated_at": "2017-06-20T22:05:49Z",
        "author_association": "NONE",
        "body": "Another datapoint, which also answers my 3rd question:\r\n- Got no OOMs by doubling mem and ~halving workers (meant to get 8 but only got 7)\r\n\r\n| params | outcome | task counts | task aftermath | sys metrics |\r\n|---|---|---|---|---|\r\n| 238&nbsp;parts&nbsp;in <br> 128&nbsp;parts&nbsp;out <br> 4g&nbsp;mem&nbsp;limit <br> 16g&nbsp;mem<br> 7 workers | 0&nbsp;OOMs <br> 28m <br> success | ![dask 4g 128 x](https://user-images.githubusercontent.com/627486/27321221-3e1ce1e6-554e-11e7-9f2e-c16879deb331.png) | ![tasks 4g 128 x](https://user-images.githubusercontent.com/627486/27321167-069a6234-554e-11e7-9e6e-f9540fea6cc5.png) | ![datadog 4g 128 x](https://user-images.githubusercontent.com/627486/27321168-069a87e6-554e-11e7-8fe8-39e4b915b434.png) |\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/309667474/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/309777857",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-309777857",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 309777857,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMwOTc3Nzg1Nw==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-06-20T14:38:58Z",
        "updated_at": "2017-06-20T14:38:58Z",
        "author_association": "MEMBER",
        "body": "FYI I am out this week with limited connectivity.  I may not respond to\nthis for a week.  My apologies for the lack of response.  (these are great\nfigures by the way and I'm sure will be of great use shortly)\n\nOn Tue, Jun 20, 2017 at 3:23 AM, Dan Brown <notifications@github.com> wrote:\n\n> Another datapoint, which also answers my 3rd question:\n>\n>    - Got no OOMs by doubling mem and ~halving workers (meant to get 8 but\n>    only got 7)\n>\n> params outcome task counts task aftermath sys metrics\n> 238 parts in\n> 128 parts out\n> 4g mem limit\n> 16g mem\n> 7 workers 0 OOMs\n> 28m\n> success [image: tasks 4g 128 x]\n> <https://user-images.githubusercontent.com/627486/27321167-069a6234-554e-11e7-9e6e-f9540fea6cc5.png> [image:\n> dask 4g 128 x]\n> <https://user-images.githubusercontent.com/627486/27321221-3e1ce1e6-554e-11e7-9f2e-c16879deb331.png> [image:\n> datadog 4g 128 x]\n> <https://user-images.githubusercontent.com/627486/27321168-069a87e6-554e-11e7-8fe8-39e4b915b434.png>\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/dask/dask/issues/2456#issuecomment-309667474>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/AASszITtFuEe-qaG7H2t930CLtixdHDvks5sF3NUgaJpZM4N65rg>\n> .\n>\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/309777857/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/310942670",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-310942670",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 310942670,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMxMDk0MjY3MA==",
        "user": {
            "login": "jdanbrown",
            "id": 627486,
            "node_id": "MDQ6VXNlcjYyNzQ4Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/627486?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jdanbrown",
            "html_url": "https://github.com/jdanbrown",
            "followers_url": "https://api.github.com/users/jdanbrown/followers",
            "following_url": "https://api.github.com/users/jdanbrown/following{/other_user}",
            "gists_url": "https://api.github.com/users/jdanbrown/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jdanbrown/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jdanbrown/subscriptions",
            "organizations_url": "https://api.github.com/users/jdanbrown/orgs",
            "repos_url": "https://api.github.com/users/jdanbrown/repos",
            "events_url": "https://api.github.com/users/jdanbrown/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jdanbrown/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-06-26T01:25:14Z",
        "updated_at": "2017-06-26T01:25:14Z",
        "author_association": "NONE",
        "body": "Another unsuccessful approach at solving the \"4g mem limit, 8g mem, 16 workers\" case:\r\n- Context: all trials above are running in docker containers (on k8s on ec2), and `psutil` reports host metrics, not container metrics\r\n  - https://fabiokung.com/2014/03/13/memory-inside-linux-containers/\r\n  - https://github.com/giampaolo/psutil/issues/1011\r\n  - Indeed, the scheduler `/workers` page shows \"memory: 64 GiB\", which is our k8s host ram, instead of the pod's container mem (one of 4/8/16 GiB in the various trials above)\r\n- Hypothesis: even though we're setting `--memory-limit`, other parts of dask are seeing `psutil.virtual_memory().total` = 64GiB and allocating more than they would have otherwise, which is causing OOMs, e.g. `max_buffer_size` in `distributed.comm.tcp`\r\n  - https://github.com/dask/distributed/blob/7639469/distributed/comm/tcp.py#L33\r\n  - https://github.com/dask/distributed/blob/7639469/distributed/comm/tcp.py#L38\r\n  - https://github.com/dask/distributed/blob/7639469/distributed/comm/tcp.py#L276-L278\r\n  - https://github.com/dask/distributed/blob/7639469/distributed/comm/tcp.py#L321-L322\r\n- So I made a hacked version of `psutil` where `virtual_memory()` returns metrics from `/sys/fs/cgroup/memory` instead of `/proc`, and verified that I saw \"memory: 8 GiB\" on the `/workers` page\r\n- But I ran the \"4g mem limit, 8g mem, 16 workers\" trial like above (https://github.com/dask/dask/issues/2456#issuecomment-309657133) and I still see multiple OOMs once the data starts shuffling (~15m into the job), similar to how it behaved without the `psutil` hack",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/310942670/reactions",
            "total_count": 2,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/312738474",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-312738474",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 312738474,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMxMjczODQ3NA==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-07-03T21:41:59Z",
        "updated_at": "2017-07-03T21:41:59Z",
        "author_association": "MEMBER",
        "body": "Hey, sorry for the delay in getting to this.  It dropped off of my radar in the confusion of vacation two weeks ago.  \r\n\r\nThe fact that the worker-memory-plot (upper left) is red says that Dask knows that its workers are out of memory.  The workers are actively sending things to disk, they're just not sending things fast enough to avoid OOM-ing.  We should probably have a separate coroutine running that tracks used memory using `psutil` and starts to slow things down if we get close to the upper limit.  Obviously there are cases where our `sizeof` computations are failing, or we're not accounting for memory use in other components, such as data-in-flight.\r\n\r\nSomething that would be interesting to try is a shuffle on purely numeric data\r\n\r\n```python\r\nimport dask.array as da\r\nimport dask.dataframe as dd\r\n\r\nx = da.random.randint(0, 100000, size=(N, 10), chunks=(100000, 10))\r\ndf = dd.from_dask_array(x)\r\ndf2 = df.set_index(0).persist()\r\n```\r\n\r\nI would set `N` sufficiently high so that it overwhelms your available memory.  This would help us to see if there is a problem with how we're accounting for data (accounting for ints is easy) or something else.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/312738474/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/315079942",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-315079942",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 315079942,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTA3OTk0Mg==",
        "user": {
            "login": "avaranovich",
            "id": 963035,
            "node_id": "MDQ6VXNlcjk2MzAzNQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/963035?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/avaranovich",
            "html_url": "https://github.com/avaranovich",
            "followers_url": "https://api.github.com/users/avaranovich/followers",
            "following_url": "https://api.github.com/users/avaranovich/following{/other_user}",
            "gists_url": "https://api.github.com/users/avaranovich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/avaranovich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/avaranovich/subscriptions",
            "organizations_url": "https://api.github.com/users/avaranovich/orgs",
            "repos_url": "https://api.github.com/users/avaranovich/repos",
            "events_url": "https://api.github.com/users/avaranovich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/avaranovich/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-07-13T13:37:23Z",
        "updated_at": "2017-07-13T13:37:23Z",
        "author_association": "NONE",
        "body": "@jdanbrown Indeed, if you run workers as replicas in Kubernetes, each of the workers by default gets the host stats. In my case I run 10 workers, and I get my HOST RAM * 10, which is wrong. My current understanding is that dask should support docker metrics https://docs.docker.com/engine/admin/runmetrics/ , i.e. use docker API to pull the resource consumption by the container, and not the host. But I did not have time to implement this yet.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/315079942/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/315096975",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-315096975",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 315096975,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTA5Njk3NQ==",
        "user": {
            "login": "martindurant",
            "id": 6042212,
            "node_id": "MDQ6VXNlcjYwNDIyMTI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6042212?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/martindurant",
            "html_url": "https://github.com/martindurant",
            "followers_url": "https://api.github.com/users/martindurant/followers",
            "following_url": "https://api.github.com/users/martindurant/following{/other_user}",
            "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions",
            "organizations_url": "https://api.github.com/users/martindurant/orgs",
            "repos_url": "https://api.github.com/users/martindurant/repos",
            "events_url": "https://api.github.com/users/martindurant/events{/privacy}",
            "received_events_url": "https://api.github.com/users/martindurant/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-07-13T14:36:28Z",
        "updated_at": "2017-07-13T14:36:28Z",
        "author_association": "MEMBER",
        "body": "psutil uses standard system tools, which get the wrong answers within a container.\r\nCan you look at `/sys/fs/cgroup/memory/memory.*` inside containers to see if the values there look reasonable?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/315096975/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/315099337",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-315099337",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 315099337,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTA5OTMzNw==",
        "user": {
            "login": "martindurant",
            "id": 6042212,
            "node_id": "MDQ6VXNlcjYwNDIyMTI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6042212?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/martindurant",
            "html_url": "https://github.com/martindurant",
            "followers_url": "https://api.github.com/users/martindurant/followers",
            "following_url": "https://api.github.com/users/martindurant/following{/other_user}",
            "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions",
            "organizations_url": "https://api.github.com/users/martindurant/orgs",
            "repos_url": "https://api.github.com/users/martindurant/repos",
            "events_url": "https://api.github.com/users/martindurant/events{/privacy}",
            "received_events_url": "https://api.github.com/users/martindurant/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-07-13T14:44:35Z",
        "updated_at": "2017-07-13T14:44:35Z",
        "author_association": "MEMBER",
        "body": "(note that dask-kubernetes always passes `--memory-limit` to each worker in a container that is a bit smaller than the container configured size, and this is probably generally good practice)",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/315099337/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/316960861",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-316960861",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 316960861,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMxNjk2MDg2MQ==",
        "user": {
            "login": "jdanbrown",
            "id": 627486,
            "node_id": "MDQ6VXNlcjYyNzQ4Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/627486?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jdanbrown",
            "html_url": "https://github.com/jdanbrown",
            "followers_url": "https://api.github.com/users/jdanbrown/followers",
            "following_url": "https://api.github.com/users/jdanbrown/following{/other_user}",
            "gists_url": "https://api.github.com/users/jdanbrown/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jdanbrown/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jdanbrown/subscriptions",
            "organizations_url": "https://api.github.com/users/jdanbrown/orgs",
            "repos_url": "https://api.github.com/users/jdanbrown/repos",
            "events_url": "https://api.github.com/users/jdanbrown/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jdanbrown/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-07-21T10:00:41Z",
        "updated_at": "2017-07-21T10:00:41Z",
        "author_association": "NONE",
        "body": "@mrocklin No worries, and sorry for the delay on my end as well\u2014been busy juggling multiple projects.\r\n\r\n- Here's a small and isolated repro you can run that I believe shows that `sizeof` isn't the issue, since it hacks the workers' `self.data` to remove their `zict.Buffer` entirely so they're forced to spill all keys to disk.\r\n- I start seeing OOMs when I increase the ddf size to be roughly close to the total worker mem. Ideally disk would let us shuffle a dataset much larger than ram, like vanilla mapreduce.\r\n- To make the repro fast to iterate on, I used 8 workers with 512MB mem each (on a k8s cluster in ec2). Hopefully this is informative and not pathological.\r\n\r\n| cols | part_rows | nparts | &rarr; | part_size | time | ddf_size | max sum \"Bytes stored\" | OOMs |\r\n|---|---|---|---|---|---|---|---|---|\r\n| 10 | 157500 | 128  | &rarr; | 12m  | 40s | 1.5g | ~2g | 0  |\r\n| 10 | 157500 | 256  | &rarr; | 12m  | ~1m | 3g   | ~4g | \u22651 |\r\n| 10 | 157500 | 512  | &rarr; | 12m  | ~1m | 6g   | >6g | \u22651 |\r\n| 10 | 157500 | 1024 | &rarr; | 12m  | ~1m | 12g  | >6g | \u22651 |\r\n| 10 | 157500 | 2048 | &rarr; | 12m  | ~1m | 24g  | >6g | \u22651 |\r\n\r\n```py\r\n# Pick params as per table above\r\ncols = ...\r\npart_rows = ...\r\nnparts = ...\r\n\r\nimport dask.dataframe as dd\r\nimport distributed\r\nfrom dask import delayed\r\n\r\nclient = distributed.Client(...)\r\n\r\n# Force workers to spill to disk for every key write\r\n#   - Code ref: distributed/worker.py:119 -> zict/buffer.py\r\ndef worker_disable_mem_buffer(worker):\r\n    if hasattr(worker.data, 'slow'):\r\n        worker._data_orig = worker.data\r\n        worker.data = worker.data.slow\r\n    return str(worker.data)\r\nprint(client.run(lambda: [\r\n    worker_disable_mem_buffer(worker()) for worker in distributed.worker._global_workers\r\n]))\r\n\r\n# Synthesize a ddf of random ints\r\nmax_int = 1024**2\r\nddf = dd.from_delayed(meta={col: 'int64' for col in range(cols)}, dfs=[\r\n    delayed(lambda: pd.DataFrame({\r\n        col: np.random.randint(0, max_int, part_rows)\r\n        for col in range(cols)\r\n    }))()\r\n    for _ in range(nparts)\r\n])\r\n\r\n# Compute a shuffle on a column of random ints\r\n#   - Specify divisions so (a) we only compute once and (b) we ensure balanced tasks\r\ndivisions = {\r\n    n: list(range(0, max_int, max_int // n)) + [max_int]\r\n    for n in [2**i for i in range(13)]\r\n}\r\nddf2 = ddf.set_index(0, divisions=divisions[nparts])\r\nprint(ddf2.count().compute())\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/316960861/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/316961871",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-316961871",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 316961871,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMxNjk2MTg3MQ==",
        "user": {
            "login": "jdanbrown",
            "id": 627486,
            "node_id": "MDQ6VXNlcjYyNzQ4Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/627486?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jdanbrown",
            "html_url": "https://github.com/jdanbrown",
            "followers_url": "https://api.github.com/users/jdanbrown/followers",
            "following_url": "https://api.github.com/users/jdanbrown/following{/other_user}",
            "gists_url": "https://api.github.com/users/jdanbrown/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jdanbrown/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jdanbrown/subscriptions",
            "organizations_url": "https://api.github.com/users/jdanbrown/orgs",
            "repos_url": "https://api.github.com/users/jdanbrown/repos",
            "events_url": "https://api.github.com/users/jdanbrown/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jdanbrown/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-07-21T10:04:57Z",
        "updated_at": "2017-07-21T10:04:57Z",
        "author_association": "NONE",
        "body": "@martindurant Yep, in my k8s docker container `/sys/fs/cgroup/memory/memory.limit_in_bytes` does report the correct mem limit for the pod, unlike `/proc/meminfo` which reports the host metrics.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/316961871/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/320550889",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-320550889",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 320550889,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDU1MDg4OQ==",
        "user": {
            "login": "jdanbrown",
            "id": 627486,
            "node_id": "MDQ6VXNlcjYyNzQ4Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/627486?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jdanbrown",
            "html_url": "https://github.com/jdanbrown",
            "followers_url": "https://api.github.com/users/jdanbrown/followers",
            "following_url": "https://api.github.com/users/jdanbrown/following{/other_user}",
            "gists_url": "https://api.github.com/users/jdanbrown/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jdanbrown/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jdanbrown/subscriptions",
            "organizations_url": "https://api.github.com/users/jdanbrown/orgs",
            "repos_url": "https://api.github.com/users/jdanbrown/repos",
            "events_url": "https://api.github.com/users/jdanbrown/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jdanbrown/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-08-07T02:02:24Z",
        "updated_at": "2017-08-07T02:02:24Z",
        "author_association": "NONE",
        "body": "@mrocklin Any thoughts on my most recent comment above (https://github.com/dask/dask/issues/2456#issuecomment-316960861)? It seems to indicate this is a task-shuffle issue and not a sizeof issue.\r\n\r\nMore generally, my team is looking for ways to safely shuffle datasets that are bigger than total worker ram. Our main pipeline is an iterative model fit on training data that easily partitions across workers' ram and works great with dask, but to get that training data we have to go through a series of more traditional ETL munging steps that require shuffles (`.set_index`, `.merge`) at various points, and that's where we've been struggling with OOMs. We've incurred a lot of incidental complexity as a result of our shuffle operations being very delicate, and overall the OOM issue has been a major drag on our development pace.\r\n\r\nAny pointers or suggestions? Are we too far off the happy path of well tread use cases? We'd love to be able to make dask a go-to tool for our broader data team.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/320550889/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/320554631",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-320554631",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 320554631,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDU1NDYzMQ==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-08-07T02:34:18Z",
        "updated_at": "2017-08-07T02:34:18Z",
        "author_association": "MEMBER",
        "body": "Sorry for the lack of response on this.  I'll try to take a look at this either Tuesday or Wednesday this week.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/320554631/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/320556026",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-320556026",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 320556026,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDU1NjAyNg==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-08-07T02:46:50Z",
        "updated_at": "2017-08-07T02:46:50Z",
        "author_association": "MEMBER",
        "body": "Looking at this again, it looks like you may be running into issues similar to @bluenote10 \r\n\r\nYou might find the following issues and PRs of interest:\r\n\r\n- https://github.com/dask/distributed/issues/1015\r\n- https://github.com/dask/zict/issues/19\r\n- https://github.com/dask/distributed/pull/1235\r\n- https://github.com/dask/distributed/pull/1255",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/320556026/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/320558185",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-320558185",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 320558185,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDU1ODE4NQ==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-08-07T03:07:07Z",
        "updated_at": "2017-08-07T03:07:17Z",
        "author_association": "MEMBER",
        "body": "Those issues point to a possible narrative that Pandas and the Python garbage collector sometimes leave data lying around for longer than they should.  Periodically calling `gc.collect()` at the right times can reduce this cost, but this can play havoc with Dask in other hard-to-pin-down ways.  \r\n\r\nAnother possibility is that the data that is in-flight is large enough to push things over the edge.  Dask isn't able to account for this data.  I wouldn't expect this to be that large though.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/320558185/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/320572591",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-320572591",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 320572591,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDU3MjU5MQ==",
        "user": {
            "login": "jdanbrown",
            "id": 627486,
            "node_id": "MDQ6VXNlcjYyNzQ4Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/627486?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jdanbrown",
            "html_url": "https://github.com/jdanbrown",
            "followers_url": "https://api.github.com/users/jdanbrown/followers",
            "following_url": "https://api.github.com/users/jdanbrown/following{/other_user}",
            "gists_url": "https://api.github.com/users/jdanbrown/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jdanbrown/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jdanbrown/subscriptions",
            "organizations_url": "https://api.github.com/users/jdanbrown/orgs",
            "repos_url": "https://api.github.com/users/jdanbrown/repos",
            "events_url": "https://api.github.com/users/jdanbrown/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jdanbrown/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-08-07T05:33:56Z",
        "updated_at": "2017-08-07T05:33:56Z",
        "author_association": "NONE",
        "body": "Hmm, I think this issue is separate from all 4 of the issues you linked since I was able to remove `worker.data.fast` from the question entirely, which iiuc is the pivotal issue in those 4.\r\n\r\nHere's a summary of the thread above, since it's a long one:\r\n- A simple shuffle triggers OOMs \u2013\u00a0https://github.com/dask/dask/issues/2456 (top)\r\n- Increasing ram does suffice to avoid the OOMs, but we want to be able to shuffle more data than ram \u2013\u00a0https://github.com/dask/dask/issues/2456#issuecomment-309667474\r\n- We're running on linux inside docker containers (inside k8s on ec2), where `psutil.virtual_memory()` erroneously reports the host metrics instead of the container metrics, but I temporarily hacked psutil and observed that the OOMs still happen even if it correctly reports the container metrics \u2013\u00a0https://github.com/dask/dask/issues/2456#issuecomment-310942670\r\n- I've narrowed the OOM repro down to a shuffle on a ddf of `int` values that spills all tasks to disk, which should rule out both `sizeof` and `worker.data.fast` as culprits (note that this is back with normal psutil, so do try repro'ing on your end) \u2013\u00a0https://github.com/dask/dask/issues/2456#issuecomment-316960861\r\n\r\nThanks @mrocklin!",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/320572591/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/320691008",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-320691008",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 320691008,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDY5MTAwOA==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-08-07T15:10:31Z",
        "updated_at": "2017-08-07T15:10:31Z",
        "author_association": "MEMBER",
        "body": "I don't think this has to do with psutil reporting wrong metrics.  Both of the explanations above I think remain possible causes.  The discussion on zict shows that pandas can leave some data lying around.\r\n\r\nMy early attempt to run your example above behaved fine (stayed well below memory limits) but I'll try other parameters.  This may not happen today though, I'm finishing up some vacation time and flying home today.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/320691008/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/320696475",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-320696475",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 320696475,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDY5NjQ3NQ==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-08-07T15:30:20Z",
        "updated_at": "2017-08-07T15:30:20Z",
        "author_association": "MEMBER",
        "body": "You might try an equivalent computation with dask.array.  A rechunk operation has the same communcation pattern as a dask.dataframe shuffle.  However rather than using pandas it will use numpy, which tends to behave a little nicer.  This would help to isolate the problem between dask book keeping and pandas+python book-keeping.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/320696475/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/320696743",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-320696743",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 320696743,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDY5Njc0Mw==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-08-07T15:31:14Z",
        "updated_at": "2017-08-07T15:31:14Z",
        "author_association": "MEMBER",
        "body": "```python\r\nx = da.random.random((N, N), chunks=(N, 1))\r\ny = x.rechunk((1, N)).persist()\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/320696743/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/320988341",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-320988341",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 320988341,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDk4ODM0MQ==",
        "user": {
            "login": "bluenote10",
            "id": 3620703,
            "node_id": "MDQ6VXNlcjM2MjA3MDM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3620703?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bluenote10",
            "html_url": "https://github.com/bluenote10",
            "followers_url": "https://api.github.com/users/bluenote10/followers",
            "following_url": "https://api.github.com/users/bluenote10/following{/other_user}",
            "gists_url": "https://api.github.com/users/bluenote10/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bluenote10/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bluenote10/subscriptions",
            "organizations_url": "https://api.github.com/users/bluenote10/orgs",
            "repos_url": "https://api.github.com/users/bluenote10/repos",
            "events_url": "https://api.github.com/users/bluenote10/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bluenote10/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-08-08T15:16:49Z",
        "updated_at": "2017-08-08T15:22:37Z",
        "author_association": "CONTRIBUTOR",
        "body": "I'm starting to think that there may be multiple effects involved. Note that the GC issues are mainly related to `worker.data.slow`, so they might play a role in your case as well.\r\n\r\nHowever, the GC issue alone also does not fully explain the behavior. I'm running with a patched version that performs explicit GC, which has lowered the memory usage on the workers significantly. However, it is still not enough to fully solve the problem. The following plots show RSS over time for 75 workers using a 2 GB `--memory-limit` given a 16 GB physical memory limit:\r\n\r\n![2017-08-08_daskrunall](https://user-images.githubusercontent.com/3620703/29078800-b12b71b4-7c5b-11e7-8458-318011b9bb97.png)\r\n\r\nThe majority of the workers are at around ~2 * memory_limit for most of the time. However some individual workers show very sudden jumps in their memory usage, which eventually makes them go OOM:\r\n\r\n![2017-08-08_daskrunkilledworker](https://user-images.githubusercontent.com/3620703/29078817-b4b9d0aa-7c5b-11e7-99ad-ce153df6fc36.png)\r\n\r\nThe algorithm performs the same logic in a loop (~15 minutes), so nothing really changes over time. Chunk sizes are below 50 MB, no rebalancing, no workers added/removed -- so it's hard to explain the sudden jumps/ramps in the memory usage. For comparison, many workers do behave as expected showing a memory profile like this:\r\n\r\n![2017-08-08_daskrungoodworker](https://user-images.githubusercontent.com/3620703/29078826-bc61bee4-7c5b-11e7-9c95-6db6ba10e6fb.png)\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/320988341/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/322042880",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-322042880",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 322042880,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMyMjA0Mjg4MA==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-08-13T13:41:21Z",
        "updated_at": "2017-08-13T13:41:21Z",
        "author_association": "MEMBER",
        "body": "@bluenote10 are you able to correlate the jumps with any particular event occurring in the worker logs?  Do you have any suspicions about what causes these jumps?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/322042880/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/322064809",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-322064809",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 322064809,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMyMjA2NDgwOQ==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-08-13T20:17:41Z",
        "updated_at": "2017-08-13T20:17:41Z",
        "author_association": "MEMBER",
        "body": "@bluenote10 I'm also curious to know if anything changes if you disable work stealing.  I've identified a small leak there.  I wouldn't expect it to result in sharp spikes like what you're seeing here, but it would be interesting to see if there is any difference.  \r\n\r\nSee https://github.com/dask/distributed/pull/1325 for how to disable work stealing (either by using the config option or just deleting the right line of code.)",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/322064809/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/323831512",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-323831512",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 323831512,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMyMzgzMTUxMg==",
        "user": {
            "login": "jdanbrown",
            "id": 627486,
            "node_id": "MDQ6VXNlcjYyNzQ4Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/627486?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jdanbrown",
            "html_url": "https://github.com/jdanbrown",
            "followers_url": "https://api.github.com/users/jdanbrown/followers",
            "following_url": "https://api.github.com/users/jdanbrown/following{/other_user}",
            "gists_url": "https://api.github.com/users/jdanbrown/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jdanbrown/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jdanbrown/subscriptions",
            "organizations_url": "https://api.github.com/users/jdanbrown/orgs",
            "repos_url": "https://api.github.com/users/jdanbrown/repos",
            "events_url": "https://api.github.com/users/jdanbrown/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jdanbrown/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-08-21T19:32:03Z",
        "updated_at": "2017-08-21T19:32:03Z",
        "author_association": "NONE",
        "body": "@mrocklin I haven't had time to test your dask.array hypothesis yet, but I'm very curious to. In the meantime, what's the setup you used to try my dask.dataframe repro? Above you said:\r\n> My early attempt to run your example above behaved fine (stayed well below memory limits) but I'll try other parameters.\r\n\r\nand I'm curious to see if I can repro your good behavior on my end.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/323831512/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/328623359",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-328623359",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 328623359,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMyODYyMzM1OQ==",
        "user": {
            "login": "jdanbrown",
            "id": 627486,
            "node_id": "MDQ6VXNlcjYyNzQ4Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/627486?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jdanbrown",
            "html_url": "https://github.com/jdanbrown",
            "followers_url": "https://api.github.com/users/jdanbrown/followers",
            "following_url": "https://api.github.com/users/jdanbrown/following{/other_user}",
            "gists_url": "https://api.github.com/users/jdanbrown/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jdanbrown/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jdanbrown/subscriptions",
            "organizations_url": "https://api.github.com/users/jdanbrown/orgs",
            "repos_url": "https://api.github.com/users/jdanbrown/repos",
            "events_url": "https://api.github.com/users/jdanbrown/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jdanbrown/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-09-11T18:50:26Z",
        "updated_at": "2017-09-23T18:26:41Z",
        "author_association": "NONE",
        "body": "@mrocklin Check it out\u2014I now have an OOM repro for array, bag, and dataframe:\r\n- All three OOM when total data volume roughly approaches or exceeds total worker ram, like my various ddf repros above\r\n- I dockerized everything so it's hopefully easy to repro on your end\r\n- I packaged it up in a repo: https://github.com/jdanbrown/dask-oom\r\n\r\nEager to hear your thoughts! Here's the summary (copied from the repo's [README](https://github.com/jdanbrown/dask-oom)):\r\n\r\n# Experimental setup\r\n- Latest stable dask+distributed versions ([requirements.txt](https://github.com/jdanbrown/dask-oom/blob/master/requirements.txt)):\r\n  - `dask==0.15.2`\r\n  - `distributed==1.18.3`\r\n- Use local docker containers to make a reproducible and portable distributed environment\r\n- Worker setup ([docker-compose.yml](https://github.com/jdanbrown/dask-oom/blob/master/docker-compose.yml)):\r\n  - 4 workers @ 1g mem + no swap (4g total worker ram)\r\n  - Default `--memory-limit` (each worker reports 0.584g)\r\n  - Limited to 1 concurrent task per worker, to minimize mem contention and oom risk\r\n- For each of ddf, dask array, and dask bag:\r\n  - Run a simple shuffle operation and test whether the operation succeeds or OOMs\r\n  - Test against increasing data volumes, from much smaller than total worker ram to slightly larger than total worker ram\r\n  - Try to keep partition sizes below ~10-15m, to control for oom risk from large partitions\r\n\r\n# Results\r\n\r\n### [oom_ddf.py](https://github.com/jdanbrown/dask-oom/blob/master/oom_ddf.py)\r\n\r\n| params | ddf_bytes | part_bytes | runtime | success/OOM?\r\n|---|---|---|---|---\r\n| `cols=10 part_rows=157500 nparts=64`  | .75g | 12m | 00:08  | success\r\n| `cols=10 part_rows=157500 nparts=128` | 1.5g | 12m | ~00:20 | usually&nbsp;OOM, sometimes&nbsp;success\r\n| `cols=10 part_rows=157500 nparts=256` | 3g   | 12m | ~00:20 | OOM\r\n| `cols=10 part_rows=157500 nparts=512` | 6g   | 12m | ~00:30 | OOM\r\n\r\n### [oom_array.py](https://github.com/jdanbrown/dask-oom/blob/master/oom_array.py)\r\n\r\n| params | da_bytes | chunk_bytes | chunk_n | chunk_shape | runtime | success/OOM?\r\n|---|---|---|---|---|---|---\r\n| `sqrt_n=64`  | 128m | 2m   | 64  | (4096, 64)   | 00:01  | success\r\n| `sqrt_n=96`  | 648m | 6.8m | 96  | (9216, 96)   | 00:03  | success\r\n| `sqrt_n=112` | 1.2g | 11m  | 112 | (12544, 112) | 00:05  | success\r\n| `sqrt_n=120` | 1.5g | 13m  | 120 | (14400, 120) | ~00:15 | usually&nbsp;OOM, rare&nbsp;success\r\n| `sqrt_n=128` | 2g   | 16m  | 128 | (16384, 128) | ~00:10 | OOM\r\n\r\n### [oom_bag.py](https://github.com/jdanbrown/dask-oom/blob/master/oom_bag.py)\r\n- Much slower than ddf and array, since simple bag operations are dominated by the overhead of python having to touch every record, whereas with ddfs and arrays python only has to process blocks of records (ddf part_df's / array chunks) and individual records are processed by native code (pandas / numpy)\r\n\r\n| params | bag_bytes | part_bytes | runtime | success/OOM?\r\n|---|---|---|---|---\r\n| `nparts=2`   | 25m  | 12m | 00:00:08 | success\r\n| `nparts=4`   | 49m  | 12m | 00:00:14 | success\r\n| `nparts=8`   | 98m  | 12m | 00:00:24 | success\r\n| `nparts=32`  | 394m | 12m | 00:01:53 | success\r\n| `nparts=64`  | 787m | 12m | 00:07:46 | success\r\n| `nparts=128` | 1.5g | 12m | 00:17:40 | success\r\n| `nparts=256` | 3.1g | 12m | 00:37:09 | success\r\n| `nparts=512` | 6.2g | 12m | 01:16:30 | OOM (first OOM ~57:00, then ~4 more OOMs before client saw `KilledWorker`)\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/328623359/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/328662713",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-328662713",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 328662713,
        "node_id": "MDEyOklzc3VlQ29tbWVudDMyODY2MjcxMw==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-09-11T21:23:27Z",
        "updated_at": "2017-09-11T21:23:27Z",
        "author_association": "MEMBER",
        "body": "Cool.  I really appreciate the work here.  I'm looking forward to taking a\nlook at this.  As a disclaimer I'm decently slammed this week but hope to\nhave some time next week.\n\nOn Mon, Sep 11, 2017 at 2:50 PM, Dan Brown <notifications@github.com> wrote:\n\n> @mrocklin <https://github.com/mrocklin> Check it out\u2014I now have an OOM\n> repro for array, bag, and dataframe:\n>\n>    - All three OOM when total data volume roughly approaches or exceeds\n>    total worker ram, like my various ddf repros above\n>    - I dockerized everything so it's hopefully easy to repro on your end\n>    - I packaged it up in a repo: https://github.com/jdanbrown/dask-oom\n>\n> Eager to hear your thoughts! Here's the summary (copied from the repo's\n> README <https://github.com/jdanbrown/dask-oom>):\n> Experimental setup\n>\n>    - Latest stable dask+distributed versions (requirements.txt\n>    <https://github.com/jdanbrown/dask-oom/blob/master/requirements.txt>):\n>       - dask==0.15.2\n>       - distributed==1.18.3\n>    - Use local docker containers to make a reproducible and portable\n>    distributed environment\n>    - Worker setup (docker-compose.yml\n>    <https://github.com/jdanbrown/dask-oom/blob/master/docker-compose.yml>):\n>\n>       - 4 workers @ 1g mem + no swap (4g total worker ram)\n>       - Default --memory-limit (each worker reports 0.584g)\n>       - Limited to 1 concurrent task per worker, to minimize mem\n>       contention and oom risk\n>    - For each of ddf, dask array, and dask bag:\n>       - Run a simple shuffle operation and test whether the operation\n>       succeeds or OOMs\n>       - Test against increasing data volumes, from much smaller than\n>       total worker ram to larger than total worker ram\n>       - Try to keep partition sizes below ~10-15m, to control for oom\n>       risk from large partitions\n>\n> Results oom_ddf.py\n> <https://github.com/jdanbrown/dask-oom/blob/master/oom_ddf.py>\n> params ddf_bytes part_bytes runtime success/OOM?\n> cols=10 part_rows=157500 nparts=64 .75g 12m 00:08 success\n> cols=10 part_rows=157500 nparts=128 1.5g 12m ~00:20 usually OOM,\n> sometimes success\n> cols=10 part_rows=157500 nparts=256 3g 12m ~00:20 OOM\n> cols=10 part_rows=157500 nparts=512 6g 12m ~00:30 OOM oom_array.py\n> <https://github.com/jdanbrown/dask-oom/blob/master/oom_array.py>\n> params da_bytes chunk_bytes chunk_n chunk_shape runtime success/OOM?\n> sqrt_n=64 128m 2m 64 (4096, 64) 00:01 success\n> sqrt_n=96 648m 6.8m 96 (9216, 96) 00:03 success\n> sqrt_n=112 1.2g 11m 112 (12544, 112) 00:05 success\n> sqrt_n=120 1.5g 13m 120 (14400, 120) ~00:15 usually OOM, rare success\n> sqrt_n=128 2g 16m 128 (16384, 128) ~00:10 OOM oom_bag.py\n> <https://github.com/jdanbrown/dask-oom/blob/master/oom_bag.py>\n>\n>    - Much slower than ddf and array, since bag operations are\n>    bottlenecked by more python execution\n>\n> params bag_bytes part_bytes runtime success/OOM?\n> nparts=2 25m 12m 00:00:08 success\n> nparts=4 49m 12m 00:00:14 success\n> nparts=8 98m 12m 00:00:24 success\n> nparts=32 394m 12m 00:01:53 success\n> nparts=64 787m 12m 00:07:46 success\n> nparts=128 1.5g 12m 00:17:40 success\n> nparts=256 3.1g 12m 00:37:09 success\n> nparts=512 6.2g 12m 01:16:30 OOM (first OOM ~57:00, then ~4 more OOMs\n> before client saw KilledWorker)\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/dask/dask/issues/2456#issuecomment-328623359>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/AASszEhWGGFroXH1g2ftE2pRxm4NlpHiks5shYD2gaJpZM4N65rg>\n> .\n>\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/328662713/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/341110462",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-341110462",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 341110462,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM0MTExMDQ2Mg==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2017-11-01T13:46:53Z",
        "updated_at": "2017-11-01T13:46:53Z",
        "author_association": "MEMBER",
        "body": "Note that there has been some good work in avoiding memory leaking when splitting many small pandas dataframes recently.  You might want to try out the master branch.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/341110462/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/379423672",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-379423672",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 379423672,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM3OTQyMzY3Mg==",
        "user": {
            "login": "Spacerat",
            "id": 141427,
            "node_id": "MDQ6VXNlcjE0MTQyNw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/141427?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Spacerat",
            "html_url": "https://github.com/Spacerat",
            "followers_url": "https://api.github.com/users/Spacerat/followers",
            "following_url": "https://api.github.com/users/Spacerat/following{/other_user}",
            "gists_url": "https://api.github.com/users/Spacerat/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Spacerat/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Spacerat/subscriptions",
            "organizations_url": "https://api.github.com/users/Spacerat/orgs",
            "repos_url": "https://api.github.com/users/Spacerat/repos",
            "events_url": "https://api.github.com/users/Spacerat/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Spacerat/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-04-07T01:47:08Z",
        "updated_at": "2018-04-07T01:47:08Z",
        "author_association": "NONE",
        "body": "I downloaded and reran `oom_ddf.py` from @jdanbrown 's repro today with `dask==0.17.2` and `distributed==1.21.5`, and it still OOMs.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/379423672/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/379425660",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-379425660",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 379425660,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM3OTQyNTY2MA==",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-04-07T02:22:34Z",
        "updated_at": "2018-04-07T02:22:34Z",
        "author_association": "MEMBER",
        "body": "If you have time to investigate this @Spacerat that would be most welcome",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/379425660/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/380881000",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-380881000",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 380881000,
        "node_id": "MDEyOklzc3VlQ29tbWVudDM4MDg4MTAwMA==",
        "user": {
            "login": "Spacerat",
            "id": 141427,
            "node_id": "MDQ6VXNlcjE0MTQyNw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/141427?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Spacerat",
            "html_url": "https://github.com/Spacerat",
            "followers_url": "https://api.github.com/users/Spacerat/followers",
            "following_url": "https://api.github.com/users/Spacerat/following{/other_user}",
            "gists_url": "https://api.github.com/users/Spacerat/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Spacerat/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Spacerat/subscriptions",
            "organizations_url": "https://api.github.com/users/Spacerat/orgs",
            "repos_url": "https://api.github.com/users/Spacerat/repos",
            "events_url": "https://api.github.com/users/Spacerat/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Spacerat/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2018-04-12T17:19:10Z",
        "updated_at": "2018-04-12T17:19:10Z",
        "author_association": "NONE",
        "body": "Although I would like to, unfortunately I do not have enough time right now; for us it was quicker to just port our problematic pipeline to use Go & some command-line tools. (Dask was probably not the right fit anyway.)",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/380881000/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/527235552",
        "html_url": "https://github.com/dask/dask/issues/2456#issuecomment-527235552",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/2456",
        "id": 527235552,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUyNzIzNTU1Mg==",
        "user": {
            "login": "denisvlah",
            "id": 12544479,
            "node_id": "MDQ6VXNlcjEyNTQ0NDc5",
            "avatar_url": "https://avatars.githubusercontent.com/u/12544479?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/denisvlah",
            "html_url": "https://github.com/denisvlah",
            "followers_url": "https://api.github.com/users/denisvlah/followers",
            "following_url": "https://api.github.com/users/denisvlah/following{/other_user}",
            "gists_url": "https://api.github.com/users/denisvlah/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/denisvlah/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/denisvlah/subscriptions",
            "organizations_url": "https://api.github.com/users/denisvlah/orgs",
            "repos_url": "https://api.github.com/users/denisvlah/repos",
            "events_url": "https://api.github.com/users/denisvlah/events{/privacy}",
            "received_events_url": "https://api.github.com/users/denisvlah/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-09-02T20:08:52Z",
        "updated_at": "2019-09-02T20:08:52Z",
        "author_association": "NONE",
        "body": "Having the same issues on dask version 2.1.0.\r\nEnvironment is almost the same as described by @jdanbrown.\r\n\r\nAny plans to fix this issue?\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/527235552/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]