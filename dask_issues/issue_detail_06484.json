{
    "url": "https://api.github.com/repos/dask/dask/issues/6484",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/6484/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/6484/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/6484/events",
    "html_url": "https://github.com/dask/dask/issues/6484",
    "id": 672817422,
    "node_id": "MDU6SXNzdWU2NzI4MTc0MjI=",
    "number": 6484,
    "title": "Parquet reading/writing is non-deterministic for multi-index frames",
    "user": {
        "login": "jqmp",
        "id": 42037,
        "node_id": "MDQ6VXNlcjQyMDM3",
        "avatar_url": "https://avatars.githubusercontent.com/u/42037?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/jqmp",
        "html_url": "https://github.com/jqmp",
        "followers_url": "https://api.github.com/users/jqmp/followers",
        "following_url": "https://api.github.com/users/jqmp/following{/other_user}",
        "gists_url": "https://api.github.com/users/jqmp/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/jqmp/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/jqmp/subscriptions",
        "organizations_url": "https://api.github.com/users/jqmp/orgs",
        "repos_url": "https://api.github.com/users/jqmp/repos",
        "events_url": "https://api.github.com/users/jqmp/events{/privacy}",
        "received_events_url": "https://api.github.com/users/jqmp/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 365513534,
            "node_id": "MDU6TGFiZWwzNjU1MTM1MzQ=",
            "url": "https://api.github.com/repos/dask/dask/labels/io",
            "name": "io",
            "color": "6f871c",
            "default": false,
            "description": ""
        },
        {
            "id": 2949099791,
            "node_id": "MDU6TGFiZWwyOTQ5MDk5Nzkx",
            "url": "https://api.github.com/repos/dask/dask/labels/parquet",
            "name": "parquet",
            "color": "77A66C",
            "default": false,
            "description": ""
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2020-08-04T14:02:19Z",
    "updated_at": "2021-10-13T06:04:59Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "The way Dask DataFrames are read/written in Parquet seems to have changed in 2.22.0. I'm not sure if this change was intended or if you'll agree it's a bug, but for my particular use case it feels like a regression.\r\n\r\n**What happened**:\r\n\r\nWhen I write a multi-index Dask DataFrame to Parquet and then read it back, the sub-indices are sometimes in the wrong order. The order is non-deterministic and seems to be driven by the [Python hash seed](https://docs.python.org/3.3/using/cmdline.html#envvar-PYTHONHASHSEED).\r\n\r\n(I'm aware that the Pandas MultiIndex is not supported in Dask, but this situation can arise after doing a `groupby` on multiple columns, which Dask will happily do. Maybe I just don't understand what usages are intended to be supported here. In my personal view, if Dask can't provide a deterministic index structure, it would much better to produce a warning or exception before doing something non-deterministic. It's natural to write to Pandas code that depends on the order of sub-indices and this code will now break non-deterministically.)\r\n\r\n**What you expected to happen**:\r\n\r\nOn versions of Dask before 2.22.0, Dask would emit a warning and fail to load any index at all.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\nHere is a Pytest test that passes or fails non-deterministically:\r\n\r\n```python\r\nimport dask.dataframe as dd\r\nimport pandas as pd\r\n\r\ndef test_dask_problem(tmpdir):\r\n    # Construct a Dask DataFrame with a multi-index.\r\n    raw_df = pd.DataFrame(\r\n        columns=[\"color\", \"shape\"],\r\n        data=[\r\n            [\"red\", \"square\"],\r\n            [\"blue\", \"circle\"],\r\n        ],\r\n    )\r\n    dask_raw_df = dd.from_pandas(raw_df, npartitions=1)\r\n    dask_counts_df = dask_raw_df.groupby([\"color\", \"shape\"]).size().to_frame(\"count\")\r\n\r\n    # Write it to Parquet, read it back, and convert it to Pandas.\r\n    path = tmpdir / 'df.pq'\r\n    dd.to_parquet(dask_counts_df, str(path), write_index=True)\r\n    dask_counts_df_from_file = dd.read_parquet(str(path))\r\n    counts_df_from_file = dask_counts_df_from_file.compute()\r\n\r\n    # Check that the index structure is as expected.\r\n    print(counts_df_from_file)\r\n    assert counts_df_from_file.index.names == ('color', 'shape')\r\n```\r\n\r\nI can make it always pass or always fail by setting `PYTHONHASHSEED`:\r\n\r\n`PYTHONHASHSEED=0 pytest -k test_dask_problem  # Always passes.`\r\n`PYTHONHASHSEED=1 pytest -k test_dask_problem  # Always fails.`\r\n\r\n**Anything else we need to know?**:\r\n\r\nThe reason this is a problem for me is that I work on a [framework](https://bionic.readthedocs.io/en/stable/) that (among other things) transparently caches Python objects to disk, somewhat like [joblib](https://joblib.readthedocs.io/en/latest/). We save Dask DataFrames as Parquet files, but when we load them we detect this warning and throw an exception instead of returning the loaded frame. From our point of view, it's much better to fail early than to introduce a subtle non-determinism deep inside our framework, because the resulting bugs will be extremely hard for the end user to track down. I don't love the current approach of watching for warnings and I'd be happy to learn of a better way to avoid this problem.\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2.22.0\r\n- Python version: 3.8.3\r\n- Operating System: Mac OS 10.15.6 (19G73)\r\n- Install method: pip\r\n\r\nThanks for reading!",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/6484/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/6484/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}