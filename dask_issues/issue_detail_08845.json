{
    "url": "https://api.github.com/repos/dask/dask/issues/8845",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/8845/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/8845/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/8845/events",
    "html_url": "https://github.com/dask/dask/issues/8845",
    "id": 1180687339,
    "node_id": "I_kwDOAbcwm85GX9vr",
    "number": 8845,
    "title": "Concat clears divisions when it shouldn't",
    "user": {
        "login": "jorloplaz",
        "id": 12827365,
        "node_id": "MDQ6VXNlcjEyODI3MzY1",
        "avatar_url": "https://avatars.githubusercontent.com/u/12827365?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/jorloplaz",
        "html_url": "https://github.com/jorloplaz",
        "followers_url": "https://api.github.com/users/jorloplaz/followers",
        "following_url": "https://api.github.com/users/jorloplaz/following{/other_user}",
        "gists_url": "https://api.github.com/users/jorloplaz/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/jorloplaz/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/jorloplaz/subscriptions",
        "organizations_url": "https://api.github.com/users/jorloplaz/orgs",
        "repos_url": "https://api.github.com/users/jorloplaz/repos",
        "events_url": "https://api.github.com/users/jorloplaz/events{/privacy}",
        "received_events_url": "https://api.github.com/users/jorloplaz/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        },
        {
            "id": 3468123446,
            "node_id": "LA_kwDOAbcwm87Ot102",
            "url": "https://api.github.com/repos/dask/dask/labels/needs%20attention",
            "name": "needs attention",
            "color": "6d626c",
            "default": false,
            "description": "It's been a while since this was pushed on. Needs attention from the owner or a maintainer."
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 6,
    "created_at": "2022-03-25T11:35:09Z",
    "updated_at": "2022-05-02T02:15:00Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "active_lock_reason": null,
    "body": "**What happened**:\r\n\r\nWhen concatenating row-wise dataframes (`[ddf1, ddf2, ..., ddfN]`) that do not have any overlap, but that naturally follow each other (so `ddf1.divisions[-1] == ddf2.divisions[0]`, and `ddf2.divisions[-1] == ddf3.divisions[0]`, and so on), `dd.multi.concat` clears divisions when it shouldn't.\r\n\r\n**What you expected to happen**:\r\n\r\nThe concatenated result should have divisions (`[ddf1.divisions[0], ..., ddf1.divisions[-2], ddf2.divisions[0], ..., ddf2.divisions[-2], ddf3.divisions[0], ..., ddfN.divisions[-2], ddfN.divisions[-1]]`).\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport dask.dataframe as dd\r\nimport pandas as pd\r\n\r\n# Initial data\r\ndf = pd.DataFrame({\r\n    \"date\": pd.date_range(\"2019-01-01\", \"2019-01-10\"), \r\n    \"col1\": range(0, 10), \r\n    \"col2\": range(9, -1, -1)\r\n}) \r\n\r\n# To Dask, but it's not partitioned properly...\r\nddf = dd.from_pandas(df, npartitions=10)           # this causes 9 partitions instead of 10!\r\nif ddf.npartitions != 10:\r\n    print(f\"ddf has {ddf.npartitions} partitions instead of 10!\")         # print instead of raising error, but why does this happen?\r\n    print(ddf.divisions)                   # (0, 1, 2, 3, 4, 5, 6, 7, 8, 9),  but a 10 should have been added as divisions[-1]!\r\n\r\n# Index by date forcing 10 partitions\r\nddf = ddf.set_index(\"date\", divisions=tuple(pd.date_range(\"2019-01-01\", \"2019-01-11\")))     # note the 11th here!\r\nassert ddf.npartitions == 10, \"After repartitioning doesn't have 10 partitions!\"\r\nassert ddf.known_divisions, \"Divisions should be known!\"\r\nassert list(ddf.divisions[:-1]) == df[\"date\"].to_list(), \"There should be one division per day!\"    # note last one omitted!\r\n\r\n# Concatenate its partitions (Dask dataframes themselves) row-wise\r\ndfs = [p for p in ddf.partitions]\r\nres = dd.concat(dfs, axis=0)\r\nif ddf.npartitions != 10:\r\n    print(f\"concatenated has {res.npartitions} partitions instead of 10!\")\r\nassert res.known_divisions, \"Should have kept divisions!\"         # this raises AssertionError\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\nLooking into [concat code](https://github.com/dask/dask/blob/36e243ca79f6babdd46f293a2700d23928bba2b6/dask/dataframe/multi.py#L1255), I think the solution is really simple. Here is the conflictive part:\r\n\r\n```python\r\nif all(df.known_divisions for df in dasks):\r\n    # each DataFrame's division must be greater than previous one\r\n    if all(\r\n        dfs[i].divisions[-1] < dfs[i + 1].divisions[0]\r\n        for i in range(len(dfs) - 1)\r\n    ):\r\n        divisions = []\r\n        for df in dfs[:-1]:\r\n            # remove last to concatenate with next\r\n            divisions += df.divisions[:-1]\r\n        divisions += dfs[-1].divisions\r\n        return stack_partitions(dfs, divisions, join=join, ignore_order=ignore_order, **kwargs)\r\n    elif interleave_partitions:\r\n        return concat_indexed_dataframes(dfs, join=join, ignore_order=ignore_order, **kwargs)\r\n    else:\r\n        divisions = [None] * (sum(df.npartitions for df in dfs) + 1)\r\n        return stack_partitions(dfs, divisions, join=join, ignore_order=ignore_order, **kwargs)\r\n```\r\n\r\nThe thing is that <u>the check in `all` uses a strict `<`, but if would suffice with `<=`, because **it's fine that the beginning of the next frame equals the last division of the previous frame, since that last division is NOT included in the previous frame**</u>.\r\n\r\nTo prove this, if I call `stack_partitions` properly in the example above, things work:\r\n\r\n```python\r\nfrom dask.dataframe.multi import stack_partitions\r\nres = stack_partitions(dfs, divisions=tuple(pd.date_range(\"2019-01-01\", \"2019-01-11\")), join=\"inner\", ignore_order=False)\r\nassert res.known_divisions, \"Should have kept divisions!\"         # this is fine\r\nassert list(res.divisions[:-1]) == df[\"date\"].to_list(), \"There should be one division per day!\"      # this is fine too\r\n```\r\n\r\nI don't know if this has been addressed in #8517 (@jsignell @gjoseph92), but in my opinion the example above proves that there's space for improvement:\r\n* The delicate point is that `divisions[-1]` by definition is a value that is **NOT present in data** (it should be the first value NOT to include), so **it cannot be properly inferred** unless it's a very easy case (e.g. a range).\r\n* Because of this, `from_pandas` in the above example yields 9 partitions instead of 10 (with the last partition having 2 rows), even if the most natural way to partition that is 1 row per partition. This is a consequence of the fact that `divisions[-1]` cannot be inferred, plus the fact that `from_pandas` doesn't accept a `divisions` argument!\r\n* Because of this, if I do afterwards `set_index` without specifying proper divisions, it keeps on having 9 partitions, and `partition_quantiles` yields a strange result: \r\n```python\r\nddf.divisions\r\n(Timestamp('2019-01-01 00:00:00'), Timestamp('2019-01-01 21:36:00'), Timestamp('2019-01-02 19:12:00'), Timestamp('2019-01-03 16:48:00'), Timestamp('2019-01-04 14:24:00'), Timestamp('2019-01-05 12:00:00'), Timestamp('2019-01-06 09:36:00'), Timestamp('2019-01-07 07:12:00'), Timestamp('2019-01-08 04:48:00'), Timestamp('2019-01-09 02:24:00'), Timestamp('2019-01-10 00:00:00'))\r\n```\r\n\r\nSo I suggest this course of action:\r\n\r\n1. Change the code of `concat` with `<=`.\r\n2. See if there are other parts of code where this same error could be present.\r\n3. Think about whether `divisions[-1]` is really necessary. Do we need to have it? \r\n    * For searching, I think it should suffice to know that `partitions[i]` has values in its index in the interval `[divisions[i], divisions[i+1])`, for all partitions except the last one. The last one we know it starts in `divisions[-2]`, but it's open-ended.\r\n    * However, this raises a symmetry question in the 1st partition. Perhaps there should be two `divisions` arrays:\r\n        * Beginning of partitions: this would be the current `[divisions[0], ..., divisions[-2]]`, which is the same as `[partitions[0].index[0], ..., partitions[-1].index[0]]`.\r\n        * End of partitions: this would be last values actually present in each partition's index: `[partitions[0].index[-1], ..., partitions[-1].index[-1]]`.\r\n    * So that we know that the `i`-th partition has values in the **closed (not semi-open) interval** `[beginning[i], end[i]]`. \r\n    * As a side effect, these 2 arrays have the same length than `partitions`, instead of the current situation where `len(divisions) == len(partitions) + 1`.\r\n4. If we ignore the previous point and stick to one `divisions` array whose size is `npartitions + 1`, in my opinion:\r\n    * `from_pandas` should accept a `divisions` argument. \r\n    * If it doesn't receive `divisions` and turns out that the resulting `npartitions` isn't the one requested by the user, at least **raise a warning. In the example above, the user should know that instead of 10 partitions it decided to take 9!**\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.02.1\r\n- Python version: 3.9.10\r\n- Operating System: Ubuntu\r\n- Install method (conda, pip, source): Pip",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/8845/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/8845/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}