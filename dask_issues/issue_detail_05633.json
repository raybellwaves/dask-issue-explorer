{
    "url": "https://api.github.com/repos/dask/dask/issues/5633",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/5633/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/5633/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/5633/events",
    "html_url": "https://github.com/dask/dask/issues/5633",
    "id": 528137403,
    "node_id": "MDU6SXNzdWU1MjgxMzc0MDM=",
    "number": 5633,
    "title": "Add partition lengths to DataFrame metadata.",
    "user": {
        "login": "hadim",
        "id": 528003,
        "node_id": "MDQ6VXNlcjUyODAwMw==",
        "avatar_url": "https://avatars.githubusercontent.com/u/528003?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/hadim",
        "html_url": "https://github.com/hadim",
        "followers_url": "https://api.github.com/users/hadim/followers",
        "following_url": "https://api.github.com/users/hadim/following{/other_user}",
        "gists_url": "https://api.github.com/users/hadim/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/hadim/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/hadim/subscriptions",
        "organizations_url": "https://api.github.com/users/hadim/orgs",
        "repos_url": "https://api.github.com/users/hadim/repos",
        "events_url": "https://api.github.com/users/hadim/events{/privacy}",
        "received_events_url": "https://api.github.com/users/hadim/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 11,
    "created_at": "2019-11-25T14:51:06Z",
    "updated_at": "2022-03-15T21:22:18Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "*edit by TomAugspurger*\r\n\r\nCurrently partitions within a dask DataFrame do not known their own length. Anything using the length of the DataFrame or the partitions will need to compute it at runtime. The simplest case is `len`, which involves computing the graph and summing up the length of each partition\r\n\r\n```python\r\nIn [1]: import dask\r\n\r\nIn [8]: ts = dask.datasets.timeseries()\r\n\r\nIn [9]: len(ts)\r\nOut[9]: 2592000\r\n\r\nIn [10]: ts.map_partitions(len).compute()\r\nOut[10]:\r\n0     86400\r\n1     86400\r\n2     86400\r\n...\r\n27    86400\r\n28    86400\r\n29    86400\r\ndtype: int64\r\n```\r\n\r\nCertain data storage formats (e.g. parquet) know the number of rows and could provide that to Dask, if there was a way to store it. This is somewhat complicated though (https://github.com/dask/dask/issues/5633#issuecomment-558228192).\r\n\r\n*original post below*\r\n\r\n---\r\n\r\nFollowing this SO question: https://stackoverflow.com/questions/59023793/why-is-computing-the-shape-on-an-indexed-parquet-file-so-slow-in-dask/59034239#59034239\r\n\r\nIt would be nice to compute the length of a dataframe from its metadata (if available) instead of iterating over all partitions.",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/5633/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/5633/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}