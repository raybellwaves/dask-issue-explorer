{
    "url": "https://api.github.com/repos/dask/dask/issues/6068",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/6068/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/6068/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/6068/events",
    "html_url": "https://github.com/dask/dask/issues/6068",
    "id": 595053879,
    "node_id": "MDU6SXNzdWU1OTUwNTM4Nzk=",
    "number": 6068,
    "title": "Dask apply throwing error using right meta",
    "user": {
        "login": "victor-ab",
        "id": 26576394,
        "node_id": "MDQ6VXNlcjI2NTc2Mzk0",
        "avatar_url": "https://avatars.githubusercontent.com/u/26576394?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/victor-ab",
        "html_url": "https://github.com/victor-ab",
        "followers_url": "https://api.github.com/users/victor-ab/followers",
        "following_url": "https://api.github.com/users/victor-ab/following{/other_user}",
        "gists_url": "https://api.github.com/users/victor-ab/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/victor-ab/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/victor-ab/subscriptions",
        "organizations_url": "https://api.github.com/users/victor-ab/orgs",
        "repos_url": "https://api.github.com/users/victor-ab/repos",
        "events_url": "https://api.github.com/users/victor-ab/events{/privacy}",
        "received_events_url": "https://api.github.com/users/victor-ab/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2020-04-06T11:58:32Z",
    "updated_at": "2021-02-26T07:58:02Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "I'm trying to run the following code:\r\n```\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\n\r\ntestpd = pd.DataFrame(\r\n    {\r\n        \"SKU_ID\": {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 2, 6: 2},\r\n        \"STR_ID\": {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 64, 6: 64},\r\n        \"DATE\": {\r\n            0: Timestamp(\"2018-01-01 00:00:00\"),\r\n            1: Timestamp(\"2018-01-02 00:00:00\"),\r\n            2: Timestamp(\"2018-01-03 00:00:00\"),\r\n            3: Timestamp(\"2018-01-04 00:00:00\"),\r\n            4: Timestamp(\"2018-01-05 00:00:00\"),\r\n            5: Timestamp(\"2020-02-22 00:00:00\"),\r\n            6: Timestamp(\"2020-02-23 00:00:00\"),\r\n        },\r\n        \"ORD_UNITS\": {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0},\r\n    }\r\n)\r\n\r\ntestdd = dd.from_pandas(testpd, npartitions=2,)\r\n\r\ndef func(x):\r\n    return pd.Series(x[\"DATE\"] == x[\"DATE\"].min(), name=\"result\")\r\n\r\n```\r\nwith pandas, works perfectly:\r\n ```\r\nIn [11]: testpd.groupby([\"SKU_ID\", \"STR_ID\"]).apply(func)\r\nOut[11]:\r\nSKU_ID  STR_ID\r\n1       1       0     True\r\n                1    False\r\n                2    False\r\n                3    False\r\n                4    False\r\n2       64      5     True\r\n                6    False\r\nName: result, dtype: bool\r\n ```\r\n\r\nBut with dask I got:\r\n```\r\nIn [12]: testdd.groupby([\"SKU_ID\", \"STR_ID\"]).apply(\r\n    ...:     func, meta=pd.Series([], dtype=bool, name=\"result\")\r\n    ...: ).compute()\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-12-e82967be25da> in <module>\r\n      1 testdd.groupby([\"SKU_ID\", \"STR_ID\"]).apply(\r\n----> 2     func, meta=pd.Series([], dtype=bool, name=\"result\")\r\n      3 ).compute()\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\base.py in compute(self, **kwargs)\r\n    164         dask.base.compute\r\n    165         \"\"\"\r\n--> 166         (result,) = compute(self, traverse=False, **kwargs)\r\n    167         return result\r\n    168\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\base.py in compute(*args, **kwargs)\r\n    435     keys = [x.__dask_keys__() for x in collections]\r\n    436     postcomputes = [x.__dask_postcompute__() for x in collections]\r\n--> 437     results = schedule(dsk, keys, **kwargs)\r\n    438     return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\r\n    439\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\threaded.py in get(dsk, result, cache, num_workers, pool, **kwargs)\r\n     82         get_id=_thread_get_id,\r\n     83         pack_exception=pack_exception,\r\n---> 84         **kwargs\r\n     85     )\r\n     86\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\local.py in get_async(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\r\n    484                         _execute_task(task, data)  # Re-execute locally\r\n    485                     else:\r\n--> 486                         raise_exception(exc, tb)\r\n    487                 res, worker_id = loads(res_info)\r\n    488                 state[\"cache\"][key] = res\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\local.py in reraise(exc, tb)\r\n    314     if exc.__traceback__ is not tb:\r\n    315         raise exc.with_traceback(tb)\r\n--> 316     raise exc\r\n    317\r\n    318\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\local.py in execute_task(key, task_info, dumps, loads, get_id, pack_exception)\r\n    220     try:\r\n    221         task, data = loads(task_info)\r\n--> 222         result = _execute_task(task, data)\r\n    223         id = get_id()\r\n    224         result = dumps((result, id))\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\core.py in _execute_task(arg, cache, dsk)\r\n    119         # temporaries by their reference count and can execute certain\r\n    120         # operations in-place.\r\n--> 121         return func(*(_execute_task(a, cache) for a in args))\r\n    122     elif not ishashable(arg):\r\n    123         return arg\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\optimization.py in __call__(self, *args)\r\n    980         if not len(args) == len(self.inkeys):\r\n    981             raise ValueError(\"Expected %d args, got %d\" % (len(self.inkeys), len(args)))\r\n--> 982         return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\r\n    983\r\n    984     def __reduce__(self):\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\core.py in get(dsk, out, cache)\r\n    149     for key in toposort(dsk):\r\n    150         task = dsk[key]\r\n--> 151         result = _execute_task(task, cache)\r\n    152         cache[key] = result\r\n    153     result = _execute_task(out, cache)\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\core.py in _execute_task(arg, cache, dsk)\r\n    119         # temporaries by their reference count and can execute certain\r\n    120         # operations in-place.\r\n--> 121         return func(*(_execute_task(a, cache) for a in args))\r\n    122     elif not ishashable(arg):\r\n    123         return arg\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\utils.py in apply(func, args, kwargs)\r\n     28 def apply(func, args, kwargs=None):\r\n     29     if kwargs:\r\n---> 30         return func(*args, **kwargs)\r\n     31     else:\r\n     32         return func(*args)\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py in apply_and_enforce(*args, **kwargs)\r\n   5077             return meta\r\n   5078         if is_dataframe_like(df):\r\n-> 5079             check_matching_columns(meta, df)\r\n   5080             c = meta.columns\r\n   5081         else:\r\n\r\n~\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py in check_matching_columns(meta, actual)\r\n    669 def check_matching_columns(meta, actual):\r\n    670     # Need nan_to_num otherwise nan comparison gives False\r\n--> 671     if not np.array_equal(np.nan_to_num(meta.columns), np.nan_to_num(actual.columns)):\r\n    672         extra = actual.columns.difference(meta.columns).tolist()\r\n    673         missing = meta.columns.difference(actual.columns).tolist()\r\n\r\n~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py in __getattr__(self, name)\r\n   5268             or name in self._accessors\r\n   5269         ):\r\n-> 5270             return object.__getattribute__(self, name)\r\n   5271         else:\r\n   5272             if self._info_axis._can_hold_identifiers_and_holds_name(name):\r\n\r\nAttributeError: 'Series' object has no attribute 'columns'\r\n```\r\n\r\n```\r\nIn [2]: dask.__version__\r\nOut[2]: '2.12.0'\r\nIn [4]: pandas.__version__\r\nOut[4]: '1.0.1'\r\n```",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/6068/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/6068/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}