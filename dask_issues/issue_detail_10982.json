{
    "url": "https://api.github.com/repos/dask/dask/issues/10982",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/10982/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/10982/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/10982/events",
    "html_url": "https://github.com/dask/dask/issues/10982",
    "id": 2172886118,
    "node_id": "I_kwDOAbcwm86Bg5xm",
    "number": 10982,
    "title": "Dask Nunique bug under dask 2024.2.1",
    "user": {
        "login": "frbelotto",
        "id": 24688087,
        "node_id": "MDQ6VXNlcjI0Njg4MDg3",
        "avatar_url": "https://avatars.githubusercontent.com/u/24688087?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/frbelotto",
        "html_url": "https://github.com/frbelotto",
        "followers_url": "https://api.github.com/users/frbelotto/followers",
        "following_url": "https://api.github.com/users/frbelotto/following{/other_user}",
        "gists_url": "https://api.github.com/users/frbelotto/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/frbelotto/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/frbelotto/subscriptions",
        "organizations_url": "https://api.github.com/users/frbelotto/orgs",
        "repos_url": "https://api.github.com/users/frbelotto/repos",
        "events_url": "https://api.github.com/users/frbelotto/events{/privacy}",
        "received_events_url": "https://api.github.com/users/frbelotto/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 7,
    "created_at": "2024-03-07T03:50:10Z",
    "updated_at": "2024-04-02T14:14:55Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "Hello guys,\r\nTake this CSV as an example dataframe. I am sorry but I could set an example dataframe by coding able to reproduce such bug\r\n[teste.csv](https://github.com/dask/dask/files/14518393/teste.csv)\r\n\r\nNow, lets open and execute the query on the example dataframe under dask 2023.10.0:\r\n\r\n```\r\nimport dask.dataframe as dd\r\nddf = dd.read_csv('teste.csv', dtype = {'status':'category', 'produto':'category','parceiro':'category', \r\n                                            'mci' : 'Int32','marca':'category', 'sku' :'string', 'cod_transacao': 'string', 'forma_pagamento':'category',\r\n                                            'gmv' : 'Float32', 'receita' : 'Float32', 'cashback':'Float32'})\r\nbase_consumo = ddf.groupby(['mci', 'marca'], dropna=False, observed=True)['marca'].nunique().to_frame()\r\nbase_consumo.head()\r\n```\r\n![image](https://github.com/dask/dask/assets/24688087/182e3baf-454d-40d7-ab01-04257cff45b7)\r\n\r\nRuns ok!\r\n\r\nNow, lets do the same test under dask 2024.2.1\r\n\r\n```\r\nimport dask.dataframe as dd\r\nddf = dd.read_csv('teste.csv', dtype = {'status':'category', 'produto':'category','parceiro':'category', \r\n                                            'mci' : 'Int32','marca':'category', 'sku' :'string', 'cod_transacao': 'string', 'forma_pagamento':'category',\r\n                                            'gmv' : 'Float32', 'receita' : 'Float32', 'cashback':'Float32'})\r\nbase_consumo = ddf.groupby(['mci', 'marca'], dropna=False, observed=True)['marca'].nunique().to_frame()\r\nbase_consumo.head()\r\n```\r\n```\r\n\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\nFile [c:\\Users\\fabio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\utils.py:194](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/utils.py:194), in raise_on_meta_error(funcname, udf)\r\n    [193](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/utils.py:193) try:\r\n--> [194](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/utils.py:194)     yield\r\n    [195](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/utils.py:195) except Exception as e:\r\n\r\nFile [c:\\Users\\fabio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\core.py:7174](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7174), in _emulate(func, udf, *args, **kwargs)\r\n   [7173](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7173) with raise_on_meta_error(funcname(func), udf=udf), check_numeric_only_deprecation():\r\n-> [7174](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7174)     return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\r\n\r\nFile [c:\\Users\\fabio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\groupby.py:781](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:781), in _nunique_df_aggregate(df, levels, name, sort)\r\n    [780](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:780) def _nunique_df_aggregate(df, levels, name, sort=False):\r\n--> [781](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:781)     return df.groupby(level=levels, sort=sort, observed=True)[name].nunique()\r\n\r\nFile [c:\\Users\\fabio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1951](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/pandas/core/groupby/generic.py:1951), in DataFrameGroupBy.__getitem__(self, key)\r\n   [1947](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/pandas/core/groupby/generic.py:1947)     raise ValueError(\r\n   [1948](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/pandas/core/groupby/generic.py:1948)         \"Cannot subset columns with a tuple with more than one element. \"\r\n   [1949](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/pandas/core/groupby/generic.py:1949)         \"Use a list instead.\"\r\n   [1950](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/pandas/core/groupby/generic.py:1950)     )\r\n-> [1951](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/pandas/core/groupby/generic.py:1951) return super().__getitem__(key)\r\n\r\nFile [c:\\Users\\fabio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\base.py:244](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/pandas/core/base.py:244), in SelectionMixin.__getitem__(self, key)\r\n    [243](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/pandas/core/base.py:243) if key not in self.obj:\r\n--> [244](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/pandas/core/base.py:244)     raise KeyError(f\"Column not found: {key}\")\r\n    [245](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/pandas/core/base.py:245) ndim = self.obj[key].ndim\r\n\r\nKeyError: 'Column not found: marca'\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nValueError                                Traceback (most recent call last)\r\nCell In[3], [line 1](vscode-notebook-cell:?execution_count=3&line=1)\r\n----> [1](vscode-notebook-cell:?execution_count=3&line=1) base_consumo = ddf.groupby(['mci', 'marca'], dropna=False, observed=True)['marca'].nunique().to_frame()\r\n      [2](vscode-notebook-cell:?execution_count=3&line=2) base_consumo.head()\r\n\r\nFile [c:\\Users\\fabio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\groupby.py:3078](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:3078), in SeriesGroupBy.nunique(self, split_every, split_out)\r\n   [3075](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:3075) else:\r\n   [3076](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:3076)     chunk = _nunique_series_chunk\r\n-> [3078](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:3078) return aca(\r\n   [3079](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:3079)     [self.obj, self.by]\r\n   [3080](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:3080)     if not isinstance(self.by, list)\r\n   [3081](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:3081)     else [self.obj] + self.by,\r\n   [3082](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:3082)     chunk=chunk,\r\n   [3083](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:3083)     aggregate=_nunique_df_aggregate,\r\n   [3084](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:3084)     combine=_nunique_df_combine,\r\n   [3085](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:3085)     token=\"series-groupby-nunique\",\r\n   [3086](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:3086)     chunk_kwargs={\"levels\": levels, \"name\": name},\r\n   [3087](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:3087)     aggregate_kwargs={\"levels\": levels, \"name\": name},\r\n   [3088](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:3088)     combine_kwargs={\"levels\": levels},\r\n   [3089](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:3089)     split_every=split_every,\r\n   [3090](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:3090)     split_out=split_out,\r\n   [3091](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:3091)     split_out_setup=split_out_on_index,\r\n   [3092](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:3092)     sort=self.sort,\r\n   [3093](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/groupby.py:3093) )\r\n\r\nFile [c:\\Users\\fabio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\core.py:7128](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7128), in apply_concat_apply(args, chunk, aggregate, combine, meta, token, chunk_kwargs, aggregate_kwargs, combine_kwargs, split_every, split_out, split_out_setup, split_out_setup_kwargs, sort, ignore_index, **kwargs)\r\n   [7126](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7126) if meta is no_default:\r\n   [7127](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7127)     meta_chunk = _emulate(chunk, *args, udf=True, **chunk_kwargs)\r\n-> [7128](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7128)     meta = _emulate(\r\n   [7129](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7129)         aggregate, _concat([meta_chunk], ignore_index), udf=True, **aggregate_kwargs\r\n   [7130](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7130)     )\r\n   [7131](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7131) meta = make_meta(\r\n   [7132](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7132)     meta,\r\n   [7133](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7133)     index=(getattr(make_meta(dfs[0]), \"index\", None) if dfs else None),\r\n   [7134](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7134)     parent_meta=dfs[0]._meta,\r\n   [7135](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7135) )\r\n   [7137](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7137) graph = HighLevelGraph.from_collections(final_name, layer, dependencies=(chunked,))\r\n\r\nFile [c:\\Users\\fabio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\core.py:7173](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7173), in _emulate(func, udf, *args, **kwargs)\r\n   [7168](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7168) def _emulate(func, *args, udf=False, **kwargs):\r\n   [7169](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7169)     \"\"\"\r\n   [7170](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7170)     Apply a function using args / kwargs. If arguments contain dd.DataFrame /\r\n   [7171](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7171)     dd.Series, using internal cache (``_meta``) for calculation\r\n   [7172](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7172)     \"\"\"\r\n-> [7173](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7173)     with raise_on_meta_error(funcname(func), udf=udf), check_numeric_only_deprecation():\r\n   [7174](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/core.py:7174)         return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\r\n\r\nFile [c:\\Users\\fabio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/contextlib.py:158), in _GeneratorContextManager.__exit__(self, typ, value, traceback)\r\n    [156](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/contextlib.py:156)     value = typ()\r\n    [157](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/contextlib.py:157) try:\r\n--> [158](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/contextlib.py:158)     self.gen.throw(value)\r\n    [159](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/contextlib.py:159) except StopIteration as exc:\r\n    [160](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/contextlib.py:160)     # Suppress StopIteration *unless* it's the same exception that\r\n    [161](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/contextlib.py:161)     # was passed to throw().  This prevents a StopIteration\r\n    [162](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/contextlib.py:162)     # raised inside the \"with\" statement from being suppressed.\r\n    [163](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/contextlib.py:163)     return exc is not value\r\n\r\nFile [c:\\Users\\fabio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\utils.py:215](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/utils.py:215), in raise_on_meta_error(funcname, udf)\r\n    [206](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/utils.py:206) msg += (\r\n    [207](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/utils.py:207)     \"Original error is below:\\n\"\r\n    [208](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/utils.py:208)     \"------------------------\\n\"\r\n   (...)\r\n    [212](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/utils.py:212)     \"{2}\"\r\n    [213](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/utils.py:213) )\r\n    [214](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/utils.py:214) msg = msg.format(f\" in `{funcname}`\" if funcname else \"\", repr(e), tb)\r\n--> [215](file:///C:/Users/fabio/AppData/Local/Programs/Python/Python312/Lib/site-packages/dask/dataframe/utils.py:215) raise ValueError(msg) from e\r\n\r\nValueError: Metadata inference failed in `_nunique_df_aggregate`.\r\n\r\nYou have supplied a custom function and Dask is unable to \r\ndetermine the type of output that that function returns. \r\n\r\nTo resolve this please provide a meta= keyword.\r\nThe docstring of the Dask function you ran should have more information.\r\n\r\nOriginal error is below:\r\n------------------------\r\nKeyError('Column not found: marca')\r\n\r\nTraceback:\r\n---------\r\n  File \"c:\\Users\\fabio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\utils.py\", line 194, in raise_on_meta_error\r\n    yield\r\n  File \"c:\\Users\\fabio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\core.py\", line 7174, in _emulate\r\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"c:\\Users\\fabio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\groupby.py\", line 781, in _nunique_df_aggregate\r\n    return df.groupby(level=levels, sort=sort, observed=True)[name].nunique()\r\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\r\n  File \"c:\\Users\\fabio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py\", line 1951, in __getitem__\r\n    return super().__getitem__(key)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"c:\\Users\\fabio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\base.py\", line 244, in __getitem__\r\n    raise KeyError(f\"Column not found: {key}\")\r\n```\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2024.2.1\r\n- Python version: 3.11.8 and 3.12.2\r\n- Operating System: windows 11\r\n- Install method (conda, pip, source): pip\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/10982/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/10982/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}