[
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1302306306",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1302306306",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1302306306,
        "node_id": "IC_kwDOAbcwm85Nn54C",
        "user": {
            "login": "rjzamora",
            "id": 20461013,
            "node_id": "MDQ6VXNlcjIwNDYxMDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rjzamora",
            "html_url": "https://github.com/rjzamora",
            "followers_url": "https://api.github.com/users/rjzamora/followers",
            "following_url": "https://api.github.com/users/rjzamora/following{/other_user}",
            "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions",
            "organizations_url": "https://api.github.com/users/rjzamora/orgs",
            "repos_url": "https://api.github.com/users/rjzamora/repos",
            "events_url": "https://api.github.com/users/rjzamora/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rjzamora/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-03T15:44:09Z",
        "updated_at": "2022-11-03T15:44:09Z",
        "author_association": "MEMBER",
        "body": ">I'd be interested in doing a comparison by hacking together a version that bypasses fsspec, and uses pyarrow's native S3FileSystem directly. Before that though, it might be good to get some baseline numbers on how fast we can pull the raw data from S3 (just as bytes), to understand what performance we can expect.\r\n\r\nNote that you should already be able to do this by passing `open_file_options={\"open_file_func\": <pyarrow-file-open-func>}` to `dd.read_parquet`. For example:\r\n\r\n```python\r\nimport dask.dataframe as dd\r\nimport pyarrow as pa\r\nimport pyarrow.fs as pa_fs\r\n\r\npath = \"s3://ursa-labs-taxi-data/2009/01/data.parquet\"\r\nfs = pa_fs.S3FileSystem(anonymous=True)\r\n\r\nddf = dd.read_parquet(\r\n    path,\r\n    engine=\"pyarrow\",\r\n    storage_options={\"anon\": True},\r\n    open_file_options={\r\n        \"open_file_func\": fs.open_input_file,\r\n    },\r\n)\r\n\r\nddf.partitions[0].compute()\r\n```\r\n\r\nUsing `fs.open_input_file` does cut my wall time by ~50% for this simple example.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1302306306/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1302309577",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1302309577",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1302309577,
        "node_id": "IC_kwDOAbcwm85Nn6rJ",
        "user": {
            "login": "martindurant",
            "id": 6042212,
            "node_id": "MDQ6VXNlcjYwNDIyMTI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6042212?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/martindurant",
            "html_url": "https://github.com/martindurant",
            "followers_url": "https://api.github.com/users/martindurant/followers",
            "following_url": "https://api.github.com/users/martindurant/following{/other_user}",
            "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions",
            "organizations_url": "https://api.github.com/users/martindurant/orgs",
            "repos_url": "https://api.github.com/users/martindurant/repos",
            "events_url": "https://api.github.com/users/martindurant/events{/privacy}",
            "received_events_url": "https://api.github.com/users/martindurant/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-03T15:46:37Z",
        "updated_at": "2022-11-03T15:46:37Z",
        "author_association": "MEMBER",
        "body": "If we are talking about IO latency problems, then obviously the chunksize and caching strategy in the fsspec filelike will be very important, as pyarrow treats it like a regular file with many small reads. This is why we created fsspec.parquet to preemptively fetch all the bytes you will be needing before handing them to arrow.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1302309577/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1302319119",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1302319119",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1302319119,
        "node_id": "IC_kwDOAbcwm85Nn9AP",
        "user": {
            "login": "rjzamora",
            "id": 20461013,
            "node_id": "MDQ6VXNlcjIwNDYxMDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rjzamora",
            "html_url": "https://github.com/rjzamora",
            "followers_url": "https://api.github.com/users/rjzamora/followers",
            "following_url": "https://api.github.com/users/rjzamora/following{/other_user}",
            "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions",
            "organizations_url": "https://api.github.com/users/rjzamora/orgs",
            "repos_url": "https://api.github.com/users/rjzamora/repos",
            "events_url": "https://api.github.com/users/rjzamora/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rjzamora/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-03T15:53:38Z",
        "updated_at": "2022-11-03T15:53:38Z",
        "author_association": "MEMBER",
        "body": ">pyarrow treats it like a regular file with many small reads\r\n\r\nPyarrow actually doesn't do this anymore. They now expose a `pre_buffer` option in [`read_table`](https://arrow.apache.org/docs/python/generated/pyarrow.parquet.read_table.html) (and other read functions) to do something similar to what `fsspec.parquet` does. Therefore the performance difference may really be python-overhead related.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1302319119/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1302321282",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1302321282",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1302321282,
        "node_id": "IC_kwDOAbcwm85Nn9iC",
        "user": {
            "login": "martindurant",
            "id": 6042212,
            "node_id": "MDQ6VXNlcjYwNDIyMTI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6042212?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/martindurant",
            "html_url": "https://github.com/martindurant",
            "followers_url": "https://api.github.com/users/martindurant/followers",
            "following_url": "https://api.github.com/users/martindurant/following{/other_user}",
            "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions",
            "organizations_url": "https://api.github.com/users/martindurant/orgs",
            "repos_url": "https://api.github.com/users/martindurant/repos",
            "events_url": "https://api.github.com/users/martindurant/events{/privacy}",
            "received_events_url": "https://api.github.com/users/martindurant/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-03T15:54:56Z",
        "updated_at": "2022-11-03T15:54:56Z",
        "author_association": "MEMBER",
        "body": "@rjzamora - worth testing! I wonder if they read the buffers concurrently.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1302321282/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1302669532",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1302669532",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1302669532,
        "node_id": "IC_kwDOAbcwm85NpSjc",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-03T21:13:13Z",
        "updated_at": "2022-11-03T21:13:13Z",
        "author_association": "MEMBER",
        "body": "> Using fs.open_input_file does cut my wall time by ~50% for this simple example\r\n\r\nI'll be dumb for a moment.  If there aren't any backend options specified, and if arrow is present, then should we switch to using Arrow by default for things like this?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1302669532/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1302683606",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1302683606",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1302683606,
        "node_id": "IC_kwDOAbcwm85NpV_W",
        "user": {
            "login": "rjzamora",
            "id": 20461013,
            "node_id": "MDQ6VXNlcjIwNDYxMDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rjzamora",
            "html_url": "https://github.com/rjzamora",
            "followers_url": "https://api.github.com/users/rjzamora/followers",
            "following_url": "https://api.github.com/users/rjzamora/following{/other_user}",
            "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions",
            "organizations_url": "https://api.github.com/users/rjzamora/orgs",
            "repos_url": "https://api.github.com/users/rjzamora/repos",
            "events_url": "https://api.github.com/users/rjzamora/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rjzamora/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-03T21:28:08Z",
        "updated_at": "2022-11-03T21:29:21Z",
        "author_association": "MEMBER",
        "body": ">If there aren't any backend options specified, and if arrow is present, then should we switch to using Arrow by default for things like this?\r\n\r\nThe issue is that Dask has adopted `fsspec` as it's standard filesystem interface, and the `fsspec` API is not always aligned with the `pyarrow.fs` API. Therefore, the user would still need to pass in `fsspec`-based `storage_options` to `read_parquet`, and those options may be slightly different than the options needed to initialize an `s3fs` instance. This is why the code I shared above requires the user to create the pyarrow filesystem themselves.\r\n\r\nAlthough, I guess you are explicitly asking \"If there aren't any backend options specified\". So, I suppose that case **may** work.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1302683606/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1302704117",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1302704117",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1302704117,
        "node_id": "IC_kwDOAbcwm85Npa_1",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-03T21:41:14Z",
        "updated_at": "2022-11-03T21:41:14Z",
        "author_association": "MEMBER",
        "body": "If storage_options was empty could we safely do this?\n\nOn Thu, Nov 3, 2022 at 4:28 PM Richard (Rick) Zamora <\n***@***.***> wrote:\n\n> If there aren't any backend options specified, and if arrow is present,\n> then should we switch to using Arrow by default for things like this?\n>\n> The issue is that Dask has adopted fsspec as it's standard filesystem\n> interface, and the fsspec API is not always aligned with the pyarrow.fs\n> API. Therefore, the user would still need to pass in fsspec-based\n> storage_options to read_parquet, and those options may be slightly\n> different than the options needed to initialize an s3fs instance. This is\n> why the code I shared above requires the user to create the pyarrow\n> filesystem themselves.\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <https://github.com/dask/dask/issues/9619#issuecomment-1302683606>, or\n> unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AACKZTAP7HDJIHWAEDS6B6DWGQU7FANCNFSM6AAAAAARWEBXU4>\n> .\n> You are receiving this because you authored the thread.Message ID:\n> ***@***.***>\n>\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1302704117/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1302759398",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1302759398",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1302759398,
        "node_id": "IC_kwDOAbcwm85Npofm",
        "user": {
            "login": "rjzamora",
            "id": 20461013,
            "node_id": "MDQ6VXNlcjIwNDYxMDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rjzamora",
            "html_url": "https://github.com/rjzamora",
            "followers_url": "https://api.github.com/users/rjzamora/followers",
            "following_url": "https://api.github.com/users/rjzamora/following{/other_user}",
            "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions",
            "organizations_url": "https://api.github.com/users/rjzamora/orgs",
            "repos_url": "https://api.github.com/users/rjzamora/repos",
            "events_url": "https://api.github.com/users/rjzamora/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rjzamora/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-03T22:41:12Z",
        "updated_at": "2022-11-03T22:41:12Z",
        "author_association": "MEMBER",
        "body": ">If storage_options was empty could we safely do this?\r\n\r\nYes. Sorry - I hit enter too early. We would still need to use fsspec for graph construction, but would be able to use pyarrow to open the file at data-reading time if `storage_options` was empty anyway.\r\n\r\nNote that we could certainly add the option to use a pyarrow filesystem throught the `read_parquet` code (I've implemented this a few different times), but it's not a trivial change.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1302759398/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1302816039",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1302816039",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1302816039,
        "node_id": "IC_kwDOAbcwm85Np2Un",
        "user": {
            "login": "gjoseph92",
            "id": 3309802,
            "node_id": "MDQ6VXNlcjMzMDk4MDI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3309802?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/gjoseph92",
            "html_url": "https://github.com/gjoseph92",
            "followers_url": "https://api.github.com/users/gjoseph92/followers",
            "following_url": "https://api.github.com/users/gjoseph92/following{/other_user}",
            "gists_url": "https://api.github.com/users/gjoseph92/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/gjoseph92/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/gjoseph92/subscriptions",
            "organizations_url": "https://api.github.com/users/gjoseph92/orgs",
            "repos_url": "https://api.github.com/users/gjoseph92/repos",
            "events_url": "https://api.github.com/users/gjoseph92/events{/privacy}",
            "received_events_url": "https://api.github.com/users/gjoseph92/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-04T00:19:28Z",
        "updated_at": "2022-11-04T00:19:28Z",
        "author_association": "MEMBER",
        "body": "A 50% speedup seems worth a non-trivial change to me?\r\n\r\n@rjzamora thanks for sharing the snippet to do this. We should benchmark this on Coiled as well to get some more data points.\r\n\r\nI wonder if there's some subset of commonly-used fsspec options that we could easily translate into arrow?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1302816039/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1302844490",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1302844490",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1302844490,
        "node_id": "IC_kwDOAbcwm85Np9RK",
        "user": {
            "login": "martindurant",
            "id": 6042212,
            "node_id": "MDQ6VXNlcjYwNDIyMTI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6042212?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/martindurant",
            "html_url": "https://github.com/martindurant",
            "followers_url": "https://api.github.com/users/martindurant/followers",
            "following_url": "https://api.github.com/users/martindurant/following{/other_user}",
            "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions",
            "organizations_url": "https://api.github.com/users/martindurant/orgs",
            "repos_url": "https://api.github.com/users/martindurant/repos",
            "events_url": "https://api.github.com/users/martindurant/events{/privacy}",
            "received_events_url": "https://api.github.com/users/martindurant/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-04T01:19:22Z",
        "updated_at": "2022-11-04T01:19:22Z",
        "author_association": "MEMBER",
        "body": "It's worth turning on logging\r\n```python\r\nfsspec.utils.setup_logging(logger_name=\"s3fs\")\r\n```\r\n\r\ncreating dataframe:\r\n```\r\n2022-11-03 20:47:02,664 - s3fs - DEBUG - _lsdir -- Get directory listing page for ursa-labs-taxi-data/2009/01/data.parquet\r\n2022-11-03 20:47:02,937 - s3fs - DEBUG - _call_s3 -- CALL: head_object - ({},) - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet'}\r\n2022-11-03 20:47:02,993 - s3fs - DEBUG - _call_s3 -- CALL: head_object - ({},) - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet'}\r\n2022-11-03 20:47:03,047 - s3fs - DEBUG - _fetch_range -- Fetch: ursa-labs-taxi-data/2009/01/data.parquet, 461900991-461966527\r\n2022-11-03 20:47:03,048 - s3fs - DEBUG - _call_s3 -- CALL: get_object - () - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet', 'Range': 'bytes=461900991-461966526', 'IfMatch': '\"880538d41446f7b8083573b44f0b8b37-27\"'}\r\n2022-11-03 20:47:03,162 - s3fs - DEBUG - _fetch_range -- Fetch: ursa-labs-taxi-data/2009/01/data.parquet, 461642441-461900991\r\n2022-11-03 20:47:03,162 - s3fs - DEBUG - _call_s3 -- CALL: get_object - () - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet', 'Range': 'bytes=461642441-461900990', 'IfMatch': '\"880538d41446f7b8083573b44f0b8b37-27\"'}\r\n2022-11-03 20:47:03,324 - s3fs - DEBUG - _call_s3 -- CALL: head_object - ({},) - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet'}\r\n2022-11-03 20:47:03,384 - s3fs - DEBUG - _call_s3 -- CALL: head_object - ({},) - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet'}\r\n2022-11-03 20:47:03,454 - s3fs - DEBUG - _fetch_range -- Fetch: ursa-labs-taxi-data/2009/01/data.parquet, 461900991-461966527\r\n2022-11-03 20:47:03,455 - s3fs - DEBUG - _call_s3 -- CALL: get_object - () - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet', 'Range': 'bytes=461900991-461966526', 'IfMatch': '\"880538d41446f7b8083573b44f0b8b37-27\"'}\r\n2022-11-03 20:47:03,524 - s3fs - DEBUG - _fetch_range -- Fetch: ursa-labs-taxi-data/2009/01/data.parquet, 461642441-461900991\r\n2022-11-03 20:47:03,525 - s3fs - DEBUG - _call_s3 -- CALL: get_object - () - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet', 'Range': 'bytes=461642441-461900990', 'IfMatch': '\"880538d41446f7b8083573b44f0b8b37-27\"'}\r\n```\r\n(4 head calls, 4 get calls, all the same range)\r\n\r\nand read\r\n```\r\n2022-11-03 20:48:11,558 - s3fs - DEBUG - _call_s3 -- CALL: head_object - ({},) - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet'}\r\n2022-11-03 20:48:11,816 - s3fs - DEBUG - _fetch_range -- Fetch: ursa-labs-taxi-data/2009/01/data.parquet, 461900991-461966527\r\n2022-11-03 20:48:11,817 - s3fs - DEBUG - _call_s3 -- CALL: get_object - () - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet', 'Range': 'bytes=461900991-461966526', 'IfMatch': '\"880538d41446f7b8083573b44f0b8b37-27\"'}\r\n2022-11-03 20:48:11,922 - s3fs - DEBUG - _fetch_range -- Fetch: ursa-labs-taxi-data/2009/01/data.parquet, 461642441-461966519\r\n2022-11-03 20:48:11,922 - s3fs - DEBUG - _call_s3 -- CALL: get_object - () - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet', 'Range': 'bytes=461642441-461966518', 'IfMatch': '\"880538d41446f7b8083573b44f0b8b37-27\"'}\r\n2022-11-03 20:48:12,089 - s3fs - DEBUG - _fetch_range -- Fetch: ursa-labs-taxi-data/2009/01/data.parquet, 4-33347731\r\n2022-11-03 20:48:12,090 - s3fs - DEBUG - _call_s3 -- CALL: get_object - () - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet', 'Range': 'bytes=4-33347730', 'IfMatch': '\"880538d41446f7b8083573b44f0b8b37-27\"'}\r\n2022-11-03 20:48:14,017 - s3fs - DEBUG - _fetch_range -- Fetch: ursa-labs-taxi-data/2009/01/data.parquet, 266106048-299556487\r\n2022-11-03 20:48:14,017 - s3fs - DEBUG - _call_s3 -- CALL: get_object - () - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet', 'Range': 'bytes=266106048-299556486', 'IfMatch': '\"880538d41446f7b8083573b44f0b8b37-27\"'}\r\n2022-11-03 20:48:15,890 - s3fs - DEBUG - _fetch_range -- Fetch: ursa-labs-taxi-data/2009/01/data.parquet, 299556576-332631576\r\n2022-11-03 20:48:15,891 - s3fs - DEBUG - _call_s3 -- CALL: get_object - () - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet', 'Range': 'bytes=299556576-332631575', 'IfMatch': '\"880538d41446f7b8083573b44f0b8b37-27\"'}\r\n2022-11-03 20:48:17,532 - s3fs - DEBUG - _fetch_range -- Fetch: ursa-labs-taxi-data/2009/01/data.parquet, 332631643-366119909\r\n2022-11-03 20:48:17,533 - s3fs - DEBUG - _call_s3 -- CALL: get_object - () - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet', 'Range': 'bytes=332631643-366119908', 'IfMatch': '\"880538d41446f7b8083573b44f0b8b37-27\"'}\r\n2022-11-03 20:48:19,814 - s3fs - DEBUG - _fetch_range -- Fetch: ursa-labs-taxi-data/2009/01/data.parquet, 366119998-399192441\r\n2022-11-03 20:48:19,815 - s3fs - DEBUG - _call_s3 -- CALL: get_object - () - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet', 'Range': 'bytes=366119998-399192440', 'IfMatch': '\"880538d41446f7b8083573b44f0b8b37-27\"'}\r\n2022-11-03 20:48:21,581 - s3fs - DEBUG - _fetch_range -- Fetch: ursa-labs-taxi-data/2009/01/data.parquet, 399192508-432738114\r\n2022-11-03 20:48:21,582 - s3fs - DEBUG - _call_s3 -- CALL: get_object - () - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet', 'Range': 'bytes=399192508-432738113', 'IfMatch': '\"880538d41446f7b8083573b44f0b8b37-27\"'}\r\n2022-11-03 20:48:23,680 - s3fs - DEBUG - _fetch_range -- Fetch: ursa-labs-taxi-data/2009/01/data.parquet, 432738203-461642359\r\n2022-11-03 20:48:23,680 - s3fs - DEBUG - _call_s3 -- CALL: get_object - () - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet', 'Range': 'bytes=432738203-461642358', 'IfMatch': '\"880538d41446f7b8083573b44f0b8b37-27\"'}\r\n2022-11-03 20:48:25,287 - s3fs - DEBUG - _fetch_range -- Fetch: ursa-labs-taxi-data/2009/01/data.parquet, 166582521-199685105\r\n2022-11-03 20:48:25,288 - s3fs - DEBUG - _call_s3 -- CALL: get_object - () - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet', 'Range': 'bytes=166582521-199685104', 'IfMatch': '\"880538d41446f7b8083573b44f0b8b37-27\"'}\r\n2022-11-03 20:48:27,760 - s3fs - DEBUG - _fetch_range -- Fetch: ursa-labs-taxi-data/2009/01/data.parquet, 33347817-66443866\r\n2022-11-03 20:48:27,762 - s3fs - DEBUG - _call_s3 -- CALL: get_object - () - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet', 'Range': 'bytes=33347817-66443865', 'IfMatch': '\"880538d41446f7b8083573b44f0b8b37-27\"'}\r\n2022-11-03 20:48:29,462 - s3fs - DEBUG - _fetch_range -- Fetch: ursa-labs-taxi-data/2009/01/data.parquet, 99952366-133117918\r\n2022-11-03 20:48:29,462 - s3fs - DEBUG - _call_s3 -- CALL: get_object - () - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet', 'Range': 'bytes=99952366-133117917', 'IfMatch': '\"880538d41446f7b8083573b44f0b8b37-27\"'}\r\n2022-11-03 20:48:31,172 - s3fs - DEBUG - _fetch_range -- Fetch: ursa-labs-taxi-data/2009/01/data.parquet, 199685171-233041894\r\n2022-11-03 20:48:31,173 - s3fs - DEBUG - _call_s3 -- CALL: get_object - () - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet', 'Range': 'bytes=199685171-233041893', 'IfMatch': '\"880538d41446f7b8083573b44f0b8b37-27\"'}\r\n2022-11-03 20:48:32,837 - s3fs - DEBUG - _fetch_range -- Fetch: ursa-labs-taxi-data/2009/01/data.parquet, 66443929-99952280\r\n2022-11-03 20:48:32,838 - s3fs - DEBUG - _call_s3 -- CALL: get_object - () - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet', 'Range': 'bytes=66443929-99952279', 'IfMatch': '\"880538d41446f7b8083573b44f0b8b37-27\"'}\r\n2022-11-03 20:48:34,515 - s3fs - DEBUG - _fetch_range -- Fetch: ursa-labs-taxi-data/2009/01/data.parquet, 133117983-166582432\r\n2022-11-03 20:48:34,517 - s3fs - DEBUG - _call_s3 -- CALL: get_object - () - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet', 'Range': 'bytes=133117983-166582431', 'IfMatch': '\"880538d41446f7b8083573b44f0b8b37-27\"'}\r\n2022-11-03 20:48:36,159 - s3fs - DEBUG - _fetch_range -- Fetch: ursa-labs-taxi-data/2009/01/data.parquet, 233041983-266105981\r\n2022-11-03 20:48:36,170 - s3fs - DEBUG - _call_s3 -- CALL: get_object - () - {'Bucket': 'ursa-labs-taxi-data', 'Key': '2009/01/data.parquet', 'Range': 'bytes=233041983-266105980', 'IfMatch': '\"880538d41446f7b8083573b44f0b8b37-27\"'}\r\n```\r\n(fetched 266MB in 16 serial, but unordered calls in 30s, including parse time, which is near my available bandwidth)\r\n\r\nWhen loading with pyarrow's FS using the snippet above, I get\r\n```\r\nFile ~/conda/envs/py39/lib/python3.9/site-packages/pyarrow/_fs.pyx:763, in pyarrow._fs.FileSystem.open_input_file()\r\n\r\nFile ~/conda/envs/py39/lib/python3.9/site-packages/pyarrow/error.pxi:144, in pyarrow.lib.pyarrow_internal_check_status()\r\n\r\nFile ~/conda/envs/py39/lib/python3.9/site-packages/pyarrow/error.pxi:115, in pyarrow.lib.check_status()\r\n\r\nOSError: When reading information for key '2009/01/data.parquet' in bucket 'ursa-labs-taxi-data': AWS Error [code 100]: No response body.\r\n```\r\n\r\nThe time to download the whole file with s3fs in a single continuous call is 27.7s.\r\n```\r\nfs = fsspec.filesystem(\"s3\", anon=True)\r\n%time fs.cat(path)\r\n```\r\n\r\n```\r\nfsspec.parquet.open_parquet_file(path, storage_options={\"anon\": True}, engine=\"pyarrow\")\r\n```\r\ntakes 29s with s3fs, with two concurrent reads (35s if actually parsing the data)\r\n\r\nPlease run these on your machines closer to the data! Note that Rick's blog ( https://developer.nvidia.com/blog/optimizing-access-to-parquet-data-with-fsspec/ ) specifically measured s3fs with various caching versus arrow's FS versus fsspec.parquet.\r\nI would appreciate some deeper benchmarking and consideration before jumping to conclusions.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1302844490/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1302862280",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1302862280",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1302862280,
        "node_id": "IC_kwDOAbcwm85NqBnI",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-04T01:53:53Z",
        "updated_at": "2022-11-04T01:53:53Z",
        "author_association": "MEMBER",
        "body": "Totally agreed that folks shouldn't jump to conclusions.\r\n\r\n@martindurant have you had a chance to look at [this video](https://www.loom.com/share/4c8ad1c5251a4e658c1c47ee2113f34a).  I would be curious about your opinion on what is going on there.  Also, if you have a chance to look at @gjoseph92 's [pyspy profiles](https://speedscope.app/#profileURL=https%3a%2f%2fgistcdn.githack.com%2fgjoseph92%2ff71d825abb5a5d7e44f1cdeb041d8bff%2fraw%2ffbcd35977906999c5df4d88ca9d847a6b7ccf0aa%2ftls-10_0_0_177-42425.json) (I click \"Left Heavy\" and find that that helps with interpretability). ",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1302862280/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1302863391",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1302863391",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1302863391,
        "node_id": "IC_kwDOAbcwm85NqB4f",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-04T01:56:07Z",
        "updated_at": "2022-11-04T01:56:07Z",
        "author_association": "MEMBER",
        "body": "If I had to guess (and I only have like 20% confidence here) it would be that while fsspec is good on its own and dask is good on its own there is some negative interaction when having both event loops doing their thing at once, and for some reason things get sticky.  Just a total guess though.  If that guess is anything near to correct though then I think we would want to evaluate things in the wild, using fsspec/arrow + dask + s3, ideally on cloud machines.  \r\n\r\nIf you'd like your very own cloud machines I'm happy to set you up with a Coiled account.  It's a pretty smooth experience today.  I'm also happy to pay if folks don't already have AWS credentials through work.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1302863391/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1302875635",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1302875635",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1302875635,
        "node_id": "IC_kwDOAbcwm85NqE3z",
        "user": {
            "login": "martindurant",
            "id": 6042212,
            "node_id": "MDQ6VXNlcjYwNDIyMTI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6042212?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/martindurant",
            "html_url": "https://github.com/martindurant",
            "followers_url": "https://api.github.com/users/martindurant/followers",
            "following_url": "https://api.github.com/users/martindurant/following{/other_user}",
            "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions",
            "organizations_url": "https://api.github.com/users/martindurant/orgs",
            "repos_url": "https://api.github.com/users/martindurant/repos",
            "events_url": "https://api.github.com/users/martindurant/events{/privacy}",
            "received_events_url": "https://api.github.com/users/martindurant/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-04T02:21:59Z",
        "updated_at": "2022-11-04T02:21:59Z",
        "author_association": "MEMBER",
        "body": "NB CLI curl took 22s to fetch the file from the HTTP endpoint.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1302875635/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1303543558",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1303543558",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1303543558,
        "node_id": "IC_kwDOAbcwm85Nsn8G",
        "user": {
            "login": "martindurant",
            "id": 6042212,
            "node_id": "MDQ6VXNlcjYwNDIyMTI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6042212?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/martindurant",
            "html_url": "https://github.com/martindurant",
            "followers_url": "https://api.github.com/users/martindurant/followers",
            "following_url": "https://api.github.com/users/martindurant/following{/other_user}",
            "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions",
            "organizations_url": "https://api.github.com/users/martindurant/orgs",
            "repos_url": "https://api.github.com/users/martindurant/repos",
            "events_url": "https://api.github.com/users/martindurant/events{/privacy}",
            "received_events_url": "https://api.github.com/users/martindurant/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-04T13:30:37Z",
        "updated_at": "2022-11-04T13:30:37Z",
        "author_association": "MEMBER",
        "body": "I will also do my own measurements n AWS, but certainly not today. I can't say there's too much rush.\r\nIt may be worthwhile for someone to check out the tricks in https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3.html#using-the-transfer-manager to make things faster (although that may be for whole files only).\r\n\r\nI would prefer if we can improve s3fs rather than splitting the FS backends.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1303543558/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1303548749",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1303548749",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1303548749,
        "node_id": "IC_kwDOAbcwm85NspNN",
        "user": {
            "login": "martindurant",
            "id": 6042212,
            "node_id": "MDQ6VXNlcjYwNDIyMTI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6042212?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/martindurant",
            "html_url": "https://github.com/martindurant",
            "followers_url": "https://api.github.com/users/martindurant/followers",
            "following_url": "https://api.github.com/users/martindurant/following{/other_user}",
            "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions",
            "organizations_url": "https://api.github.com/users/martindurant/orgs",
            "repos_url": "https://api.github.com/users/martindurant/repos",
            "events_url": "https://api.github.com/users/martindurant/events{/privacy}",
            "received_events_url": "https://api.github.com/users/martindurant/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-04T13:35:34Z",
        "updated_at": "2022-11-04T13:35:34Z",
        "author_association": "MEMBER",
        "body": "Feel free to see if this makes any difference\r\n```diff\r\n--- a/s3fs/core.py\r\n+++ b/s3fs/core.py\r\n@@ -2231,7 +2231,11 @@ def _fetch_range(fs, bucket, key, version_id, start, end, req_kw=None):\r\n         )\r\n         return b\"\"\r\n     logger.debug(\"Fetch: %s/%s, %s-%s\", bucket, key, start, end)\r\n-    resp = fs.call_s3(\r\n+    return sync(fs.loop, _inner_fetch, fs, bucket, key, version_id, start, end, req_kw)\r\n+\r\n+\r\n+async def _inner_fetch(fs, bucket, key, version_id, start, end, req_kw=None):\r\n+    resp = await fs._call_s3(\r\n         \"get_object\",\r\n         Bucket=bucket,\r\n         Key=key,\r\n@@ -2239,4 +2243,4 @@ def _fetch_range(fs, bucket, key, version_id, start, end, req_kw=None):\r\n         **version_id_kw(version_id),\r\n         **req_kw,\r\n     )\r\n-    return sync(fs.loop, resp[\"Body\"].read)\r\n+    return await resp[\"Body\"].read()\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1303548749/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1303558724",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1303558724",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1303558724,
        "node_id": "IC_kwDOAbcwm85NsrpE",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-04T13:44:44Z",
        "updated_at": "2022-11-04T13:44:44Z",
        "author_association": "MEMBER",
        "body": "> I would prefer if we can improve s3fs rather than splitting the FS backends\r\n\r\nCan you motivate this a bit more?\r\n\r\nWhat are some of the downsides of using Arrow filesystems in specialized cases like above? ",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1303558724/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1303566518",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1303566518",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1303566518,
        "node_id": "IC_kwDOAbcwm85Nsti2",
        "user": {
            "login": "martindurant",
            "id": 6042212,
            "node_id": "MDQ6VXNlcjYwNDIyMTI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6042212?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/martindurant",
            "html_url": "https://github.com/martindurant",
            "followers_url": "https://api.github.com/users/martindurant/followers",
            "following_url": "https://api.github.com/users/martindurant/following{/other_user}",
            "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions",
            "organizations_url": "https://api.github.com/users/martindurant/orgs",
            "repos_url": "https://api.github.com/users/martindurant/repos",
            "events_url": "https://api.github.com/users/martindurant/events{/privacy}",
            "received_events_url": "https://api.github.com/users/martindurant/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-04T13:48:17Z",
        "updated_at": "2022-11-04T13:48:17Z",
        "author_association": "MEMBER",
        "body": "To dask: some additional complexity and development, as well as possible confusion in users when multiple backends are used in conjunction.\r\nTo the community: s3fs is used an awful lot without arrow, so improvements will be far reaching (arrow's install size on, for instance, AWS Lambda, is one of the main reasons for the continued existence of fastparquet); any specific features that might be needing development are much easier to achieve in python than arrow's C++ monolith.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1303566518/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1303576716",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1303576716",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1303576716,
        "node_id": "IC_kwDOAbcwm85NswCM",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-04T13:52:15Z",
        "updated_at": "2022-11-04T13:52:15Z",
        "author_association": "MEMBER",
        "body": "Sure, and I'm not currently planning to invest any development resources in improving arrow.  However, if today Arrow's reading is better than s3fs's reading in a particular case, and if we know that we are in a situation where we can swap the two safely, then it seems to me like we should do so.  \r\n\r\nTo be clear, I'm not saying \"let's rip out S3\" I'm saying \"In this restricted but common case where we know it's safe, maybe we can automatically swap things and get a speed boost\"",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1303576716/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1303586612",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1303586612",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1303586612,
        "node_id": "IC_kwDOAbcwm85Nsyc0",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-04T13:56:05Z",
        "updated_at": "2022-11-04T13:56:05Z",
        "author_association": "MEMBER",
        "body": "You might also be underestimating the importance of this speed boost.  We've just discovered a way for Dask to go 2x faster on very common workloads.  This is HUGE for a lot of users.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1303586612/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1303588015",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1303588015",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1303588015,
        "node_id": "IC_kwDOAbcwm85Nsyyv",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-04T13:56:37Z",
        "updated_at": "2022-11-04T13:56:37Z",
        "author_association": "MEMBER",
        "body": "(if indeed, this speedup exists (which currently our benchmarking shows that it does in the wild, but we should do more homework))",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1303588015/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1303611293",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1303611293",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1303611293,
        "node_id": "IC_kwDOAbcwm85Ns4ed",
        "user": {
            "login": "rjzamora",
            "id": 20461013,
            "node_id": "MDQ6VXNlcjIwNDYxMDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rjzamora",
            "html_url": "https://github.com/rjzamora",
            "followers_url": "https://api.github.com/users/rjzamora/followers",
            "following_url": "https://api.github.com/users/rjzamora/following{/other_user}",
            "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions",
            "organizations_url": "https://api.github.com/users/rjzamora/orgs",
            "repos_url": "https://api.github.com/users/rjzamora/repos",
            "events_url": "https://api.github.com/users/rjzamora/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rjzamora/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-04T14:08:09Z",
        "updated_at": "2022-11-04T14:08:09Z",
        "author_association": "MEMBER",
        "body": ">I would prefer if we can improve s3fs rather than splitting the FS backends.\r\n\r\nWe built everything on `fsspec` for good reason. It is flexible, effective, and has excellent API coverage. Therefore, `fsspec`/`s3fs` will clearly remain the primary code path in Dask-IO in the future. With that said, I do feel that the user should be allowed to set the global filesystem to an `S3FileSystem` object for the \u201dpyarrow\u201d engine. There have been issues related to pyarrow users who want to pass the same arguments to Dask that they are already passing to `pyarrow.dataset`. Also, if we ultimately find that `S3FileSystem` has a consistent performance advantage (one that cannot be fixed), it would be pretty silly not to tweak default behavior.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1303611293/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1312210237",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1312210237",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1312210237,
        "node_id": "IC_kwDOAbcwm85ONr09",
        "user": {
            "login": "martindurant",
            "id": 6042212,
            "node_id": "MDQ6VXNlcjYwNDIyMTI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6042212?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/martindurant",
            "html_url": "https://github.com/martindurant",
            "followers_url": "https://api.github.com/users/martindurant/followers",
            "following_url": "https://api.github.com/users/martindurant/following{/other_user}",
            "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions",
            "organizations_url": "https://api.github.com/users/martindurant/orgs",
            "repos_url": "https://api.github.com/users/martindurant/repos",
            "events_url": "https://api.github.com/users/martindurant/events{/privacy}",
            "received_events_url": "https://api.github.com/users/martindurant/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-11T21:36:51Z",
        "updated_at": "2022-11-11T21:36:51Z",
        "author_association": "MEMBER",
        "body": "On ec2:\r\n```\r\n%time fs.get(\"s3://ursa-labs-taxi-data/2009/01/data.parquet\", \"data.parquet\")\r\nCPU times: user 1.16 s, sys: 641 ms, total: 1.8 s\r\nWall time: 4.67 s\r\n\r\n> wget https://ursa-labs-taxi-data.s3.amazonaws.com/2009/01/data.parquet\r\n461,966,527 96.0MB/s   in 4.6s\r\n\r\n%time f = fsspec.parquet.open_parquet_file(\"s3://ursa-labs-taxi-data/2009/01/data.parquet\", storage_options={\"anon\": True})\r\nCPU times: user 1.36 s, sys: 833 ms, total: 2.2 s\r\nWall time: 3.46 s\r\n\r\n%%time\r\nwith fs.open_input_file(\"ursa-labs-taxi-data/2009/01/data.parquet\") as f:\r\n    data = True\r\n    while data:\r\n        data = f.read(2**10)\r\nAWS Error [code 100]: No response body  # also fails via dd.read_parquet as in Rick's snippet\r\n\r\n%%time  # serial\r\nwith fsspec.open(\"s3://ursa-labs-taxi-data/2009/01/data.parquet\", mode=\"rb\", anon=True) as f:\r\n    data = True\r\n    while data:\r\n        data = f.read(2**10)\r\nCPU times: user 2.87 s, sys: 530 ms, total: 3.4 s\r\nWall time: 13.9 s\r\n\r\nIn [26]: print(_i23)\r\n%%time  # serial, bigger blocks\r\nwith fsspec.open(\"s3://ursa-labs-taxi-data/2009/01/data.parquet\", mode=\"rb\", anon=True, default_block_size=50*2**20) as f:\r\n    data = True\r\n    while data:\r\n        data = f.read(2**10)\r\nCPU times: user 3.09 s, sys: 1.13 s, total: 4.22 s\r\nWall time: 7.63 s\r\n\r\n> curl https://ursa-labs-taxi-data.s3.amazonaws.com/2009/01/data.parquet -o temp\r\n4s\r\n```\r\n\r\nSo s3fs matches wget and curl for throughput.\r\n\r\nWith dask in the loop, exactly the same\r\n\r\n```\r\nimoprt dask\r\nimport dask\r\nimport fsspec\r\nfs = fsspec.filesystem(\"s3\", anon=True)\r\n\r\n@dask.delayed\r\ndef f():\r\n    fs.get(\"s3://ursa-labs-taxi-data/2009/01/data.parquet\", \"data.parquet\")\r\n    return True\r\n\r\nd = f()\r\n%timeit dask.compute(d)\r\n4.64 s \u00b1 3.14 ms per loop\r\n```\r\n\r\nSo all saturate at about 100MB/s, as expected for a .medium EC2 instance. Do I need something bigger? Why does pyarrow consistently fail?\r\n\r\npyarrow 8.0.0\r\nfsspec, s3fs 2022.11.0\r\ndask 2022.10.2\r\n(fresh conda environment with conda-forge, no particular care taken)",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1312210237/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1314062997",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1314062997",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1314062997,
        "node_id": "IC_kwDOAbcwm85OUwKV",
        "user": {
            "login": "rjzamora",
            "id": 20461013,
            "node_id": "MDQ6VXNlcjIwNDYxMDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rjzamora",
            "html_url": "https://github.com/rjzamora",
            "followers_url": "https://api.github.com/users/rjzamora/followers",
            "following_url": "https://api.github.com/users/rjzamora/following{/other_user}",
            "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions",
            "organizations_url": "https://api.github.com/users/rjzamora/orgs",
            "repos_url": "https://api.github.com/users/rjzamora/repos",
            "events_url": "https://api.github.com/users/rjzamora/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rjzamora/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-14T16:46:05Z",
        "updated_at": "2022-11-14T16:46:05Z",
        "author_association": "MEMBER",
        "body": ">Why does pyarrow consistently fail?\r\n\r\nI haven't seen any failures on pyarrow-9.0.0 (using `S3FileSystem(anonymous=True)`).\r\n\r\n>So all saturate at about 100MB/s, as expected for a .medium EC2 instance. Do I need something bigger? \r\n\r\nMy network is too noisy right now to run any useful experiments. However, it may be the case that the data-transfer time is indeed optimal (or close to it) for `fsspec.read_parquet_file`. **If** there is actually a consistent discrepancy in the `read_parquet` wall time (still not sure if there is), it may be related to something unrelated to data transfer.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1314062997/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1314069814",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1314069814",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1314069814,
        "node_id": "IC_kwDOAbcwm85OUx02",
        "user": {
            "login": "martindurant",
            "id": 6042212,
            "node_id": "MDQ6VXNlcjYwNDIyMTI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6042212?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/martindurant",
            "html_url": "https://github.com/martindurant",
            "followers_url": "https://api.github.com/users/martindurant/followers",
            "following_url": "https://api.github.com/users/martindurant/following{/other_user}",
            "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions",
            "organizations_url": "https://api.github.com/users/martindurant/orgs",
            "repos_url": "https://api.github.com/users/martindurant/repos",
            "events_url": "https://api.github.com/users/martindurant/events{/privacy}",
            "received_events_url": "https://api.github.com/users/martindurant/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-14T16:51:27Z",
        "updated_at": "2022-11-14T16:51:27Z",
        "author_association": "MEMBER",
        "body": "> I haven't seen any failures on pyarrow-9.0.0\r\n\r\nThe env was created like\r\n```\r\nconda create -n new python=3.9 pyarrow dask s3fs ipython pandas -c conda-forge\r\n```\r\nunder AWS linux from fresh miniconda, nothing special.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1314069814/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1314079351",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1314079351",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1314079351,
        "node_id": "IC_kwDOAbcwm85OU0J3",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-14T16:59:09Z",
        "updated_at": "2022-11-14T16:59:09Z",
        "author_association": "MEMBER",
        "body": "> My network is too noisy right now to run any useful experiments\r\n\r\n@rjzamora sorry to pitch a for-profit thing, but I notice that you have a Coiled account.  If you do the following you should get a Dask cluster with your local setup.\r\n\r\n```\r\npip install coiled --upgrade # or conda, if you prefer\r\n\r\nimport coiled\r\n\r\ncluster = coiled.Cluster(\r\n    account=\"dask\",   # use an AWS account that we've set up for development\r\n    package_sync=True,  # copy versions of dask, arrow, etc. whatever you have locally\r\n)\r\n\r\nfrom dask.distributed import Client\r\nclient = Client(cluster)\r\n```\r\n\r\nNo pressure of course, but I'd like to remove any hardware bottleneck you may have to do experimentation.  \r\n\r\n@martindurant , same offer to you if you're interested.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1314079351/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1314142599",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1314142599",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1314142599,
        "node_id": "IC_kwDOAbcwm85OVDmH",
        "user": {
            "login": "martindurant",
            "id": 6042212,
            "node_id": "MDQ6VXNlcjYwNDIyMTI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6042212?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/martindurant",
            "html_url": "https://github.com/martindurant",
            "followers_url": "https://api.github.com/users/martindurant/followers",
            "following_url": "https://api.github.com/users/martindurant/following{/other_user}",
            "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions",
            "organizations_url": "https://api.github.com/users/martindurant/orgs",
            "repos_url": "https://api.github.com/users/martindurant/repos",
            "events_url": "https://api.github.com/users/martindurant/events{/privacy}",
            "received_events_url": "https://api.github.com/users/martindurant/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-14T17:45:09Z",
        "updated_at": "2022-11-14T17:45:09Z",
        "author_association": "MEMBER",
        "body": "I'm not sure it helps me, since I was doing interactive timings mostly without dask; and then with dask-threads. It's really a remote client I need, not workers.\r\n\r\nDoes anyone suspect that the effect might *only* happen on dask workers? That would be interesting.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1314142599/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1314160571",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1314160571",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1314160571,
        "node_id": "IC_kwDOAbcwm85OVH-7",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-14T18:00:20Z",
        "updated_at": "2022-11-14T18:00:20Z",
        "author_association": "MEMBER",
        "body": "It certainly happens on Dask Workers.  I don't know where the boundary is\nthough.  It's easy enough to experiment up there that it seems useful to\nhave the ability.\n\nIf I wanted a remote machine I would probably spin up a single worker\ncluster and then start using afar.\n\nRegardless though, the thing that I want to optimize isn't s3fs, it's\ns3fs+dask+cloud-machines.  If I were trying to optimize this I would start\nwith the full system, verify the slowdown, and then start pulling away\npieces and seeing what happens.\n\nOn Mon, Nov 14, 2022 at 11:45 AM Martin Durant ***@***.***>\nwrote:\n\n> I'm not sure it helps me, since I was doing interactive timings mostly\n> without dask; and then with dask-threads. It's really a remote client I\n> need, not workers.\n>\n> Does anyone suspect that the effect might *only* happen on dask workers?\n> That would be interesting.\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <https://github.com/dask/dask/issues/9619#issuecomment-1314142599>, or\n> unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AACKZTHD6I3TEGYH2VXXTRTWIJ3C7ANCNFSM6AAAAAARWEBXU4>\n> .\n> You are receiving this because you authored the thread.Message ID:\n> ***@***.***>\n>\n",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1314160571/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1314305994",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1314305994",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1314305994,
        "node_id": "IC_kwDOAbcwm85OVrfK",
        "user": {
            "login": "gjoseph92",
            "id": 3309802,
            "node_id": "MDQ6VXNlcjMzMDk4MDI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3309802?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/gjoseph92",
            "html_url": "https://github.com/gjoseph92",
            "followers_url": "https://api.github.com/users/gjoseph92/followers",
            "following_url": "https://api.github.com/users/gjoseph92/following{/other_user}",
            "gists_url": "https://api.github.com/users/gjoseph92/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/gjoseph92/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/gjoseph92/subscriptions",
            "organizations_url": "https://api.github.com/users/gjoseph92/orgs",
            "repos_url": "https://api.github.com/users/gjoseph92/repos",
            "events_url": "https://api.github.com/users/gjoseph92/events{/privacy}",
            "received_events_url": "https://api.github.com/users/gjoseph92/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-14T20:05:14Z",
        "updated_at": "2022-11-14T20:05:14Z",
        "author_association": "MEMBER",
        "body": "> However, it may be the case that the data-transfer time is indeed optimal (or close to it) for `fsspec.read_parquet_file`. **If** there is actually a consistent discrepancy in the `read_parquet` wall time (still not sure if there is), it may be related to something unrelated to data transfer.\r\n\r\nI'd expect plain `read_parquet` wall time to be pretty much optimal.\r\n\r\nI think the problem here is about the _interaction_\u2014particularly regarding concurrency\u2014between s3fs and dask (and pyarrow?), as Matt is saying. s3fs seems perfectly fast on its own, but when you have multiple Arrow threads calling into single-threaded, GIL-locked Python to do their reads, which then call `sync` into a single-threaded event loop, which then call s3fs stuff, is that optimal?\r\n\r\nAs an example, please take a look at the py-spy profile I recorded of multi-threaded dask workers on a real cluster loading Parquet data: [tls-10_0_0_177-42425.json](https://speedscope.app/#profileURL=https%3a%2f%2fgistcdn.githack.com%2fgjoseph92%2ff71d825abb5a5d7e44f1cdeb041d8bff%2fraw%2ffbcd35977906999c5df4d88ca9d847a6b7ccf0aa%2ftls-10_0_0_177-42425.json)\r\n\r\nIf you look at the `fsspecIO` thread (which is a _different_ thread from the worker event loop `MainThread`, which itself is quite concerning\u2014this implies there are two separate event loops running in separate threads), you can see that 30% of the time, the event loop is blocked acquiring the Python GIL:\r\n\r\n![Screen Shot 2022-11-14 at 11 04 48 AM](https://user-images.githubusercontent.com/3309802/201733627-3a55d67f-c1a5-4ed3-819f-59db4c847f46.png)\r\n\r\nThis is the convoy effect https://bugs.python.org/issue7946; you can read more here https://github.com/dask/distributed/issues/6325. It means that async networking performance will be significantly degraded if you're doing stuff in other threads that hold the GIL. In Dask, we're using async networking to load parquet, and we have other worker threads doing stuff that's likely to hold the GIL (plenty of pandas operations hold the GIL at least some of the time).\r\n\r\nThis is just an inherent limitation of Python right now, there's not much fsspec can do about it.\r\n\r\nI'm not saying this is the only problem. I also would imagine (unfounded) that arrow can be more memory-efficient and reduce the number of copies if it to manage its own IO without leaving the C++ world. I'd hope it could read from network directly into an arrow-managed buffer\u2014ideally zero-copy `sendfile`, but at least without a copy into non-Arrow userspace then getting copied again into Arrow-manged userspace.\r\n\r\nBroadly, I just find it weird to see 4 Arrow threads all calling into Python to do their IO. I would expect, intuitively, that a performance and memory sensitive C++ library like Arrow can perform better if it gets to manage its own IO, also in C++.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1314305994/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1315385500",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1315385500",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1315385500,
        "node_id": "IC_kwDOAbcwm85OZzCc",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-15T14:27:04Z",
        "updated_at": "2022-11-15T14:27:04Z",
        "author_association": "MEMBER",
        "body": "> I'm not sure it helps me, since I was doing interactive timings mostly without dask;\r\n\r\nYeah, just to be clear, what I'm interested in here isn't \"the relative performance of s3fs vs pyarrow s3\" it's the \"relative performance of these libraries in the context of Dask\".  \r\n\r\nWhat I'm seeing here (thanks @gjoseph92 for the profiling) is that s3fs is 2x slower in the context of Dask in a specific but very common use case.  Unless we see an easy development path towards making this much faster (and @gjoseph92 's comment leads me to believe that such a path will be hard to find), I think that we should probably move in the direction of swapping things out when we know that it is safe to do so.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1315385500/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1315471583",
        "html_url": "https://github.com/dask/dask/issues/9619#issuecomment-1315471583",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9619",
        "id": 1315471583,
        "node_id": "IC_kwDOAbcwm85OaIDf",
        "user": {
            "login": "mrocklin",
            "id": 306380,
            "node_id": "MDQ6VXNlcjMwNjM4MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/306380?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrocklin",
            "html_url": "https://github.com/mrocklin",
            "followers_url": "https://api.github.com/users/mrocklin/followers",
            "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
            "organizations_url": "https://api.github.com/users/mrocklin/orgs",
            "repos_url": "https://api.github.com/users/mrocklin/repos",
            "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrocklin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-15T15:26:22Z",
        "updated_at": "2022-11-15T15:26:22Z",
        "author_association": "MEMBER",
        "body": "quick addendum: \"*at least in the short term\"",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1315471583/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]