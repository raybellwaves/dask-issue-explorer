{
    "url": "https://api.github.com/repos/dask/dask/issues/2456",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/2456/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/2456/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/2456/events",
    "html_url": "https://github.com/dask/dask/issues/2456",
    "id": 236117194,
    "node_id": "MDU6SXNzdWUyMzYxMTcxOTQ=",
    "number": 2456,
    "title": "OOMs on seemingly simple shuffle job: mem usage greatly exceeds --memory-limit",
    "user": {
        "login": "jdanbrown",
        "id": 627486,
        "node_id": "MDQ6VXNlcjYyNzQ4Ng==",
        "avatar_url": "https://avatars.githubusercontent.com/u/627486?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/jdanbrown",
        "html_url": "https://github.com/jdanbrown",
        "followers_url": "https://api.github.com/users/jdanbrown/followers",
        "following_url": "https://api.github.com/users/jdanbrown/following{/other_user}",
        "gists_url": "https://api.github.com/users/jdanbrown/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/jdanbrown/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/jdanbrown/subscriptions",
        "organizations_url": "https://api.github.com/users/jdanbrown/orgs",
        "repos_url": "https://api.github.com/users/jdanbrown/repos",
        "events_url": "https://api.github.com/users/jdanbrown/events{/privacy}",
        "received_events_url": "https://api.github.com/users/jdanbrown/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 34,
    "created_at": "2017-06-15T08:41:06Z",
    "updated_at": "2022-03-28T18:00:58Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "# Summary\r\n- I'm struggling to figure out how to avoid OOMs in a seemingly simple shuffle on a ~6gb parquet.snappy dataset using 16 workers, each with 8gb mem, ~4gb memory limit, 1 proc, and 1 thread. I'm not persisting anything, and I'm ok with shuffle tasks spilling to disk as necessary.\r\n- The OOMs cause the job to either fail after a while or complete after a really long while, nondeterministically.\r\n- I decreased task size by increasing task count (128 -> 512), but I still observed OOMs with similar frequency.\r\n- Plotting mem usage over time shows a tight distribution around `--memory-limit` for the first ~1/2 of the job and then large variance for the second ~1/2 of the job, during which time OOMs start happening (plots below).\r\n- I created more headroom for this large variance by decreasing `--memory-limit` (4gb/8gb -> 2gb/8gb) and I did observe many fewer OOMs, but still 1 OOM, and moreover 2gb/8gb impedes our ability to persist data later in this pipeline for an iterative ML algo so this isn't a feasible solution.\r\n- Maybe there's something fishy on the dask side happening here, in particular in the high variance of mem usage above `--memory-limit`? Or maybe I'm just making a dumb user error somewhere that's easy to fix?\r\n- Lmk if I can clarify or distill anything better!\r\n\r\n# Setup\r\n- 16 workers (on k8s on ec2), each running in its own docker container with 8gb mem and 1 cpu\r\n- Workers running with ~4gb mem limit, 1 proc, and 1 thread:\r\n  - `DASK_COMPRESSION=zlib dask-worker --nprocs 1 --nthreads 1 --memory-limit=4e9 --no-nanny <scheduler-url>`\r\n- Code looks like:\r\n\r\n```py\r\n# Read from parquet (s3)\r\n#   - 238 parts in\r\n#   - ~6.5gb total\r\n#   - Part file sizes vary 10-50mb (see plot below)\r\nddf_no_index = dd.read_parquet(in_path)\r\n\r\n# Pick task/part count for output\r\nnum_parts_out = ... # 128 or 512\r\n\r\n# Reindex to a column of uniformly distributed uuid5 values with fixed, uniform divisions\r\n#   - npartitions=num_parts_out, via divisions=uniform_divisions[num_parts_out]\r\nddf_indexed = ddf_no_index.set_index(\r\n    uniformly_distributed_uuid5_column,\r\n    drop=False,\r\n    divisions=uniform_divisions[num_parts_out],\r\n)\r\n\r\n# Write to parquet (s3)\r\n#   - 128 or 512 parts out\r\n#   - ~6.6gb total (based on a successful 128-part output)\r\n#   - When 128 parts, output part files vary 54-58mb (see plot below)\r\n#   - When 512 parts, output part files should vary ~10-15mb, but I didn't let the job finish\r\n(ddf_indexed\r\n    .astype(...)\r\n    .drop(ddf_indexed.index.name, axis=1)\r\n    .to_parquet(\r\n        out_path,\r\n        compression='snappy',\r\n        object_encoding=...,\r\n        write_index=True,\r\n    )\r\n)\r\n```\r\n\r\n- Data skew looks like:\r\n\r\n| input parquet.snappy part file sizes <br> 238 parts | output parquet.snappy part file sizes <br> 128 parts |\r\n|---|---|\r\n| ![fig-20170615t072553509023](https://user-images.githubusercontent.com/627486/27170013-36aae5e8-5161-11e7-97aa-c6f0e1e11564.png) | ![fig-20170615t073618347342](https://user-images.githubusercontent.com/627486/27170455-c870244c-5162-11e7-8214-c12098f77b41.png) |\r\n\r\n# Trials\r\n- Rows 1\u20132: my starting point was `num_parts_out=128` with `--memory-limit=4e9`, which fails a lot of the time but actually succeeded twice with many OOMs and long runtimes\r\n- Row 3: I increased task count to `num_parts_out=512`, but saw a similar frequency of OOMs and killed the job\r\n- Row 4: I decreased mem limit to `--memory-limit=2e9` but still saw 1 OOM (and thus some amount of repeated work)\r\n- Col \"sys metrics\": check out the change in variance in mem usage partway through the job, after which OOMs start happening\r\n- Col \"task aftermath\": you can see the lost workers, all due to OOMs\r\n- Col \"task counts\": shows the number of shuffle tasks, for reference (~6\u20138k)\r\n\r\n| params | outcome | task counts | task aftermath | sys metrics |\r\n|---|---|---|---|---|\r\n| 238&nbsp;parts&nbsp;in <br> 128&nbsp;parts&nbsp;out <br> 4g&nbsp;mem&nbsp;limit | 27&nbsp;OOMs <br> 111m <br> success ||| ![datadog 4g 128 2](https://user-images.githubusercontent.com/627486/27168445-86a68b94-515a-11e7-959c-c0c6a6478b12.png) |\r\n| 238&nbsp;parts&nbsp;in <br> 128&nbsp;parts&nbsp;out <br> 4g&nbsp;mem&nbsp;limit | 10&nbsp;OOMs <br> 47m <br> success | ![dask 4g 128](https://user-images.githubusercontent.com/627486/27167974-7228ba72-5158-11e7-8f16-5a9483c14baf.png) | ![tasks 4g 128](https://user-images.githubusercontent.com/627486/27167970-72013f56-5158-11e7-9472-60a16151c8e0.png) | ![datadog 4g 128](https://user-images.githubusercontent.com/627486/27168385-48cd352a-515a-11e7-8d20-69c4cd539cdf.png) |\r\n| 238&nbsp;parts&nbsp;in <br> 512&nbsp;parts&nbsp;out <br> 4g&nbsp;mem&nbsp;limit | >4&nbsp;OOMs <br> gave&nbsp;up&nbsp;early | ![dask 4g 512](https://user-images.githubusercontent.com/627486/27167969-71d81216-5158-11e7-858f-494876a9d6b0.png) | ![blank](https://user-images.githubusercontent.com/627486/27168471-a0b3693a-515a-11e7-8e45-e266fc4dcc00.png) | ![datadog 4g 512](https://user-images.githubusercontent.com/627486/27168326-0f06583a-515a-11e7-8566-059cffd39cac.png) |\r\n| 238&nbsp;parts&nbsp;in <br> 128&nbsp;parts&nbsp;out <br> 2g&nbsp;mem&nbsp;limit | 1&nbsp;OOM <br> 56m <br> success | ![dask 2g 128](https://user-images.githubusercontent.com/627486/27167976-723e4252-5158-11e7-9ae0-7e63b98c4c4e.png) | ![tasks 2g 128](https://user-images.githubusercontent.com/627486/27167977-72410082-5158-11e7-971f-b8769fd30213.png) | ![datadog 2g 128](https://user-images.githubusercontent.com/627486/27168416-645b8b98-515a-11e7-82cf-584f03443263.png) |\r\n\r\n# Versions\r\n```sh\r\n$ python --version\r\nPython 3.6.0\r\n\r\n$ cat requirements.txt | egrep 'dask|distributed|fastparquet'\r\ngit+https://github.com/dask/dask.git@a883f44\r\ngit+https://github.com/dask/fastparquet.git@d07d662\r\ndistributed==1.16.2\r\n```",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/2456/reactions",
        "total_count": 3,
        "+1": 3,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/2456/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}