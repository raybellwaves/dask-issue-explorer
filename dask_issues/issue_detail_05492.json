{
    "url": "https://api.github.com/repos/dask/dask/issues/5492",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/5492/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/5492/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/5492/events",
    "html_url": "https://github.com/dask/dask/issues/5492",
    "id": 506999545,
    "node_id": "MDU6SXNzdWU1MDY5OTk1NDU=",
    "number": 5492,
    "title": "Dask dataframe resample - value too large to convert to int",
    "user": {
        "login": "varunbpatil",
        "id": 1353218,
        "node_id": "MDQ6VXNlcjEzNTMyMTg=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1353218?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/varunbpatil",
        "html_url": "https://github.com/varunbpatil",
        "followers_url": "https://api.github.com/users/varunbpatil/followers",
        "following_url": "https://api.github.com/users/varunbpatil/following{/other_user}",
        "gists_url": "https://api.github.com/users/varunbpatil/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/varunbpatil/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/varunbpatil/subscriptions",
        "organizations_url": "https://api.github.com/users/varunbpatil/orgs",
        "repos_url": "https://api.github.com/users/varunbpatil/repos",
        "events_url": "https://api.github.com/users/varunbpatil/events{/privacy}",
        "received_events_url": "https://api.github.com/users/varunbpatil/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2019-10-15T04:36:18Z",
    "updated_at": "2019-11-19T02:12:47Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "**_This issue may not be related to Dask itself, but wanted to know if there is a better way._**\r\n\r\nI have a very large time-series Dask dataframe (~2.7 billion rows) in which there are several million timestamps (rows) missing.\r\n\r\nI am trying to do a `resample` to fill in the missing timestamps (rows) since there is no `reindex` in Dask.\r\n\r\n**The problem appears to be in the following code.**\r\n\r\nhttps://github.com/dask/dask/blob/0b2b15bd92857036e309f5e1bffbd766178361e9/dask/dataframe/tseries/resample.py#L41-L48\r\n\r\nspecifically, this line.\r\n\r\nhttps://github.com/dask/dask/blob/0b2b15bd92857036e309f5e1bffbd766178361e9/dask/dataframe/tseries/resample.py#L48\r\n\r\nFor boolean indexing like this one, pandas eventually calls `DataFrame.take()` which only takes in integer indexes and is not able to handle large row indexes like 2.7 billion.\r\n\r\n**Following is the full backtrace.**\r\n\r\n```python\r\n---------------------------------------------------------------------------\r\nOverflowError                             Traceback (most recent call last)\r\n/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getbool_axis(self, key, axis)\r\n   1440         try:\r\n-> 1441             return self.obj.take(inds, axis=axis)\r\n   1442         except Exception as detail:\r\n\r\n/usr/local/lib/python3.6/site-packages/pandas/core/series.py in take(self, indices, axis, is_copy, **kwargs)\r\n   4431         indices = ensure_platform_int(indices)\r\n-> 4432         new_index = self.index.take(indices)\r\n   4433\r\n\r\n/usr/local/lib/python3.6/site-packages/pandas/core/indexes/datetimelike.py in take(self, indices, axis, allow_fill, fill_value,\r\n**kwargs)\r\n    285\r\n--> 286         maybe_slice = lib.maybe_indices_to_slice(indices, len(self))\r\n    287         if isinstance(maybe_slice, slice):\r\n\r\npandas/_libs/lib.pyx in pandas._libs.lib.maybe_indices_to_slice()\r\n\r\nOverflowError: value too large to convert to int\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nKeyError                                  Traceback (most recent call last)\r\n<ipython-input-10-1ad4e47f52da> in <module>\r\n----> 1 df1 = df.resample('10ms').first()\r\n\r\n/usr/local/lib/python3.6/site-packages/dask/dataframe/tseries/resample.py in first(self)\r\n    154     @derived_from(pd_Resampler)\r\n    155     def first(self):\r\n--> 156         return self._agg(\"first\")\r\n    157\r\n    158     @derived_from(pd_Resampler)\r\n\r\n/usr/local/lib/python3.6/site-packages/dask/dataframe/tseries/resample.py in _agg(self, how, meta, fill_value, how_args, how_kwargs)\r\n    110         # Create a grouper to determine closed and label conventions\r\n    111         newdivs, outdivs = _resample_bin_and_out_divs(\r\n--> 112             self.obj.divisions, rule, **kwargs\r\n    113         )\r\n    114\r\n\r\n/usr/local/lib/python3.6/site-packages/dask/dataframe/tseries/resample.py in _resample_bin_and_out_divs(divisions, rule, closed, label)\r\n     46     divs = pd.Series(range(len(divisions)), index=divisions)\r\n     47     temp = divs.resample(rule, closed=closed, label=\"left\").count()\r\n---> 48     tempdivs = temp.loc[temp > 0].index\r\n     49\r\n     50     # Cleanup closed == 'right' and label == 'right'\r\n\r\n/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key)\r\n   1422\r\n   1423             maybe_callable = com.apply_if_callable(key, self.obj)\r\n-> 1424             return self._getitem_axis(maybe_callable, axis=axis)\r\n   1425\r\n   1426     def _is_scalar_access(self, key: Tuple):\r\n\r\n/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis)\r\n   1797             return self._get_slice_axis(key, axis=axis)\r\n   1798         elif com.is_bool_indexer(key):\r\n-> 1799             return self._getbool_axis(key, axis=axis)\r\n   1800         elif is_list_like_indexer(key):\r\n   1801\r\n\r\n/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getbool_axis(self, key, axis)\r\n   1441             return self.obj.take(inds, axis=axis)\r\n   1442         except Exception as detail:\r\n-> 1443             raise self._exception(detail)\r\n   1444\r\n   1445     def _get_slice_axis(self, slice_obj: slice, axis: int):\r\n\r\nKeyError: OverflowError('value too large to convert to int',)\r\n> /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py(1443)_getbool_axis()\r\n   1441             return self.obj.take(inds, axis=axis)\r\n   1442         except Exception as detail:\r\n-> 1443             raise self._exception(detail)\r\n   1444\r\n   1445     def _get_slice_axis(self, slice_obj: slice, axis: int):\r\n```\r\n\r\n**Following are some of the values I'm dealing with.**\r\n\r\n```python\r\n> /usr/local/lib/python3.6/site-packages/dask/dataframe/tseries/resample.py(48)_resample_bin_and_out_divs()\r\n     46     divs = pd.Series(range(len(divisions)), index=divisions)\r\n     47     temp = divs.resample(rule, closed=closed, label=\"left\").count()\r\n---> 48     tempdivs = temp.loc[temp > 0].index\r\n     49\r\n     50     # Cleanup closed == 'right' and label == 'right'\r\n\r\nipdb> p temp\r\n2018-09-21 00:44:32.180    1\r\n2018-09-21 00:44:32.190    0\r\n2018-09-21 00:44:32.200    0\r\n2018-09-21 00:44:32.210    0\r\n2018-09-21 00:44:32.220    0\r\n                          ..\r\n2019-07-30 17:40:23.080    0\r\n2019-07-30 17:40:23.090    0\r\n2019-07-30 17:40:23.100    0\r\n2019-07-30 17:40:23.110    0\r\n2019-07-30 17:40:23.120    1\r\nFreq: 10L, Length: 2701775095, dtype: int64\r\n\r\nipdb> temp.loc[temp > 0]\r\n*** KeyError: OverflowError('value too large to convert to int',)\r\n```\r\n\r\n```python\r\nipdb> d\r\n> /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py(1799)_getitem_axis()\r\n   1797             return self._get_slice_axis(key, axis=axis)\r\n   1798         elif com.is_bool_indexer(key):\r\n-> 1799             return self._getbool_axis(key, axis=axis)\r\n   1800         elif is_list_like_indexer(key):\r\n   1801\r\n\r\nipdb> p key\r\n2018-09-21 00:44:32.180     True\r\n2018-09-21 00:44:32.190    False\r\n2018-09-21 00:44:32.200    False\r\n2018-09-21 00:44:32.210    False\r\n2018-09-21 00:44:32.220    False\r\n                           ...\r\n2019-07-30 17:40:23.080    False\r\n2019-07-30 17:40:23.090    False\r\n2019-07-30 17:40:23.100    False\r\n2019-07-30 17:40:23.110    False\r\n2019-07-30 17:40:23.120     True\r\nFreq: 10L, Length: 2701775095, dtype: bool\r\n```\r\n\r\n```python\r\nipdb> d\r\n> /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py(1443)_getbool_axis()\r\n   1441             return self.obj.take(inds, axis=axis)\r\n   1442         except Exception as detail:\r\n-> 1443             raise self._exception(detail)\r\n   1444\r\n   1445     def _get_slice_axis(self, slice_obj: slice, axis: int):\r\n\r\nipdb> l\r\n   1438         key = check_bool_indexer(labels, key)\r\n   1439         inds, = key.nonzero()\r\n   1440         try:\r\n   1441             return self.obj.take(inds, axis=axis)\r\n   1442         except Exception as detail:\r\n-> 1443             raise self._exception(detail)\r\n   1444\r\n   1445     def _get_slice_axis(self, slice_obj: slice, axis: int):\r\n   1446         \"\"\" this is pretty simple as we just have to deal with labels \"\"\"\r\n   1447         # caller is responsible for ensuring non-None axis\r\n   1448         obj = self.obj\r\n\r\nipdb> p inds\r\narray([         0,       2782,       8782, ..., 2701766782, 2701772782,\r\n       2701775094])\r\nipdb> len(inds)\r\n450298\r\nipdb> p axis\r\n0\r\n```",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/5492/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/5492/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}