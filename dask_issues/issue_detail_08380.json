{
    "url": "https://api.github.com/repos/dask/dask/issues/8380",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/8380/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/8380/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/8380/events",
    "html_url": "https://github.com/dask/dask/issues/8380",
    "id": 1053960824,
    "node_id": "I_kwDOAbcwm84-0ip4",
    "number": 8380,
    "title": "da.store loses dependency information",
    "user": {
        "login": "djhoese",
        "id": 1828519,
        "node_id": "MDQ6VXNlcjE4Mjg1MTk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1828519?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/djhoese",
        "html_url": "https://github.com/djhoese",
        "followers_url": "https://api.github.com/users/djhoese/followers",
        "following_url": "https://api.github.com/users/djhoese/following{/other_user}",
        "gists_url": "https://api.github.com/users/djhoese/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/djhoese/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/djhoese/subscriptions",
        "organizations_url": "https://api.github.com/users/djhoese/orgs",
        "repos_url": "https://api.github.com/users/djhoese/repos",
        "events_url": "https://api.github.com/users/djhoese/events{/privacy}",
        "received_events_url": "https://api.github.com/users/djhoese/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862305,
            "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=",
            "url": "https://api.github.com/repos/dask/dask/labels/array",
            "name": "array",
            "color": "006b75",
            "default": false,
            "description": null
        },
        {
            "id": 3798450413,
            "node_id": "LA_kwDOAbcwm87iZ8Dt",
            "url": "https://api.github.com/repos/dask/dask/labels/bug",
            "name": "bug",
            "color": "faadaf",
            "default": true,
            "description": "Something is broken"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 12,
    "created_at": "2021-11-15T18:10:00Z",
    "updated_at": "2022-12-09T15:38:41Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "active_lock_reason": null,
    "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**What happened**:\r\n\r\nI'm trying to take the result from a `map_blocks` function and store one slice of the resulting array in one zarr array and another slice in another array. I set `compute=False` on the `da.store` calls so that I can compute them together later and avoid computing the array multiple times. However, it seems the map blocks function is called for each store operation. From what I can tell the dependency graph is getting lost.\r\n\r\n**What you expected to happen**:\r\n\r\nTwo `da.store` calls with shared tasks on their dask graphs should share computations when computed at the same time.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport dask\r\nimport dask.array as da\r\nimport numpy as np\r\n\r\nTOTAL_CALLS = 0\r\n\r\n\r\ndef shared_task2(arr1):\r\n    global TOTAL_CALLS\r\n    TOTAL_CALLS += 1\r\n    return np.stack([arr1 + 1, arr1 + 2])\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    start = da.zeros((2, 2), chunks=1)\r\n    src = da.map_blocks(shared_task2, start, dtype=start.dtype,\r\n                        meta=np.array((), dtype=start.dtype),\r\n                        new_axis=[0],\r\n                        chunks=(2,) + start.chunks)\r\n    target1 = np.zeros((2, 2))\r\n    target2 = np.zeros((2, 2))\r\n\r\n    with dask.config.set(schedulers='single-threaded'):\r\n        store_res1 = da.store(src[0], target1, compute=False)\r\n        store_res2 = da.store(src[1], target2, compute=False)\r\n        da.compute(store_res1, store_res2)\r\n    # one call per chunk\r\n    assert TOTAL_CALLS == start.blocks.size\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\nAs mentioned above, I'm actually trying to use `to_zarr` to save some dask arrays. I want to write them to zarr and then get the resulting loaded zarr arrays as results, but I couldn't find a way to do that with the combination of `return_stored` and `compute=False` as you need to compute to write to the zarr arrays, but that then returns the resulting numpy arrays.\r\n\r\nAlso note that my map_blocks function is returning the `np.stack` because it is actually returning two results. \r\n\r\n**Environment**:\r\n\r\n- Dask version: 2021.11.1\r\n- Python version: 3.9\r\n- Operating System: Ubuntu/PopOS\r\n- Install method (conda, pip, source): conda-forge\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/8380/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/8380/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}