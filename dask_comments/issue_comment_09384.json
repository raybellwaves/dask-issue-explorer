[
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1214249977",
        "html_url": "https://github.com/dask/dask/issues/9384#issuecomment-1214249977",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9384",
        "id": 1214249977,
        "node_id": "IC_kwDOAbcwm85IX_v5",
        "user": {
            "login": "ba05",
            "id": 38542612,
            "node_id": "MDQ6VXNlcjM4NTQyNjEy",
            "avatar_url": "https://avatars.githubusercontent.com/u/38542612?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ba05",
            "html_url": "https://github.com/ba05",
            "followers_url": "https://api.github.com/users/ba05/followers",
            "following_url": "https://api.github.com/users/ba05/following{/other_user}",
            "gists_url": "https://api.github.com/users/ba05/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ba05/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ba05/subscriptions",
            "organizations_url": "https://api.github.com/users/ba05/orgs",
            "repos_url": "https://api.github.com/users/ba05/repos",
            "events_url": "https://api.github.com/users/ba05/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ba05/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-14T00:10:06Z",
        "updated_at": "2022-08-14T00:10:06Z",
        "author_association": "NONE",
        "body": "Can you just convert the parquet to a pandas dataframe and then use df.to_pickle?",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1214249977/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1214276105",
        "html_url": "https://github.com/dask/dask/issues/9384#issuecomment-1214276105",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9384",
        "id": 1214276105,
        "node_id": "IC_kwDOAbcwm85IYGIJ",
        "user": {
            "login": "multimeric",
            "id": 5019367,
            "node_id": "MDQ6VXNlcjUwMTkzNjc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5019367?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/multimeric",
            "html_url": "https://github.com/multimeric",
            "followers_url": "https://api.github.com/users/multimeric/followers",
            "following_url": "https://api.github.com/users/multimeric/following{/other_user}",
            "gists_url": "https://api.github.com/users/multimeric/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/multimeric/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/multimeric/subscriptions",
            "organizations_url": "https://api.github.com/users/multimeric/orgs",
            "repos_url": "https://api.github.com/users/multimeric/repos",
            "events_url": "https://api.github.com/users/multimeric/events{/privacy}",
            "received_events_url": "https://api.github.com/users/multimeric/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-14T03:17:35Z",
        "updated_at": "2022-08-14T03:17:35Z",
        "author_association": "CONTRIBUTOR",
        "body": "I want a direct `dask.dataframe.DataFrame` \u2192 pickle conversion, without parquet involved.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1214276105/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1215889991",
        "html_url": "https://github.com/dask/dask/issues/9384#issuecomment-1215889991",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9384",
        "id": 1215889991,
        "node_id": "IC_kwDOAbcwm85IeQJH",
        "user": {
            "login": "jrbourbeau",
            "id": 11656932,
            "node_id": "MDQ6VXNlcjExNjU2OTMy",
            "avatar_url": "https://avatars.githubusercontent.com/u/11656932?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jrbourbeau",
            "html_url": "https://github.com/jrbourbeau",
            "followers_url": "https://api.github.com/users/jrbourbeau/followers",
            "following_url": "https://api.github.com/users/jrbourbeau/following{/other_user}",
            "gists_url": "https://api.github.com/users/jrbourbeau/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jrbourbeau/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jrbourbeau/subscriptions",
            "organizations_url": "https://api.github.com/users/jrbourbeau/orgs",
            "repos_url": "https://api.github.com/users/jrbourbeau/repos",
            "events_url": "https://api.github.com/users/jrbourbeau/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jrbourbeau/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-15T21:47:09Z",
        "updated_at": "2022-08-15T21:47:09Z",
        "author_association": "MEMBER",
        "body": "Thanks for the issue @multimeric! Adding a `to_pickle` method seems in scope. That said if you're experiencing issues with Dask's use of Parquet, I'd be interested in hearing more about them or (if you're interested) opening new issues. Always interested in how we can improve Dask's Parquet experience for users",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1215889991/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1215985314",
        "html_url": "https://github.com/dask/dask/issues/9384#issuecomment-1215985314",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9384",
        "id": 1215985314,
        "node_id": "IC_kwDOAbcwm85Ienai",
        "user": {
            "login": "multimeric",
            "id": 5019367,
            "node_id": "MDQ6VXNlcjUwMTkzNjc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5019367?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/multimeric",
            "html_url": "https://github.com/multimeric",
            "followers_url": "https://api.github.com/users/multimeric/followers",
            "following_url": "https://api.github.com/users/multimeric/following{/other_user}",
            "gists_url": "https://api.github.com/users/multimeric/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/multimeric/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/multimeric/subscriptions",
            "organizations_url": "https://api.github.com/users/multimeric/orgs",
            "repos_url": "https://api.github.com/users/multimeric/repos",
            "events_url": "https://api.github.com/users/multimeric/events{/privacy}",
            "received_events_url": "https://api.github.com/users/multimeric/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-15T23:36:05Z",
        "updated_at": "2022-08-15T23:36:05Z",
        "author_association": "CONTRIBUTOR",
        "body": "Okay so my main issue with parquet at the moment is in serializing dicts and lists. Here's a very simple example:\r\n\r\n```python\r\nimport dask.dataframe as dd\r\nimport pandas as pd\r\n\r\ndf = pd.DataFrame({\"a\": [[1, 2], [2, 3], [4, 5], [6, 7]], \"b\": [{\"key\": \"value\"}] * 4})\r\nddf = dd.from_pandas(\r\n    df,\r\n    npartitions=2,\r\n)\r\nddf.to_parquet(\"save\")\r\n```\r\n```\r\nValueError: Failed to convert partition to expected pyarrow schema:\r\n    `ArrowTypeError(\"Expected bytes, got a 'list' object\", 'Conversion failed for column a with type object')`\r\n\r\nExpected partition schema:\r\n    a: string\r\n    b: string\r\n    __null_dask_index__: int64\r\n\r\nReceived partition schema:\r\n    a: list<item: int64>\r\n      child 0, item: int64\r\n    b: struct<key: string>\r\n      child 0, key: string\r\n    __null_dask_index__: int64\r\n```\r\n\r\nSo it's true that, with improved type inference we could avoid this error (not sure if the type inference lives in dask, or in pyarrow though). However, I believe Parquet's lists and dicts are strongly typed, so if you have a data frame with several thousand rows, you would need to check *every* item in every list, in order to determine what type the list is. Then if you find out that it's a mixed-type list, I'm not sure what you could even do. So I understand why `to_parquet()` requires a schema in the way that it does. This is my motivation for `to_pickle`. It still lets you serialize the data frame, but it's the easy version which doesn't require and schema customization, at the cost of being only Python compatible (unlike Parquet which is pretty easy to read into any language).",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1215985314/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1216006214",
        "html_url": "https://github.com/dask/dask/issues/9384#issuecomment-1216006214",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9384",
        "id": 1216006214,
        "node_id": "IC_kwDOAbcwm85IeshG",
        "user": {
            "login": "ian-r-rose",
            "id": 5728311,
            "node_id": "MDQ6VXNlcjU3MjgzMTE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ian-r-rose",
            "html_url": "https://github.com/ian-r-rose",
            "followers_url": "https://api.github.com/users/ian-r-rose/followers",
            "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}",
            "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions",
            "organizations_url": "https://api.github.com/users/ian-r-rose/orgs",
            "repos_url": "https://api.github.com/users/ian-r-rose/repos",
            "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ian-r-rose/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-16T00:15:58Z",
        "updated_at": "2022-08-16T00:15:58Z",
        "author_association": "MEMBER",
        "body": "Dask makes the (often, but not always, accurate) assumption that an \"object\" dtype is a string when writing parquet datasets. If you are doing tricky things like serializing dicts and lists, then you will need to specify a pyarrow schema (see the brief discussion under the [schema](https://docs.dask.org/en/stable/generated/dask.dataframe.to_parquet.html#dask-dataframe-to-parquet) argument in `to_parquet`).\r\n\r\nIf you have a strict shape for these structures, you can try to provide a schema manually to describe them:\r\n\r\n```python\r\nimport pyarrow as pa\r\n\r\nschema = pa.schema(\r\n    {\r\n        \"a\": pa.list_(pa.int32()),\r\n        \"b\": pa.struct([(pa.field(\"key\", pa.string()))]),\r\n    }\r\n)\r\n\r\nddf.to_parquet(\"tmp.parquet\", schema=schema)\r\ndd.read_parquet(\"tmp.parquet\").compute()\r\n```\r\n\r\nThis, however, will fail if your data has lists/dicts that are less structured than the above. In that case, I might suggest a preprocessing step dumping them to something like JSON:\r\n\r\n```python\r\nimport json\r\n\r\nddf2 = ddf.applymap(json.dumps)\r\n\r\nddf2.to_parquet(\"tmp.parquet\", schema={\"a\": pa.binary(), \"b\": pa.binary()})\r\ndd.read_parquet(\"tmp.parquet\").applymap(json.loads, meta=\"object\").compute()\r\n```\r\n(Note: I think that parquet has a JSON dtype, but it wasn't immediately clear to me whether this is possible with pyarrow -- perhaps we could figure it out with more searching)\r\n\r\nIf you *really* want pickling, a similar trick might be done with `pickle`:\r\n```python\r\nimport pickle\r\n\r\nddf2 = ddf.applymap(pickle.dumps)\r\n\r\nddf2.to_parquet(\"tmp.parquet\", schema={\"a\": pa.binary(), \"b\": pa.binary()})\r\ndd.read_parquet(\"tmp.parquet\").applymap(pickle.loads, meta=\"object\").compute()\r\n```\r\n\r\n> This is my motivation for to_pickle. It still lets you serialize the data frame, but it's the easy version which doesn't require and schema customization, at the cost of being only Python compatible (unlike Parquet which is pretty easy to read into any language).\r\n\r\nI can see how writing all of the above are a bit more work than just writing `to_pickle()`, so I won't push back *too* hard against the idea, but to me the benefits of parquet make the extra work of dealing with object dtypes somewhat worth it.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1216006214/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1216009394",
        "html_url": "https://github.com/dask/dask/issues/9384#issuecomment-1216009394",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9384",
        "id": 1216009394,
        "node_id": "IC_kwDOAbcwm85IetSy",
        "user": {
            "login": "ian-r-rose",
            "id": 5728311,
            "node_id": "MDQ6VXNlcjU3MjgzMTE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5728311?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ian-r-rose",
            "html_url": "https://github.com/ian-r-rose",
            "followers_url": "https://api.github.com/users/ian-r-rose/followers",
            "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}",
            "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions",
            "organizations_url": "https://api.github.com/users/ian-r-rose/orgs",
            "repos_url": "https://api.github.com/users/ian-r-rose/repos",
            "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ian-r-rose/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-16T00:21:59Z",
        "updated_at": "2022-08-16T00:21:59Z",
        "author_association": "MEMBER",
        "body": "I should also note: if you want to just let pyarrow take a crack at serializing things, throwing schema-matching caution to the wind, you can pass `to_parquet(schema=None)`",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1216009394/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/dask/dask/issues/comments/1216089305",
        "html_url": "https://github.com/dask/dask/issues/9384#issuecomment-1216089305",
        "issue_url": "https://api.github.com/repos/dask/dask/issues/9384",
        "id": 1216089305,
        "node_id": "IC_kwDOAbcwm85IfAzZ",
        "user": {
            "login": "multimeric",
            "id": 5019367,
            "node_id": "MDQ6VXNlcjUwMTkzNjc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5019367?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/multimeric",
            "html_url": "https://github.com/multimeric",
            "followers_url": "https://api.github.com/users/multimeric/followers",
            "following_url": "https://api.github.com/users/multimeric/following{/other_user}",
            "gists_url": "https://api.github.com/users/multimeric/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/multimeric/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/multimeric/subscriptions",
            "organizations_url": "https://api.github.com/users/multimeric/orgs",
            "repos_url": "https://api.github.com/users/multimeric/repos",
            "events_url": "https://api.github.com/users/multimeric/events{/privacy}",
            "received_events_url": "https://api.github.com/users/multimeric/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-16T03:03:33Z",
        "updated_at": "2022-08-16T03:03:33Z",
        "author_association": "CONTRIBUTOR",
        "body": "I think there are some meaningful downsides with these workarounds, though. \r\n\r\nManually specifying a schema works well when you only have two columns like in my example, but my real life use case is loading in a massive data frame with hundreds of columns from JSON, at which point curating the schema is a huge undertaking that I wouldn't want to burden my users with. \r\n\r\nI can see the appeal of mapping to JSON strings, but this can't represent any arbitrary python type, although you are right that it works for lists and dicts as in my example. \r\n\r\nPickling each element is closer to what I'm after, because it will always succeed, but I suspect it will be less optimized than pickling the entire data frame, and it has the downside that no one function can load the data frame into a \"final\", usable data frame, because you need to apply your specific knowledge that each element needs to be unpickled first. If someone sees your `.parquet` file and tries to load it with any standard tool they would just see binary blobs in each cell of the table which is not intuitive.\r\n\r\nPickling each partition still strikes me as the easiest solution. Users can then just `from_pickle` to load the partitions back into memory, and it will be usable straight away, with all the data in the right format. They can even read individual partitions using pandas `from_pickle`, which I find is a great tool for debugging.",
        "reactions": {
            "url": "https://api.github.com/repos/dask/dask/issues/comments/1216089305/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]