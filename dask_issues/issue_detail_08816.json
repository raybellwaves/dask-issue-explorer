{
    "url": "https://api.github.com/repos/dask/dask/issues/8816",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/8816/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/8816/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/8816/events",
    "html_url": "https://github.com/dask/dask/issues/8816",
    "id": 1170191912,
    "node_id": "I_kwDOAbcwm85Fv7Yo",
    "number": 8816,
    "title": "`test_blockwise_dataframe_io[True-False-hdf]` is flaky on osx CI",
    "user": {
        "login": "jcrist",
        "id": 2783717,
        "node_id": "MDQ6VXNlcjI3ODM3MTc=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2783717?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/jcrist",
        "html_url": "https://github.com/jcrist",
        "followers_url": "https://api.github.com/users/jcrist/followers",
        "following_url": "https://api.github.com/users/jcrist/following{/other_user}",
        "gists_url": "https://api.github.com/users/jcrist/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/jcrist/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/jcrist/subscriptions",
        "organizations_url": "https://api.github.com/users/jcrist/orgs",
        "repos_url": "https://api.github.com/users/jcrist/repos",
        "events_url": "https://api.github.com/users/jcrist/events{/privacy}",
        "received_events_url": "https://api.github.com/users/jcrist/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        },
        {
            "id": 1887344368,
            "node_id": "MDU6TGFiZWwxODg3MzQ0MzY4",
            "url": "https://api.github.com/repos/dask/dask/labels/tests",
            "name": "tests",
            "color": "a0f9b4",
            "default": false,
            "description": "Unit tests and/or continuous integration"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": {
        "login": "jrbourbeau",
        "id": 11656932,
        "node_id": "MDQ6VXNlcjExNjU2OTMy",
        "avatar_url": "https://avatars.githubusercontent.com/u/11656932?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/jrbourbeau",
        "html_url": "https://github.com/jrbourbeau",
        "followers_url": "https://api.github.com/users/jrbourbeau/followers",
        "following_url": "https://api.github.com/users/jrbourbeau/following{/other_user}",
        "gists_url": "https://api.github.com/users/jrbourbeau/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/jrbourbeau/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/jrbourbeau/subscriptions",
        "organizations_url": "https://api.github.com/users/jrbourbeau/orgs",
        "repos_url": "https://api.github.com/users/jrbourbeau/repos",
        "events_url": "https://api.github.com/users/jrbourbeau/events{/privacy}",
        "received_events_url": "https://api.github.com/users/jrbourbeau/received_events",
        "type": "User",
        "site_admin": false
    },
    "assignees": [
        {
            "login": "jrbourbeau",
            "id": 11656932,
            "node_id": "MDQ6VXNlcjExNjU2OTMy",
            "avatar_url": "https://avatars.githubusercontent.com/u/11656932?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jrbourbeau",
            "html_url": "https://github.com/jrbourbeau",
            "followers_url": "https://api.github.com/users/jrbourbeau/followers",
            "following_url": "https://api.github.com/users/jrbourbeau/following{/other_user}",
            "gists_url": "https://api.github.com/users/jrbourbeau/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jrbourbeau/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jrbourbeau/subscriptions",
            "organizations_url": "https://api.github.com/users/jrbourbeau/orgs",
            "repos_url": "https://api.github.com/users/jrbourbeau/repos",
            "events_url": "https://api.github.com/users/jrbourbeau/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jrbourbeau/received_events",
            "type": "User",
            "site_admin": false
        }
    ],
    "milestone": null,
    "comments": 15,
    "created_at": "2022-03-15T20:21:29Z",
    "updated_at": "2022-08-04T19:09:03Z",
    "closed_at": null,
    "author_association": "MEMBER",
    "active_lock_reason": null,
    "body": "I noticed this test periodically failing due to a pytables locking issue today (may have started earlier). \r\n\r\n<details>\r\n<summary>Traceback </summary>\r\n\r\n```\r\n_________________ test_blockwise_dataframe_io[True-False-hdf] __________________\r\n[gw0] darwin -- Python 3.8.12 /Users/runner/miniconda3/envs/test-environment/bin/python\r\n\r\nc = <Client: 'tcp://127.0.0.1:50922' processes=2 threads=2, memory=28.00 GiB>\r\ntmpdir = local('/private/var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T/pytest-of-runner/pytest-0/popen-gw0/test_blockwise_dataframe_io_Tr3')\r\nio = 'hdf', fuse = False, from_futures = True\r\n\r\n    @pytest.mark.filterwarnings(\r\n        \"ignore:Running on a single-machine scheduler when a distributed client \"\r\n        \"is active might lead to unexpected results.\"\r\n    )\r\n    @pytest.mark.parametrize(\r\n        \"io\",\r\n        [\"parquet-pyarrow\", \"parquet-fastparquet\", \"csv\", \"hdf\"],\r\n    )\r\n    @pytest.mark.parametrize(\"fuse\", [True, False, None])\r\n    @pytest.mark.parametrize(\"from_futures\", [True, False])\r\n    def test_blockwise_dataframe_io(c, tmpdir, io, fuse, from_futures):\r\n        pd = pytest.importorskip(\"pandas\")\r\n        dd = pytest.importorskip(\"dask.dataframe\")\r\n    \r\n        df = pd.DataFrame({\"x\": [1, 2, 3] * 5, \"y\": range(15)})\r\n    \r\n        if from_futures:\r\n            parts = [df.iloc[:5], df.iloc[5:10], df.iloc[10:15]]\r\n            futs = c.scatter(parts)\r\n            ddf0 = dd.from_delayed(futs, meta=parts[0])\r\n        else:\r\n            ddf0 = dd.from_pandas(df, npartitions=3)\r\n    \r\n        if io.startswith(\"parquet\"):\r\n            if io == \"parquet-pyarrow\":\r\n                pytest.importorskip(\"pyarrow.parquet\")\r\n                engine = \"pyarrow\"\r\n            else:\r\n                pytest.importorskip(\"fastparquet\")\r\n                engine = \"fastparquet\"\r\n            ddf0.to_parquet(str(tmpdir), engine=engine)\r\n            ddf = dd.read_parquet(str(tmpdir), engine=engine)\r\n        elif io == \"csv\":\r\n            ddf0.to_csv(str(tmpdir), index=False)\r\n            ddf = dd.read_csv(os.path.join(str(tmpdir), \"*\"))\r\n        elif io == \"hdf\":\r\n            pytest.importorskip(\"tables\")\r\n            fn = str(tmpdir.join(\"h5\"))\r\n>           ddf0.to_hdf(fn, \"/data*\")\r\n\r\ndask/tests/test_distributed.py:370: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\ndask/dataframe/core.py:1620: in to_hdf\r\n    return to_hdf(self, path_or_buf, key, mode, append, **kwargs)\r\ndask/dataframe/io/hdf.py:251: in to_hdf\r\n    compute_as_if_collection(\r\ndask/base.py:319: in compute_as_if_collection\r\n    return schedule(dsk2, keys, **kwargs)\r\n../../../miniconda3/envs/test-environment/lib/python3.8/site-packages/distributed/client.py:3015: in get\r\n    results = self.gather(packed, asynchronous=asynchronous, direct=direct)\r\n../../../miniconda3/envs/test-environment/lib/python3.8/site-packages/distributed/client.py:2167: in gather\r\n    return self.sync(\r\n../../../miniconda3/envs/test-environment/lib/python3.8/site-packages/distributed/utils.py:311: in sync\r\n    return sync(\r\n../../../miniconda3/envs/test-environment/lib/python3.8/site-packages/distributed/utils.py:378: in sync\r\n    raise exc.with_traceback(tb)\r\n../../../miniconda3/envs/test-environment/lib/python3.8/site-packages/distributed/utils.py:351: in f\r\n    result = yield future\r\n../../../miniconda3/envs/test-environment/lib/python3.8/site-packages/tornado/gen.py:762: in run\r\n    value = future.result()\r\n../../../miniconda3/envs/test-environment/lib/python3.8/site-packages/distributed/client.py:2030: in _gather\r\n    raise exception.with_traceback(traceback)\r\ndask/dataframe/io/hdf.py:27: in _pd_to_hdf\r\n    pd_to_hdf(*args, **kwargs)\r\n../../../miniconda3/envs/test-environment/lib/python3.8/site-packages/pandas/core/generic.py:2606: in to_hdf\r\n    pytables.to_hdf(\r\n../../../miniconda3/envs/test-environment/lib/python3.8/site-packages/pandas/io/pytables.py:277: in to_hdf\r\n    with HDFStore(\r\n../../../miniconda3/envs/test-environment/lib/python3.8/site-packages/pandas/io/pytables.py:561: in __init__\r\n    self.open(mode=mode, **kwargs)\r\n../../../miniconda3/envs/test-environment/lib/python3.8/site-packages/pandas/io/pytables.py:710: in open\r\n    self._handle = tables.open_file(self._path, self._mode, **kwargs)\r\n../../../miniconda3/envs/test-environment/lib/python3.8/site-packages/tables/file.py:300: in open_file\r\n    return File(filename, mode, title, root_uep, filters, **kwargs)\r\n../../../miniconda3/envs/test-environment/lib/python3.8/site-packages/tables/file.py:750: in __init__\r\n    self._g_new(filename, mode, **params)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\n>   ???\r\nE   tables.exceptions.HDF5ExtError: HDF5 error back trace\r\nE   \r\nE     File \"H5F.c\", line 620, in H5Fopen\r\nE       unable to open file\r\nE     File \"H5VLcallback.c\", line 3502, in H5VL_file_open\r\nE       failed to iterate over available VOL connector plugins\r\nE     File \"H5PLpath.c\", line 579, in H5PL__path_table_iterate\r\nE       can't iterate over plugins in plugin path '(null)'\r\nE     File \"H5PLpath.c\", line 620, in H5PL__path_table_iterate_process_path\r\nE       can't open directory: /Users/runner/miniconda3/envs/test-environment/lib/hdf5/plugin\r\nE     File \"H5VLcallback.c\", line 3351, in H5VL__file_open\r\nE       open failed\r\nE     File \"H5VLnative_file.c\", line 97, in H5VL__native_file_open\r\nE       unable to open file\r\nE     File \"H5Fint.c\", line 1898, in H5F_open\r\nE       unable to lock the file\r\nE     File \"H5FD.c\", line 1625, in H5FD_lock\r\nE       driver lock request failed\r\nE     File \"H5FDsec2.c\", line 1002, in H5FD__sec2_lock\r\nE       unable to lock file, errno = 35, error message = 'Resource temporarily unavailable'\r\nE   \r\nE   End of HDF5 error back trace\r\nE   \r\nE   Unable to open/create file '/private/var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T/pytest-of-runner/pytest-0/popen-gw0/test_blockwise_dataframe_io_Tr3/h5'\r\n\r\ntables/hdf5extension.pyx:486: HDF5ExtError\r\n```\r\n\r\n</details>\r\n\r\nLog from failing test: https://github.com/dask/dask/runs/5558289646?check_suite_focus=true#step:6:21912",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/8816/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/8816/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}