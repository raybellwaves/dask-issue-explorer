{
    "url": "https://api.github.com/repos/dask/dask/issues/3842",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/3842/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/3842/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/3842/events",
    "html_url": "https://github.com/dask/dask/issues/3842",
    "id": 347074081,
    "node_id": "MDU6SXNzdWUzNDcwNzQwODE=",
    "number": 3842,
    "title": "Saving to parquet with partition_on results in loss of divisions when reading it back to dataframe.",
    "user": {
        "login": "TSFelg",
        "id": 38079600,
        "node_id": "MDQ6VXNlcjM4MDc5NjAw",
        "avatar_url": "https://avatars.githubusercontent.com/u/38079600?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/TSFelg",
        "html_url": "https://github.com/TSFelg",
        "followers_url": "https://api.github.com/users/TSFelg/followers",
        "following_url": "https://api.github.com/users/TSFelg/following{/other_user}",
        "gists_url": "https://api.github.com/users/TSFelg/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/TSFelg/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/TSFelg/subscriptions",
        "organizations_url": "https://api.github.com/users/TSFelg/orgs",
        "repos_url": "https://api.github.com/users/TSFelg/repos",
        "events_url": "https://api.github.com/users/TSFelg/events{/privacy}",
        "received_events_url": "https://api.github.com/users/TSFelg/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862289,
            "node_id": "MDU6TGFiZWwyNDI4NjIyODk=",
            "url": "https://api.github.com/repos/dask/dask/labels/dataframe",
            "name": "dataframe",
            "color": "fbca04",
            "default": false,
            "description": null
        },
        {
            "id": 386719598,
            "node_id": "MDU6TGFiZWwzODY3MTk1OTg=",
            "url": "https://api.github.com/repos/dask/dask/labels/documentation",
            "name": "documentation",
            "color": "f9d0c4",
            "default": true,
            "description": "Improve or add to documentation"
        },
        {
            "id": 2949099791,
            "node_id": "MDU6TGFiZWwyOTQ5MDk5Nzkx",
            "url": "https://api.github.com/repos/dask/dask/labels/parquet",
            "name": "parquet",
            "color": "77A66C",
            "default": false,
            "description": ""
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 4,
    "created_at": "2018-08-02T15:56:23Z",
    "updated_at": "2021-10-12T07:26:16Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "\r\n# TLDR\r\nWhen I save a Dask dataframe to parquet using partition on a certain collumn and then I read those parquet files into a dataframe the divisions are lost. This doesn't happen with every dataframe, for example if the collumn I'm using for the partitioning (let's call it 'Categoricals') is ordered then this problem won't happen. Below I'll leave an example where the problem happens and one where it doesn't.\r\n\r\n# Imports\r\n\r\n\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\nfrom fastparquet import ParquetFile\r\n```\r\n\r\n    /usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\r\n      return f(*args, **kwds)\r\n    /usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\r\n      return f(*args, **kwds)\r\n\r\n\r\n# Example where divisions are known\r\n\r\nHere I created a dummy dataframe where the column by which we partition ('Categoricals') is ordered, as can be seen the divisions are known after loading the parquet file.\r\n\r\n\r\n```python\r\ndef generate_df(size):\r\n    df = pd.Series(np.arange(0, size), name='unique').to_frame()\r\n\r\n    df['dates'] = pd.date_range('2015-01-01', periods=size, freq='1min', name='dates')\r\n    df['ints'] = np.linspace(0, 100, size, endpoint=False, dtype=int)\r\n    df['floats'] = df['ints'].astype(float)\r\n    df['constants'] = 42\r\n    df['uniques'] = df['unique'].astype(str)\r\n\r\n    # nanints is ints with first 10% entries set to nan\r\n    df['nanints'] = df['ints']\r\n    df.loc[df.index < int(size / 10), 'nanints'] = np.nan\r\n\r\n    # generate categorical column with 4 distinct values\r\n    categoricals = []\r\n    for value in ['a', 'b', 'c', 'd']:\r\n        categoricals += [value] * int(size / 4)\r\n    df['categoricals'] = categoricals\r\n    df['nancategoricals'] = df['categoricals'].replace('d', np.nan)\r\n\r\n    return df\r\n```\r\n\r\n\r\n```python\r\ndf = generate_df(16)\r\n```\r\n\r\n\r\n```python\r\ndf = df.set_index('dates')\r\ndf = dd.from_pandas(df, npartitions=3)\r\n```\r\n\r\n\r\n```python\r\ndf.head(16, npartitions=-1)\r\n```\r\n\r\n\r\n</style>\r\n<table border=\"1\" class=\"dataframe\">\r\n  <thead>\r\n    <tr style=\"text-align: right;\">\r\n      <th></th>\r\n      <th>unique</th>\r\n      <th>ints</th>\r\n      <th>floats</th>\r\n      <th>constants</th>\r\n      <th>uniques</th>\r\n      <th>nanints</th>\r\n      <th>categoricals</th>\r\n      <th>nancategoricals</th>\r\n    </tr>\r\n    <tr>\r\n      <th>dates</th>\r\n      <th></th>\r\n      <th></th>\r\n      <th></th>\r\n      <th></th>\r\n      <th></th>\r\n      <th></th>\r\n      <th></th>\r\n      <th></th>\r\n    </tr>\r\n  </thead>\r\n  <tbody>\r\n    <tr>\r\n      <th>2015-01-01 00:00:00</th>\r\n      <td>0</td>\r\n      <td>0</td>\r\n      <td>0.0</td>\r\n      <td>42</td>\r\n      <td>0</td>\r\n      <td>NaN</td>\r\n      <td>a</td>\r\n      <td>a</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:01:00</th>\r\n      <td>1</td>\r\n      <td>6</td>\r\n      <td>6.0</td>\r\n      <td>42</td>\r\n      <td>1</td>\r\n      <td>6.0</td>\r\n      <td>a</td>\r\n      <td>a</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:02:00</th>\r\n      <td>2</td>\r\n      <td>12</td>\r\n      <td>12.0</td>\r\n      <td>42</td>\r\n      <td>2</td>\r\n      <td>12.0</td>\r\n      <td>a</td>\r\n      <td>a</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:03:00</th>\r\n      <td>3</td>\r\n      <td>18</td>\r\n      <td>18.0</td>\r\n      <td>42</td>\r\n      <td>3</td>\r\n      <td>18.0</td>\r\n      <td>a</td>\r\n      <td>a</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:04:00</th>\r\n      <td>4</td>\r\n      <td>25</td>\r\n      <td>25.0</td>\r\n      <td>42</td>\r\n      <td>4</td>\r\n      <td>25.0</td>\r\n      <td>b</td>\r\n      <td>b</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:05:00</th>\r\n      <td>5</td>\r\n      <td>31</td>\r\n      <td>31.0</td>\r\n      <td>42</td>\r\n      <td>5</td>\r\n      <td>31.0</td>\r\n      <td>b</td>\r\n      <td>b</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:06:00</th>\r\n      <td>6</td>\r\n      <td>37</td>\r\n      <td>37.0</td>\r\n      <td>42</td>\r\n      <td>6</td>\r\n      <td>37.0</td>\r\n      <td>b</td>\r\n      <td>b</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:07:00</th>\r\n      <td>7</td>\r\n      <td>43</td>\r\n      <td>43.0</td>\r\n      <td>42</td>\r\n      <td>7</td>\r\n      <td>43.0</td>\r\n      <td>b</td>\r\n      <td>b</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:08:00</th>\r\n      <td>8</td>\r\n      <td>50</td>\r\n      <td>50.0</td>\r\n      <td>42</td>\r\n      <td>8</td>\r\n      <td>50.0</td>\r\n      <td>c</td>\r\n      <td>c</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:09:00</th>\r\n      <td>9</td>\r\n      <td>56</td>\r\n      <td>56.0</td>\r\n      <td>42</td>\r\n      <td>9</td>\r\n      <td>56.0</td>\r\n      <td>c</td>\r\n      <td>c</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:10:00</th>\r\n      <td>10</td>\r\n      <td>62</td>\r\n      <td>62.0</td>\r\n      <td>42</td>\r\n      <td>10</td>\r\n      <td>62.0</td>\r\n      <td>c</td>\r\n      <td>c</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:11:00</th>\r\n      <td>11</td>\r\n      <td>68</td>\r\n      <td>68.0</td>\r\n      <td>42</td>\r\n      <td>11</td>\r\n      <td>68.0</td>\r\n      <td>c</td>\r\n      <td>c</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:12:00</th>\r\n      <td>12</td>\r\n      <td>75</td>\r\n      <td>75.0</td>\r\n      <td>42</td>\r\n      <td>12</td>\r\n      <td>75.0</td>\r\n      <td>d</td>\r\n      <td>NaN</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:13:00</th>\r\n      <td>13</td>\r\n      <td>81</td>\r\n      <td>81.0</td>\r\n      <td>42</td>\r\n      <td>13</td>\r\n      <td>81.0</td>\r\n      <td>d</td>\r\n      <td>NaN</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:14:00</th>\r\n      <td>14</td>\r\n      <td>87</td>\r\n      <td>87.0</td>\r\n      <td>42</td>\r\n      <td>14</td>\r\n      <td>87.0</td>\r\n      <td>d</td>\r\n      <td>NaN</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:15:00</th>\r\n      <td>15</td>\r\n      <td>93</td>\r\n      <td>93.0</td>\r\n      <td>42</td>\r\n      <td>15</td>\r\n      <td>93.0</td>\r\n      <td>d</td>\r\n      <td>NaN</td>\r\n    </tr>\r\n  </tbody>\r\n</table>\r\n</div>\r\n\r\n\r\n\r\n\r\n```python\r\ndf.divisions \r\n```\r\n\r\n\r\n\r\n\r\n    (Timestamp('2015-01-01 00:00:00'),\r\n     Timestamp('2015-01-01 00:06:00'),\r\n     Timestamp('2015-01-01 00:12:00'),\r\n     Timestamp('2015-01-01 00:15:00'))\r\n\r\n\r\n\r\n\r\n```python\r\ndf.to_parquet('./data_new', engine='fastparquet', partition_on=['categoricals'])\r\n\r\n```\r\n\r\n    /home/felgueira/.local/lib/python3.5/site-packages/fastparquet/writer.py:407: FutureWarning: Method .valid will be removed in a future version. Use .dropna instead.\r\n      out = data.valid()  # better, data[data.notnull()], from above ?\r\n\r\n\r\n\r\n```python\r\npq_f = ParquetFile('./data_new')\r\n\r\n```\r\n\r\n\r\n```python\r\ndf = dd.read_parquet(pq_f)\r\n\r\n```\r\n\r\n\r\n```python\r\ndf.divisions\r\n\r\n```\r\n\r\n\r\n\r\n\r\n    (Timestamp('2015-01-01 00:00:00'),\r\n     Timestamp('2015-01-01 00:04:00'),\r\n     Timestamp('2015-01-01 00:06:00'),\r\n     Timestamp('2015-01-01 00:08:00'),\r\n     Timestamp('2015-01-01 00:12:00'),\r\n     Timestamp('2015-01-01 00:15:00'))\r\n\r\n\r\n\r\n# Example where divisions are not known\r\n\r\nHere I created a dummy dataframe where the column by which we partition ('Categoricals') is not ordered because of an \"outlier\", as can be seen the divisions are not known after loading the parquet file.\r\n\r\n\r\n```python\r\ndef generate_df(size):\r\n    df = pd.Series(np.arange(0, size), name='unique').to_frame()\r\n\r\n    df['dates'] = pd.date_range('2015-01-01', periods=size, freq='1min', name='dates')\r\n    df['ints'] = np.linspace(0, 100, size, endpoint=False, dtype=int)\r\n    df['floats'] = df['ints'].astype(float)\r\n    df['constants'] = 42\r\n    df['uniques'] = df['unique'].astype(str)\r\n\r\n    # nanints is ints with first 10% entries set to nan\r\n    df['nanints'] = df['ints']\r\n    df.loc[df.index < int(size / 10), 'nanints'] = np.nan\r\n\r\n    # generate categorical column with 4 distinct values\r\n    categoricals = []\r\n    for value in ['a', 'b', 'c', 'd']:\r\n        categoricals += [value] * int(size / 4)\r\n    categoricals[10] = 'b'\r\n    df['categoricals'] = categoricals\r\n    df['nancategoricals'] = df['categoricals'].replace('d', np.nan)\r\n\r\n    return df\r\n```\r\n\r\n\r\n```python\r\ndf = generate_df(16)\r\n```\r\n\r\n\r\n```python\r\ndf = df.set_index('dates')\r\ndf = dd.from_pandas(df, npartitions=3)\r\n```\r\n\r\n\r\n```python\r\ndf.head(16, npartitions=-1)\r\n```\r\n\r\n\r\n\r\n\r\n<table border=\"1\" class=\"dataframe\">\r\n  <thead>\r\n    <tr style=\"text-align: right;\">\r\n      <th></th>\r\n      <th>unique</th>\r\n      <th>ints</th>\r\n      <th>floats</th>\r\n      <th>constants</th>\r\n      <th>uniques</th>\r\n      <th>nanints</th>\r\n      <th>categoricals</th>\r\n      <th>nancategoricals</th>\r\n    </tr>\r\n    <tr>\r\n      <th>dates</th>\r\n      <th></th>\r\n      <th></th>\r\n      <th></th>\r\n      <th></th>\r\n      <th></th>\r\n      <th></th>\r\n      <th></th>\r\n      <th></th>\r\n    </tr>\r\n  </thead>\r\n  <tbody>\r\n    <tr>\r\n      <th>2015-01-01 00:00:00</th>\r\n      <td>0</td>\r\n      <td>0</td>\r\n      <td>0.0</td>\r\n      <td>42</td>\r\n      <td>0</td>\r\n      <td>NaN</td>\r\n      <td>a</td>\r\n      <td>a</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:01:00</th>\r\n      <td>1</td>\r\n      <td>6</td>\r\n      <td>6.0</td>\r\n      <td>42</td>\r\n      <td>1</td>\r\n      <td>6.0</td>\r\n      <td>a</td>\r\n      <td>a</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:02:00</th>\r\n      <td>2</td>\r\n      <td>12</td>\r\n      <td>12.0</td>\r\n      <td>42</td>\r\n      <td>2</td>\r\n      <td>12.0</td>\r\n      <td>a</td>\r\n      <td>a</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:03:00</th>\r\n      <td>3</td>\r\n      <td>18</td>\r\n      <td>18.0</td>\r\n      <td>42</td>\r\n      <td>3</td>\r\n      <td>18.0</td>\r\n      <td>a</td>\r\n      <td>a</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:04:00</th>\r\n      <td>4</td>\r\n      <td>25</td>\r\n      <td>25.0</td>\r\n      <td>42</td>\r\n      <td>4</td>\r\n      <td>25.0</td>\r\n      <td>b</td>\r\n      <td>b</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:05:00</th>\r\n      <td>5</td>\r\n      <td>31</td>\r\n      <td>31.0</td>\r\n      <td>42</td>\r\n      <td>5</td>\r\n      <td>31.0</td>\r\n      <td>b</td>\r\n      <td>b</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:06:00</th>\r\n      <td>6</td>\r\n      <td>37</td>\r\n      <td>37.0</td>\r\n      <td>42</td>\r\n      <td>6</td>\r\n      <td>37.0</td>\r\n      <td>b</td>\r\n      <td>b</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:07:00</th>\r\n      <td>7</td>\r\n      <td>43</td>\r\n      <td>43.0</td>\r\n      <td>42</td>\r\n      <td>7</td>\r\n      <td>43.0</td>\r\n      <td>b</td>\r\n      <td>b</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:08:00</th>\r\n      <td>8</td>\r\n      <td>50</td>\r\n      <td>50.0</td>\r\n      <td>42</td>\r\n      <td>8</td>\r\n      <td>50.0</td>\r\n      <td>c</td>\r\n      <td>c</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:09:00</th>\r\n      <td>9</td>\r\n      <td>56</td>\r\n      <td>56.0</td>\r\n      <td>42</td>\r\n      <td>9</td>\r\n      <td>56.0</td>\r\n      <td>c</td>\r\n      <td>c</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:10:00</th>\r\n      <td>10</td>\r\n      <td>62</td>\r\n      <td>62.0</td>\r\n      <td>42</td>\r\n      <td>10</td>\r\n      <td>62.0</td>\r\n      <td>b</td>\r\n      <td>b</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:11:00</th>\r\n      <td>11</td>\r\n      <td>68</td>\r\n      <td>68.0</td>\r\n      <td>42</td>\r\n      <td>11</td>\r\n      <td>68.0</td>\r\n      <td>c</td>\r\n      <td>c</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:12:00</th>\r\n      <td>12</td>\r\n      <td>75</td>\r\n      <td>75.0</td>\r\n      <td>42</td>\r\n      <td>12</td>\r\n      <td>75.0</td>\r\n      <td>d</td>\r\n      <td>NaN</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:13:00</th>\r\n      <td>13</td>\r\n      <td>81</td>\r\n      <td>81.0</td>\r\n      <td>42</td>\r\n      <td>13</td>\r\n      <td>81.0</td>\r\n      <td>d</td>\r\n      <td>NaN</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:14:00</th>\r\n      <td>14</td>\r\n      <td>87</td>\r\n      <td>87.0</td>\r\n      <td>42</td>\r\n      <td>14</td>\r\n      <td>87.0</td>\r\n      <td>d</td>\r\n      <td>NaN</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2015-01-01 00:15:00</th>\r\n      <td>15</td>\r\n      <td>93</td>\r\n      <td>93.0</td>\r\n      <td>42</td>\r\n      <td>15</td>\r\n      <td>93.0</td>\r\n      <td>d</td>\r\n      <td>NaN</td>\r\n    </tr>\r\n  </tbody>\r\n</table>\r\n</div>\r\n\r\n\r\n\r\n\r\n```python\r\ndf.divisions \r\n```\r\n\r\n\r\n\r\n\r\n    (Timestamp('2015-01-01 00:00:00'),\r\n     Timestamp('2015-01-01 00:06:00'),\r\n     Timestamp('2015-01-01 00:12:00'),\r\n     Timestamp('2015-01-01 00:15:00'))\r\n\r\n\r\n\r\n\r\n```python\r\ndf.to_parquet('./data_new', engine='fastparquet', partition_on=['categoricals'])\r\n\r\n```\r\n\r\n    /home/felgueira/.local/lib/python3.5/site-packages/fastparquet/writer.py:407: FutureWarning: Method .valid will be removed in a future version. Use .dropna instead.\r\n      out = data.valid()  # better, data[data.notnull()], from above ?\r\n\r\n\r\n\r\n```python\r\npq_f = ParquetFile('./data_new')\r\n\r\n```\r\n\r\n\r\n```python\r\ndf = dd.read_parquet(pq_f)\r\n\r\n```\r\n\r\n\r\n```python\r\ndf.divisions\r\n\r\n```\r\n\r\n\r\n\r\n\r\n    (None, None, None, None, None, None)\r\n\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/3842/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/3842/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}