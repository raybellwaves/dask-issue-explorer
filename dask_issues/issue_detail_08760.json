{
    "url": "https://api.github.com/repos/dask/dask/issues/8760",
    "repository_url": "https://api.github.com/repos/dask/dask",
    "labels_url": "https://api.github.com/repos/dask/dask/issues/8760/labels{/name}",
    "comments_url": "https://api.github.com/repos/dask/dask/issues/8760/comments",
    "events_url": "https://api.github.com/repos/dask/dask/issues/8760/events",
    "html_url": "https://github.com/dask/dask/issues/8760",
    "id": 1151024140,
    "node_id": "I_kwDOAbcwm85EmzwM",
    "number": 8760,
    "title": "Error pickling h5py objects with multiprocessing scheduler",
    "user": {
        "login": "scharlottej13",
        "id": 8620816,
        "node_id": "MDQ6VXNlcjg2MjA4MTY=",
        "avatar_url": "https://avatars.githubusercontent.com/u/8620816?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/scharlottej13",
        "html_url": "https://github.com/scharlottej13",
        "followers_url": "https://api.github.com/users/scharlottej13/followers",
        "following_url": "https://api.github.com/users/scharlottej13/following{/other_user}",
        "gists_url": "https://api.github.com/users/scharlottej13/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/scharlottej13/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/scharlottej13/subscriptions",
        "organizations_url": "https://api.github.com/users/scharlottej13/orgs",
        "repos_url": "https://api.github.com/users/scharlottej13/repos",
        "events_url": "https://api.github.com/users/scharlottej13/events{/privacy}",
        "received_events_url": "https://api.github.com/users/scharlottej13/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 242862305,
            "node_id": "MDU6TGFiZWwyNDI4NjIzMDU=",
            "url": "https://api.github.com/repos/dask/dask/labels/array",
            "name": "array",
            "color": "006b75",
            "default": false,
            "description": null
        },
        {
            "id": 365513534,
            "node_id": "MDU6TGFiZWwzNjU1MTM1MzQ=",
            "url": "https://api.github.com/repos/dask/dask/labels/io",
            "name": "io",
            "color": "6f871c",
            "default": false,
            "description": ""
        },
        {
            "id": 3798450413,
            "node_id": "LA_kwDOAbcwm87iZ8Dt",
            "url": "https://api.github.com/repos/dask/dask/labels/bug",
            "name": "bug",
            "color": "faadaf",
            "default": true,
            "description": "Something is broken"
        },
        {
            "id": 3798450422,
            "node_id": "LA_kwDOAbcwm87iZ8D2",
            "url": "https://api.github.com/repos/dask/dask/labels/p3",
            "name": "p3",
            "color": "ffff33",
            "default": false,
            "description": "Affects a small number of users or is largely cosmetic"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 3,
    "created_at": "2022-02-26T01:34:30Z",
    "updated_at": "2022-06-30T14:39:48Z",
    "closed_at": null,
    "author_association": "MEMBER",
    "active_lock_reason": null,
    "body": "**What happened**:\r\nThis issue first came up on [discourse](https://dask.discourse.group/t/h5py-objects-cannot-be-pickled-or-slow-processing/229). When using the multiprocessing scheduler with `h5py` objects, there is a `TypeError: h5py objects cannot be pickled`. This does not happen when using the distributed scheduler.\r\n\r\n**Minimal Complete Verifiable Example**:\r\n```python\r\nimport h5py\r\nimport dask.array as da\r\n\r\n# create fake hdf5 for testing\r\nf = h5py.File(\"tmp/mytestfile.hdf5\", \"w\")\r\ndset = f.create_dataset(\"mydataset\", (1000, 3), dtype='i')\r\n\r\n# read it back in\r\nf = h5py.File('tmp/mytestfile.hdf5', 'r')\r\ndset = f['mydataset']\r\n\r\n# send dask array result to map_blocks\r\ndask_array = da.from_array(dset, chunks=(dset.shape[0], 1))\r\n\r\ndoubled = dask_array.map_blocks(lambda x: x * 2)\r\ndoubled.compute(scheduler='processes')\r\n```\r\n<details>\r\n <summary>Full traceback</summary>\r\n\r\n```python-traceback\r\n  ---------------------------------------------------------------------------\r\n  TypeError                                 Traceback (most recent call last)\r\n  /var/folders/hf/2s7qjx7j5ndc5220_qxv8y800000gn/T/ipykernel_8250/2047040186.py in <module>\r\n       17 \r\n       18 # compute\r\n  ---> 19 doubled.compute(scheduler='processes')\r\n  \r\n  ~/mambaforge/envs/dask-mini-tutorial/lib/python3.9/site-packages/dask/base.py in compute(self, **kwargs)\r\n      288         dask.base.compute\r\n      289         \"\"\"\r\n  --> 290         (result,) = compute(self, traverse=False, **kwargs)\r\n      291         return result\r\n      292 \r\n  \r\n  ~/mambaforge/envs/dask-mini-tutorial/lib/python3.9/site-packages/dask/base.py in compute(traverse, optimize_graph, scheduler, get, *args, **kwargs)\r\n      571         postcomputes.append(x.__dask_postcompute__())\r\n      572 \r\n  --> 573     results = schedule(dsk, keys, **kwargs)\r\n      574     return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\r\n      575 \r\n  \r\n  ~/mambaforge/envs/dask-mini-tutorial/lib/python3.9/site-packages/dask/multiprocessing.py in get(dsk, keys, num_workers, func_loads, func_dumps, optimize_graph, pool, chunksize, **kwargs)\r\n      218     try:\r\n      219         # Run\r\n  --> 220         result = get_async(\r\n      221             pool.submit,\r\n      222             pool._max_workers,\r\n  \r\n  ~/mambaforge/envs/dask-mini-tutorial/lib/python3.9/site-packages/dask/local.py in get_async(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\r\n      492             # Main loop, wait on tasks to finish, insert new ones\r\n      493             while state[\"waiting\"] or state[\"ready\"] or state[\"running\"]:\r\n  --> 494                 fire_tasks(chunksize)\r\n      495                 for key, res_info, failed in queue_get(queue).result():\r\n      496                     if failed:\r\n  \r\n  ~/mambaforge/envs/dask-mini-tutorial/lib/python3.9/site-packages/dask/local.py in fire_tasks(chunksize)\r\n      474                         (\r\n      475                             key,\r\n  --> 476                             dumps((dsk[key], data)),\r\n      477                             dumps,\r\n      478                             loads,\r\n  \r\n  ~/mambaforge/envs/dask-mini-tutorial/lib/python3.9/site-packages/cloudpickle/cloudpickle_fast.py in dumps(obj, protocol, buffer_callback)\r\n       71                 file, protocol=protocol, buffer_callback=buffer_callback\r\n       72             )\r\n  ---> 73             cp.dump(obj)\r\n       74             return file.getvalue()\r\n       75 \r\n  \r\n  ~/mambaforge/envs/dask-mini-tutorial/lib/python3.9/site-packages/cloudpickle/cloudpickle_fast.py in dump(self, obj)\r\n      600     def dump(self, obj):\r\n      601         try:\r\n  --> 602             return Pickler.dump(self, obj)\r\n      603         except RuntimeError as e:\r\n      604             if \"recursion\" in e.args[0]:\r\n  \r\n  ~/mambaforge/envs/dask-mini-tutorial/lib/python3.9/site-packages/h5py/_hl/base.py in __getnewargs__(self)\r\n      366         limitations, look at the h5pickle project on PyPI.\r\n      367         \"\"\"\r\n  --> 368         raise TypeError(\"h5py objects cannot be pickled\")\r\n      369 \r\n      370     def __getstate__(self):\r\n  \r\n  TypeError: h5py objects cannot be pickled\r\n  ```\r\n</details>\r\n\r\n\r\n**Anything else we need to know?**:\r\nI tried the same with zarr and there was no error:\r\n```python\r\nimport zarr\r\nimport dask.array as da\r\n\r\n# create fake zarr array\r\nzarr_array = zarr.zeros((1000, 3), chunks=(1000, 1), dtype='i')\r\n\r\n# convert to dask array\r\ndask_array = da.from_zarr(zarr_array, chunks=(zarr_array.shape[0], 1))\r\n\r\n# apply function\r\ndoubled = dask_array.map_blocks(lambda x: x * 2)\r\n\r\n# compute\r\ndoubled.compute(scheduler='processes')\r\n```\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2022.02.1\r\n- Python version: 3.9\r\n- Operating System: Mac\r\n- Install method (conda, pip, source): conda",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/dask/dask/issues/8760/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/dask/dask/issues/8760/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}